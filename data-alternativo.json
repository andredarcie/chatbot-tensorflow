{
    "questoes": [
        {
            "tag": "questao_469",
            "padroes": [
                "I am using the Photoshop's javascript API to find the fonts in a given PSD.Given a font name returned by the API, I want to find the actual physical font file that that font name corresponds to on the disc.\n\nThis is all happening in a python program running on OSX so I guess I'm looking for one of:- Some Photoshop javascript- A Python function- An OSX API that I can call from python"
            ],
            "respostas": [
                "<p>There must be a method in Cocoa to get a list of fonts, then you would have to use the PyObjC bindings to call it..<\/p>\n\n<p>Depending on what you need them for, you could probably just use something like the following..<\/p>\n\n<pre><code>import os\ndef get_font_list():\n    fonts = []\n    for font_path in [\"\/Library\/Fonts\", os.path.expanduser(\"~\/Library\/Fonts\")]:\n        if os.path.isdir(font_path):\n            fonts.extend(\n                [os.path.join(font_path, cur_font) \n                 for cur_font in os.listdir(font_path)\n                ]\n            )\n    return fonts\n<\/code><\/pre>\n",
                "<p>I haven't been able to find anything that does this directly.  I think you'll have to iterate through the various font folders on the system: <code>\/System\/Library\/Fonts<\/code>, <code>\/Library\/Fonts<\/code>, and there can probably be a user-level directory as well <code>~\/Library\/Fonts<\/code>.<\/p>\n",
                "<p>open up a terminal (Applications-&gt;Utilities-&gt;Terminal) and type this in:<\/p>\r\n\r\n<pre><code>locate InsertFontHere<br><\/code><\/pre>\r\n\r\n<p>This will spit out every file that has the name you want.<\/p>\r\n\r\n<p>Warning: there may be alot to wade through.<\/p>",
                "<p>Unfortunately the only API that isn't deprecated is located in the ApplicationServices framework, which doesn't have a bridge support file, and thus isn't available in the bridge. If you're wanting to use ctypes, you can use ATSFontGetFileReference after looking up the ATSFontRef.<\/p>\r\n\r\n<p>Cocoa doesn't have any native support, at least as of 10.5, for getting the location of a font.<\/p>"
            ]
        },
        {
            "tag": "questao_502",
            "padroes": [
                "I have a cross-platform (Python) application which needs to generate a JPEG preview of the first page of a PDF.\n\nOn the Mac I am spawning sips.  Is there something similarly simple I can do on Windows?\n"
            ],
            "respostas": [
                "<p>Is the PC likely to have Acrobat installed? I think Acrobat installs a shell extension so previews of the first page of a PDF document appear in Windows Explorer's thumbnail view. You can get thumbnails yourself via the IExtractImage COM API, which you'll need to wrap. <a href=\"http:\/\/www.vbaccelerator.com\/home\/net\/code\/libraries\/shell_projects\/Thumbnail_Extraction\/article.asp\" rel=\"nofollow\" title=\"Domain Specific Development with Visual Studio DSL Tools.\">VBAccelerator has an example in C#<\/a> that you could port to Python.<\/p>\n",
                "<p>You can use ImageMagick's convert utility for this, see some examples in <a href=\"https:\/\/web.archive.org\/web\/20120413111338\/http:\/\/studio.imagemagick.org\/pipermail\/magick-users\/2002-May\/002636.html\" rel=\"nofollow\">http:\/\/studio.imagemagick.org\/pipermail\/magick-users\/2002-May\/002636.html<\/a>\n:<\/p>\n\n<blockquote>\n<pre><code>Convert taxes.pdf taxes.jpg \n<\/code><\/pre>\n  \n  <p>Will convert a two page PDF file into [2] jpeg files: taxes.jpg.0,\n  taxes.jpg.1<\/p>\n  \n  <p>I can also convert these JPEGS to a thumbnail as follows:<\/p>\n\n<pre><code>convert -size 120x120 taxes.jpg.0 -geometry 120x120 +profile '*' thumbnail.jpg\n<\/code><\/pre>\n  \n  <p>I can even convert the PDF directly to a jpeg thumbnail as follows:<\/p>\n\n<pre><code>convert -size 120x120 taxes.pdf -geometry 120x120 +profile '*' thumbnail.jpg\n<\/code><\/pre>\n  \n  <p>This will result in a thumbnail.jpg.0 and thumbnail.jpg.1 for the two\n  pages.<\/p>\n<\/blockquote>\n",
                "<p>ImageMagick delegates the PDF->bitmap conversion to GhostScript anyway, so here's a command you can use (it's based on the actual command listed by the <code>ps:alpha<\/code> delegate in ImageMagick, just adjusted to use JPEG as output):<\/p>\n\n<pre><code>gs -q -dQUIET -dPARANOIDSAFER -dBATCH -dNOPAUSE -dNOPROMPT \\\n-dMaxBitmap=500000000 -dLastPage=1 -dAlignToPixels=0 -dGridFitTT=0 \\\n-sDEVICE=jpeg -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -r72x72 \\\n-sOutputFile=$OUTPUT -f$INPUT\n<\/code><\/pre>\n\n<p>where <code>$OUTPUT<\/code> and <code>$INPUT<\/code> are the output and input filenames. Adjust the <code>72x72<\/code> to whatever resolution you need. (Obviously, strip out the backslashes if you're writing out the whole command as one line.)<\/p>\n\n<p>This is good for two reasons:<\/p>\n\n<ol>\n<li>You don't need to have ImageMagick installed anymore. Not that I have anything against ImageMagick (I love it to bits), but I believe in simple solutions.<\/li>\n<li>ImageMagick does a two-step conversion. First PDF->PPM, then PPM->JPEG. This way, the conversion is one-step.<\/li>\n<\/ol>\n\n<p>Other things to consider: with the files I've tested, PNG compresses better than JPEG. If you want to use PNG, change the <code>-sDEVICE=jpeg<\/code> to <code>-sDEVICE=png16m<\/code>.<\/p>\n"
            ]
        },
        {
            "tag": "questao_535",
            "padroes": [
                "I'm starting work on a hobby project with a python codebase and would like to set up some form of continuous integration (i.e. running a battery of test-cases each time a check-in is made and sending nag e-mails to responsible persons when the tests fail) similar to CruiseControl or TeamCity.\n\nI realize I could do this with hooks in most VCSes, but that requires that the tests run on the same machine as the version control server, which isn't as elegant as I would like. Does anyone have any suggestions for a small, user-friendly, open-source continuous integration system suitable for a Python codebase?\n"
            ],
            "respostas": [
                "<p>I have very good experiences with <a href=\"http:\/\/travis-ci.org\/\" rel=\"nofollow\">Travis-CI<\/a> for smaller code bases.\nThe main advantages are:<\/p>\n\n<ul>\n<li>setup is done in less than half a screen of config file<\/li>\n<li>you can do your own installation or just use the free hosted version<\/li>\n<li>semi-automatic setup for github repositories<\/li>\n<li>no account needed on website; login via github<\/li>\n<\/ul>\n\n<p>Some limitations:<\/p>\n\n<ul>\n<li><p>Python is not supported as a first class language (as of time of writing; but you can use pip and apt-get to install python dependencies; see <a href=\"http:\/\/www.travisswicegood.com\/2011\/11\/11\/travis-and-python\/\" rel=\"nofollow\">this tutorial<\/a>)<\/p><\/li>\n<li><p>code has to be hosted on github (at least when using the official version)<\/p><\/li>\n<\/ul>\n",
                "<p>TeamCity has some Python <a href=\"http:\/\/www.jetbrains.net\/confluence\/display\/TW\/Python+Unit+Test+Reporting\" rel=\"nofollow\">integration<\/a>.<\/p>\n\n<p>But TeamCity is:<\/p>\n\n<ul>\n<li>not open-source<\/li>\n<li>is not small, but rather feature rich<\/li>\n<li>is free for small-mid teams.<\/li>\n<\/ul>\n",
                "<p>We are using <a href=\"http:\/\/bitten.edgewall.org\/\" rel=\"nofollow\">Bitten<\/a> wich is integrated with trac. And it's python based.<\/p>\n",
                "<p>We use both Buildbot and Hudson for Jython development.  Both are useful, but have different strengths and weaknesses.<\/p>\n\n<p>Buildbot's configuration is pure Python and quite simple once you get the hang of it (look at the epydoc-generated API docs for the most current info).  Buildbot makes it easier to define non-testing tasks-Ã¡and distribute the testers.  However, it really has no concept of individual tests, just textual, HTML, and summary output, so if you want to have multi-level browsable test output and so forth you'll have to build it yourself, or just use Hudson.<\/p>\n\n<p>Hudson has terrific support for drilling down from overall results into test suites and individual tests; it also is great for comparing test output between builds, but the distributed (master\/slave) stuff is comparatively more complicated because you need a Java environment on the slaves too; also, Hudson is less tolerant of flaky network links between the master and slaves.<\/p>\n\n<p>So, to get the benefits of both tools, we run a single instance of Hudson, which catches the common test failures, then we do multi-platform regression with Buildbot.<\/p>\n\n<p>Here are our instances:<\/p>\n\n<ul>\n<li><a href=\"http:\/\/bob.underboss.org:8080\/job\/jython\/lastBuild\/testReport\/\">Jython Hudson<\/a><\/li>\n<li><a href=\"http:\/\/www.acm.uiuc.edu\/jython-buildbot\/waterfall\">Jython buildbot<\/a><\/li>\n<\/ul>\n",
                "<p>Second the Buildbot - Trac integration. You can find more information about the integration on the <a href=\"http:\/\/buildbot.net\/trac\/wiki\/BuildbotAndTrac\">Buildbot website<\/a>. At my previous job, we wrote and used the plugin they mention (tracbb).\r\nWhat the plugin does is rewriting all of the Buildbot urls so you can use Buildbot from within Trac. (http:\/\/example.com\/tracbb).<\/p>\r\n\r\n<p>The really nice thing about Buildbot is that the configuration is written in Python. You can integrate your own Python code directly to the configuration. It's also very easy to write your own BuildSteps to execute specific tasks.<\/p>\r\n\r\n<p>We used BuildSteps to get the source from SVN, pull the dependencies, publish test results to WebDAV, etcetera.<\/p>\r\n\r\n<p>I wrote an X10 interface so we could send signals with build results. When the build failed, we switched on a red lava lamp. When the build succeeded, a green lava lamp switched on. Good times :-)<\/p>",
                "<p>We run <a href=\"http:\/\/buildbot.net\/trac\">Buildbot - Trac<\/a> at work, I haven't used it too much since my code base isn't part of the release cycle yet. But we run the tests on different environments (OSX\/Linux\/Win) and it sends emails --and it's written in python.<\/p>",
                "<p>One possibility is Hudson.  It's written in Java, but there's integration with Python projects:<\/p>\n\n<blockquote>\n  <p><a href=\"http:\/\/redsolo.blogspot.com\/2007\/11\/hudson-embraces-python.html\" rel=\"nofollow\">Hudson embraces Python<\/a><\/p>\n<\/blockquote>\n\n<p>I've never tried it myself, however.<\/p>\n\n<p>(<strong>Update<\/strong>, Sept. 2011: After a trademark dispute Hudson has been renamed to <a href=\"http:\/\/jenkins-ci.org\/\" rel=\"nofollow\">Jenkins<\/a>.)<\/p>\n"
            ]
        },
        {
            "tag": "questao_594",
            "padroes": [
                "There are several ways to iterate over a result set. What are the tradeoff of each?\n"
            ],
            "respostas": [
                "<p>There's also the way <code>psyco-pg<\/code> seems to do it... From what I gather, it seems to create dictionary-like row-proxies to map key lookup into the memory block returned by the query. In that case, fetching the whole answer and working with a similar proxy-factory over the rows seems like useful idea. Come to think of it though, it feels more like Lua than Python.<\/p>\n\n<p>Also, this should be applicable to all <a href=\"http:\/\/www.python.org\/dev\/peps\/pep-0249\/\" rel=\"nofollow\">PEP-249 DBAPI2.0<\/a> interfaces, not just Oracle, or did you mean just <em>fastest<\/em> using <em>Oracle<\/em>?<\/p>\n",
                "<p>My preferred way is the cursor iterator, but setting first the arraysize property of the cursor. <\/p>\n\n<pre><code>curs.execute('select * from people')\ncurs.arraysize = 256\nfor row in curs:\n    print row\n<\/code><\/pre>\n\n<p>In this example, cx_Oracle will fetch rows from Oracle 256 rows at a time, reducing the number of network round trips that need to be performed<\/p>\n",
                "<p>The canonical way is to use the built-in cursor iterator.<\/p>\n\n<pre><code>curs.execute('select * from people')\nfor row in curs:\n    print row\n<\/code><\/pre>\n\n<hr>\n\n<p>You can use <code>fetchall()<\/code> to get all rows at once.<\/p>\n\n<pre><code>for row in curs.fetchall():\n    print row\n<\/code><\/pre>\n\n<p>It can be convenient to use this to create a Python list containing the values returned:<\/p>\n\n<pre><code>curs.execute('select first_name from people')\nnames = [row[0] for row in curs.fetchall()]\n<\/code><\/pre>\n\n<p>This can be useful for smaller result sets, but can have bad side effects if the result set is large.<\/p>\n\n<ul>\n<li><p>You have to wait for the entire result set to be returned to\nyour client process.<\/p><\/li>\n<li><p>You may eat up a lot of memory in your client to hold\nthe built-up list.<\/p><\/li>\n<li><p>It may take a while for Python to construct and deconstruct the\nlist which you are going to immediately discard anyways.<\/p><\/li>\n<\/ul>\n\n<hr>\n\n<p>If you know there's a single row being returned in the result set you can call <code>fetchone()<\/code> to get the single row.<\/p>\n\n<pre><code>curs.execute('select max(x) from t')\nmaxValue = curs.fetchone()[0]\n<\/code><\/pre>\n\n<hr>\n\n<p>Finally, you can loop over the result set fetching one row at a time.  In general, there's no particular advantage in doing this over using the iterator.<\/p>\n\n<pre><code>row = curs.fetchone()\nwhile row:\n    print row\n    row = curs.fetchone()\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_683",
            "padroes": [
                "I don't remember whether I was dreaming or not but I seem to recall there being a function which allowed something like,\r\n\r\nfoo in iter_attr(array of python objects, attribute name)\r\n\r\nI've looked over the docs but this kind of thing doesn't fall under any obvious listed headers"
            ],
            "respostas": [
                "<p>I think:<\/p>\r\n\r\n<pre><code>#!\/bin\/python<br>bar in dict(Foo)<br><\/code><\/pre>\r\n\r\n<p>Is what you are thinking of.  When trying to see if a certain key exists within a dictionary in python (python's version of a hash table) there are two ways to check.  First is the <strong><code>has_key()<\/code><\/strong> method attached to the dictionary and second is the example given above.  It will return a boolean value.<\/p>\r\n\r\n<p>That should answer your question.<\/p>\r\n\r\n<p>And now a little off topic to tie this in to the <em>list comprehension<\/em> answer previously given (for a bit more clarity).  <em>List Comprehensions<\/em> construct a list from a basic <em>for loop<\/em> with modifiers.  As an example (to clarify slightly), a way to use the <code>in dict<\/code> language construct in a _list comprehension_:<\/p>\r\n\r\n<p>Say you have a two dimensional dictionary <strong><code>foo<\/code><\/strong> and you only want the second dimension dictionaries which contain the key <strong><code>bar<\/code><\/strong>.  A relatively straightforward way to do so would be to use a <em>list comprehension<\/em> with a conditional as follows:<\/p>\r\n\r\n<pre><code>#!\/bin\/python<br>baz = dict([(key, value) for key, value in foo if bar in value])<br><\/code><\/pre>\r\n\r\n<p>Note the <strong><code>if bar in value<\/code><\/strong> at the end of the statement<strong>, this is a modifying clause which tells the <em>list comprehension<\/em> to only keep those key-value pairs which meet the conditional.<\/strong>  In this case <strong><code>baz<\/code><\/strong> is a new dictionary which contains only the dictionaries from foo which contain bar (Hopefully I didn't miss anything in that code example... you may have to take a look at the list comprehension documentation found in <a href=\"http:\/\/docs.python.org\/tut\/node7.html#SECTION007140000000000000000\" rel=\"nofollow\">docs.python.org tutorials<\/a> and at <a href=\"http:\/\/www.secnetix.de\/olli\/Python\/list_comprehensions.hawk\" rel=\"nofollow\">secnetix.de<\/a>, both sites are good references if you have questions in the future.).<\/p>",
                "<p>What I was thinking of can be achieved using list comprehensions, but I thought that there was a function that did this in a slightly neater way.<\/p>\r\n\r\n<p>i.e. 'bar' is a list of objects, all of which have the attribute 'id'<\/p>\r\n\r\n<p>The mythical functional way:<\/p>\r\n\r\n<pre><code>foo = 12<br>foo in iter_attr(bar, 'id')<\/code><\/pre>\r\n\r\n<p>The list comprehension way:<\/p>\r\n\r\n<pre><code>foo = 12<br>foo in [obj.id for obj in bar]<\/code><\/pre>\r\n\r\n<p>In retrospect the list comprehension way is pretty neat anyway.<\/p>",
                "<p>If you plan on searching anything of remotely decent size, your best bet is going to be to use a dictionary or a set.  Otherwise, you basically have to iterate through every element of the iterator until you get to the one you want.<\/p>\n\n<p>If this isn't necessarily performance sensitive code, then the list comprehension way should work.  But note that it is fairly inefficient because it goes over every element of the iterator and then goes BACK over it again until it finds what it wants.<\/p>\n\n<p>Remember, python has one of the most efficient hashing algorithms around.  Use it to your advantage.<\/p>\n",
                "<p>No, you were not dreaming.  Python has a pretty excellent list comprehension system that lets you manipulate lists pretty elegantly, and depending on exactly what you want to accomplish, this can be done a couple of ways.  In essence, what you're doing is saying \"For item in list if criteria.matches\", and from that you can just iterate through the results or dump the results into a new list.<\/p>\n\n<p>I'm going to crib an example from <a href=\"http:\/\/diveintopython.net\/functional_programming\/filtering_lists.html\" rel=\"nofollow\">Dive Into Python<\/a> here, because it's pretty elegant and they're smarter than I am.  Here they're getting a list of files in a directory, then filtering the list for all files that match a regular expression criteria.<\/p>\n\n<blockquote>\n<pre><code>    files = os.listdir(path)                               \n    test = re.compile(\"test\\.py$\", re.IGNORECASE)          \n    files = [f for f in files if test.search(f)]\n<\/code><\/pre>\n<\/blockquote>\n\n<p>You could do this without regular expressions, for your example, for anything where your expression at the end returns true for a match.  There are other options like using the filter() function, but if I were going to choose, I'd go with this.<\/p>\n\n<p>Eric Sipple<\/p>\n",
                "<p>The function you are thinking of is probably <code>operator.attrgettter<\/code>. For example, to get a list that contains the value of each object's \"id\" attribute:<\/p>\n\n<pre><code>import operator\nids = map(operator.attrgetter(\"id\"), bar)<\/code><\/pre>\n\n<p>If you want to check whether the list contains an object with an id == 12, then a neat and efficient (i.e. doesn't iterate the whole list unnecessarily) way to do it is:<\/p>\n\n<pre><code>any(obj.id == 12 for obj in bar)<\/code><\/pre>\n\n<p>If you want to use 'in' with attrgetter, while still retaining lazy iteration of the list:<\/p>\n\n<p><pre><code>import operator,itertools\nfoo = 12\nfoo in itertools.imap(operator.attrgetter(\"id\"), bar)\n<\/pre><\/code><\/p>\n",
                "<p>you could always write one yourself:<\/p>\n\n<pre><code>def iterattr(iterator, attributename):\n    for obj in iterator:\n        yield getattr(obj, attributename)\n<\/code><\/pre>\n\n<p>will work with anything that iterates, be it a tuple, list, or whatever.<\/p>\n\n<p>I love python, it makes stuff like this very simple and no more of a hassle than neccessary, and in use stuff like this is hugely elegant.<\/p>\n",
                "<p>Are you looking to get a list of objects that have a certain attribute? If so, a <a href=\"http:\/\/docs.python.org\/tut\/node7.html#SECTION007140000000000000000\">list comprehension<\/a> is the right way to do this.<\/p>\r\n\r\n<pre><code>result = [obj for obj in listOfObjs if hasattr(obj, 'attributeName')]<br><\/code><\/pre>",
                "<p>Using a list comprehension would build a temporary list, which could eat all your memory if the sequence being searched is large. Even if the sequence is not large, building the list means iterating over the whole of the sequence before <code>in<\/code> could start its search.<\/p>\n\n<p>The temporary list can be avoiding by using a generator expression:<\/p>\n\n<pre><code>foo = 12\nfoo in (obj.id for obj in bar)\n<\/code><\/pre>\n\n<p>Now, as long as <code>obj.id == 12<\/code> near the start of <code>bar<\/code>, the search will be fast, even if <code>bar<\/code> is infinitely long.<\/p>\n\n<p>As @Matt suggested, it's a good idea to use <code>hasattr<\/code> if any of the objects in <code>bar<\/code> can be missing an <code>id<\/code> attribute:<\/p>\n\n<pre><code>foo = 12\nfoo in (obj.id for obj in bar if hasattr(obj, 'id'))\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_742",
            "padroes": [
                "Django view points to a function, which can be a problem if you want to change only a bit of functionality. Yes, I could have million keyword arguments and even more if statements in the function, but I was thinking more of an object oriented approach.\r\n\r\nFor example, I have a page that displays a user. This page is very similar to page that displays a group, but it's still not so similar to just use another data model. Group also has members etc...\r\n\r\nOne way would be to point views to class methods and then extend that class. Has anyone tried this approach or has any other idea?"
            ],
            "respostas": [
                "<p>Sounds to me like you're trying to combine things that shouldn't be combined.  If you need to do different processing in your view depending on if it's a User or Group object you're trying to look at then you should use two different view functions.<\/p>\r\n\r\n<p>On the other hand there can be common idioms you'd want to extract out of your object_detail type views... perhaps you could use a decorator or just helper functions?<\/p>\r\n\r\n<p>-Dan<\/p>",
                "<p>If you want to share common functionality between pages I suggest you look at custom tags. They're quite <a href=\"https:\/\/docs.djangoproject.com\/en\/1.1\/howto\/custom-template-tags\/\" rel=\"nofollow\">easy to create<\/a>, and are very powerful.<\/p>\n\n<p>Also, <a href=\"https:\/\/code.djangoproject.com\/wiki\/ExtendingTemplates\" rel=\"nofollow\">templates can extend from other templates<\/a>. This allows you to have a base template to set up the layout of the page and to share this between other templates which fill in the blanks. You can nest templates to any depth; allowing you to specify the layout on separate groups of related pages in one place.<\/p>\n",
                "<p>Generic views will usually be the way to go, but ultimately you're free to handle URLs however you want. FormWizard does things in a class-based way, as do some apps for RESTful APIs.<\/p>\n\n<p>Basically with a URL you are given a bunch of variables and place to provide a callable, what callable you provide is completely up to you - the standard way is to provide a function - but ultimately Django puts no restrictions on what you do.<\/p>\n\n<p>I do agree that a few more examples of how to do this would be good, FormWizard is probably the place to start though.<\/p>\n",
                "<p>You can use the Django Generic Views. You can easily achieve desired functionality thorough Django generic Views<\/p>\n",
                "<p>Unless you want to do something a little complex, using the generic views are the way to go.  They are far more powerful than their name implies, and if you are just displaying model data generic views will do the job.<\/p>\n",
                "<p>You can always create a class, override the <em><code>__call__<\/code><\/em> function and then point the URL file to an instance of the class. You can take a look at the <a href=\"http:\/\/code.djangoproject.com\/browser\/django\/trunk\/django\/contrib\/formtools\/wizard.py\" rel=\"nofollow\">FormWizard<\/a> class to see how this is done.<\/p>\n",
                "<p>If you're simply displaying data from models, why not use the <a href=\"https:\/\/docs.djangoproject.com\/en\/1.2\/ref\/generic-views\/\" rel=\"nofollow\">Django Generic Views<\/a>? They're designed to let you easy show data from a model without having to write your own view and stuff about mapping URL paramaters to views, fetching data, handling edge cases, rendering output, etc.<\/p>\n",
                "<p>I needed to use class based views, but I wanted to be able to use the full name of the class in my URLconf without always having to instantiate the view class before using it. What helped me was a surprisingly simple metaclass:<\/p>\n\n<pre><code>class CallableViewClass(type):\n    def __call__(cls, *args, **kwargs):\n        if args and isinstance(args[0], HttpRequest):\n            instance = super(CallableViewClass, cls).__call__()\n            return instance.__call__(*args, **kwargs)\n        else:\n            instance = super(CallableViewClass, cls).__call__(*args, **kwargs)\n            return instance\n\n\nclass View(object):\n    __metaclass__ = CallableViewClass\n\n    def __call__(self, request, *args, **kwargs):\n        if hasattr(self, request.method):\n            handler = getattr(self, request.method)\n            if hasattr(handler, '__call__'):\n                return handler(request, *args, **kwargs)\n        return HttpResponseBadRequest('Method Not Allowed', status=405)\n<\/code><\/pre>\n\n<p>I can now both instantiate view classes and use the instances as view functions, OR I can simply point my URLconf to my class and have the metaclass instantiate (and call) the view class for me. This works by checking the first argument to <code>__call__<\/code> ÃÃÃ´ if it's a <code>HttpRequest<\/code>, it must be an actual HTTP request because it would be nonsense to attept to instantiate a view class with an <code>HttpRequest<\/code> instance.<\/p>\n\n<pre><code>class MyView(View):\n    def __init__(self, arg=None):\n        self.arg = arg\n    def GET(request):\n        return HttpResponse(self.arg or 'no args provided')\n\n@login_required\nclass MyOtherView(View):\n    def POST(request):\n        pass\n\n# And all the following work as expected.\nurlpatterns = patterns(''\n    url(r'^myview1$', 'myapp.views.MyView', name='myview1'),\n    url(r'^myview2$', myapp.views.MyView, name='myview2'),\n    url(r'^myview3$', myapp.views.MyView('foobar'), name='myview3'),\n    url(r'^myotherview$', 'myapp.views.MyOtherView', name='otherview'),\n)\n<\/code><\/pre>\n\n<p>(I posted a snippet for this at <a href=\"http:\/\/djangosnippets.org\/snippets\/2041\/\">http:\/\/djangosnippets.org\/snippets\/2041\/<\/a>)<\/p>\n",
                "<p>I've created and used my own generic view classes, defining <strong><code>__call__<\/code><\/strong> so an instance of the class is callable.  I really like it; while Django's generic views allow some customization through keyword arguments, OO generic views (if their behavior is split into a number of separate methods) can have much more fine-grained customization via subclassing, which lets me repeat myself a lot less.  (I get tired of rewriting the same create\/update view logic anytime I need to tweak something Django's generic views don't quite allow).<\/p>\n\n<p>I've posted some code at <a href=\"http:\/\/www.djangosnippets.org\/snippets\/1009\/\">djangosnippets.org<\/a>.<\/p>\n\n<p>The only real downside I see is the proliferation of internal method calls, which may impact performance somewhat. I don't think this is much of a concern; it's rare that Python code execution would be your performance bottleneck in a web app.<\/p>\n\n<p><strong>UPDATE<\/strong>: Django's own <a href=\"http:\/\/docs.djangoproject.com\/en\/dev\/topics\/class-based-views\/\">generic views<\/a> are now class-based.<\/p>\n\n<p><strong>UPDATE<\/strong>: FWIW, I've changed my opinion on class-based views since this answer was written. After having used them extensively on a couple of projects, I feel they tend to lead to code that is satisfyingly DRY to write, but very hard to read and maintain later, because functionality is spread across so many different places, and subclasses are so dependent on every implementation detail of the superclasses and mixins. I now feel that <a href=\"https:\/\/docs.djangoproject.com\/en\/dev\/ref\/template-response\/\">TemplateResponse<\/a> and view decorators is a better answer for decomposing view code.<\/p>\n"
            ]
        },
        {
            "tag": "questao_766",
            "padroes": [
                "I can get Python to work with Postgresql but I cannot get it to work with MySQL. The main problem is that on the shared hosting account I have I do not have the ability to install things such as Django or PySQL, I generally fail when installing them on my computer so maybe it's good I can't install on the host.\r\n\r\nI found bpgsql really good because it does not require an install, it's a single file that I can look at, read and then call the functions of. Does anybody know of something like this for MySQL?"
            ],
            "respostas": [
                "<p>Take a pick at<\/p>\n\n<p><a href=\"https:\/\/docs.djangoproject.com\/en\/1.8\/ref\/databases\/\" rel=\"nofollow\">https:\/\/docs.djangoproject.com\/en\/1.8\/ref\/databases\/<\/a><\/p>\n\n<p>MySQLdb is mostly used driver, but if you are using python3 and django 1.8.x that will not work, then you should use mysqlclient that is a folk of MySQLdb on the following link<\/p>\n\n<p><a href=\"https:\/\/pypi.python.org\/pypi\/mysqlclient\" rel=\"nofollow\">https:\/\/pypi.python.org\/pypi\/mysqlclient<\/a><\/p>\n",
                "<p>You really want MySQLdb for any MySQL + Python code.  However, you shouldn't need root access or anything to use it.  You can build\/install it in a user directory (~\/lib\/python2.x\/site-packages), and just add that to your PYTHON_PATH env variable.  This should work for just about any python library.<\/p>\n\n<p>Give it a shot, there really isn't a good alternative.<\/p>\n",
                "<p>I uploaded it and got an internal error<\/p>\r\n\r\n<pre><code>Premature end of script headers<br><\/code><\/pre>\r\n\r\n<p>After much playing around, I found that if I had<\/p>\r\n\r\n<pre><code>import cgi<br>import cgitb; cgitb.enable()<br>import MySQLdb<br><\/code><\/pre>\r\n\r\n<p>It would give me a much more useful answer and say that it was not installed, you can see it yourself -> <a href=\"http:\/\/woarl.com\/db.py\" rel=\"nofollow\">http:\/\/woarl.com\/db.py<\/a><\/p>\r\n\r\n<p>Oddly enough, this would produce an error<\/p>\r\n\r\n<pre><code>import MySQLdb<br>import cgi<br>import cgitb; cgitb.enable()<br><\/code><\/pre>\r\n\r\n<p>I looked at some of the other files I had up there and it seems that library was one of the ones I had already tried.<\/p>",
                "<p>You could try setting up your own python installation using <a href=\"http:\/\/peak.telecommunity.com\/DevCenter\/EasyInstall#creating-a-virtual-python\" rel=\"nofollow\">Virtual Python<\/a>.  Check out how to setup Django using it <a href=\"http:\/\/forums.site5.com\/showthread.php?t=10236\" rel=\"nofollow\">here<\/a>.  That was written a long time ago, but it shows how I got MySQLdb setup without having root access or anything like it.  Once you've got the basics going, you can install any python library you want.<\/p>\n",
                "<p>I don't have any experience with <a href=\"http:\/\/www.SiteGround.com\" rel=\"nofollow\">http:\/\/www.SiteGround.com<\/a> as a web host personally.  <\/p>\r\n\r\n<p>This is just a guess, but it's common for a shared host to support Python and MySQL with the MySQLdb module (e.g., GoDaddy does this).  Try the following CGI script to see if MySQLdb is installed.<\/p>\r\n\r\n<pre><code>#!\/usr\/bin\/python<br><br>module_name = 'MySQLdb'<br>head = '''Content-Type: text\/html<br><br>%s is ''' % module_name<br><br>try:<br>    __import__(module_name)<br>    print head + 'installed'<br>except ImportError:<br>    print head + 'not installed'<br><\/code><\/pre>",
                "<p>MySQLdb is what I have used before.<\/p>\r\n\r\n<p>If you host is using Python version 2.5 or higher, support for sqlite3 databases is built in (sqlite allows you to have a relational database that is simply a file in your filesystem).  But buyer beware, sqlite is not suited for production, so it may depend what you are trying to do with it.<\/p>\r\n\r\n<p>Another option may be to call your host and complain, or change hosts.  Honestly these days, any self respecting web host that supports python and mysql ought to have MySQLdb pre installed.<\/p>"
            ]
        },
        {
            "tag": "questao_773",
            "padroes": [
                "I haven't been able to find an understandable explanation of how to actually use Python's itertools.groupby() function.  What I'm trying to do is this:\n\n\n- Take a list - in this case, the children of an objectified lxml element- Divide it into groups based on some criteria- Then later iterate over each of these groups separately.\n\nI've reviewed the documentation, and the examples, but I've had trouble trying to apply them beyond a simple list of numbers. \n\nSo, how do I use of itertools.groupby()?  Is there another technique I should be using?  Pointers to good \"prerequisite\" reading would also be appreciated.\n"
            ],
            "respostas": [
                "<p>Thanks for lots of nice anwser, this is a hackerrank challenge about <strong>groupby<\/strong>, this is <a href=\"https:\/\/www.hackerrank.com\/challenges\/compress-the-string\/submissions\/code\/18455859\" rel=\"nofollow\">link<\/a>.<\/p>\n\n<pre><code>args = \"1234567890\"\n\nfor key, group in groupby(args):\n    # print group # you can look what group is.\n    print((len(list(group)), int(key)), end=\" \")\n<\/code><\/pre>\n\n<p>the output:<\/p>\n\n<p>(1, 1) (1, 2) (1, 3) (1, 4) (1, 5) (1, 6) (1, 7) (1, 8) (1, 9) (1, 0)<\/p>\n\n<p>just count the num occurrence.<\/p>\n",
                "<blockquote>\n  <p><strong>How do I use Python's itertools.groupby()?<\/strong><\/p>\n<\/blockquote>\n\n<p>You can use groupby to group things to iterate over. You give groupby an iterable, and a optional <strong>key<\/strong> function\/callable by which to check the items as they come out of the iterable, and it returns an iterator that gives a two-tuple of the result of the key callable and the actual items in another iterable. From the help:<\/p>\n\n<pre><code>groupby(iterable[, keyfunc]) -&gt; create an iterator which returns\n(key, sub-iterator) grouped by each value of key(value).\n<\/code><\/pre>\n\n<p>Here's an example of groupby using a coroutine to group by a count, it uses a key callable (in this case, <code>coroutine.send<\/code>) to just spit out the count for however many iterations and a grouped sub-iterator of elements:<\/p>\n\n<pre><code>import itertools\n\n\ndef grouper(iterable, n):\n    def coroutine(n):\n        yield # queue up coroutine\n        for i in itertools.count():\n            for j in range(n):\n                yield i\n    groups = coroutine(n)\n    next(groups) # queue up coroutine\n\n    for c, objs in itertools.groupby(iterable, groups.send):\n        yield c, list(objs)\n    # or instead of materializing a list of objs, just:\n    # return itertools.groupby(iterable, groups.send)\n\nlist(grouper(range(10), 3))\n<\/code><\/pre>\n\n<p>prints<\/p>\n\n<pre><code>[(0, [0, 1, 2]), (1, [3, 4, 5]), (2, [6, 7, 8]), (3, [9])]\n<\/code><\/pre>\n",
                "<p>@CaptSolo, I tried your example, but it didn't work.<\/p>\n\n<pre><code>from itertools import groupby \n[(c,len(list(cs))) for c,cs in groupby('Pedro Manoel')]\n<\/code><\/pre>\n\n<p>Output:<\/p>\n\n<pre><code>[('P', 1), ('e', 1), ('d', 1), ('r', 1), ('o', 1), (' ', 1), ('M', 1), ('a', 1), ('n', 1), ('o', 1), ('e', 1), ('l', 1)]\n<\/code><\/pre>\n\n<p>As you can see, there are two o's and two e's, but they got into separate groups. That's when I realized you need to sort the list passed to the groupby function. So, the correct usage would be:<\/p>\n\n<pre><code>name = list('Pedro Manoel')\nname.sort()\n[(c,len(list(cs))) for c,cs in groupby(name)]\n<\/code><\/pre>\n\n<p>Output:<\/p>\n\n<pre><code>[(' ', 1), ('M', 1), ('P', 1), ('a', 1), ('d', 1), ('e', 2), ('l', 1), ('n', 1), ('o', 2), ('r', 1)]\n<\/code><\/pre>\n\n<p>Just remembering, if the list is not sorted, the groupby function <strong>will not work<\/strong>!<\/p>\n",
                "<p>I would like to give another example where groupby without sort is not working. Adapted from example by James Sulak<\/p>\n\n<pre><code>from itertools import groupby\n\nthings = [(\"vehicle\", \"bear\"), (\"animal\", \"duck\"), (\"animal\", \"cactus\"), (\"vehicle\", \"speed boat\"), (\"vehicle\", \"school bus\")]\n\nfor key, group in groupby(things, lambda x: x[0]):\n    for thing in group:\n        print \"A %s is a %s.\" % (thing[1], key)\n    print \" \"\n<\/code><\/pre>\n\n<p>output is<\/p>\n\n<pre><code>A bear is a vehicle.\n\nA duck is a animal.\nA cactus is a animal.\n\nA speed boat is a vehicle.\nA school bus is a vehicle.\n<\/code><\/pre>\n\n<p>there are two groups with vehicule, whereas one could expect only one group<\/p>\n",
                "<p>WARNING:<\/p>\n\n<p>The syntax list(groupby(...)) won't work the way that you intend. It seems to destroy the internal iterator objects, so using<\/p>\n\n<pre><code>for x in list(groupby(range(10))):\n    print(list(x[1]))\n<\/code><\/pre>\n\n<p>will produce:<\/p>\n\n<pre><code>[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[9]\n<\/code><\/pre>\n\n<p>Instead, of list(groupby(...)), try [(k, list(g)) for k,g in groupby(...)], or if you use that syntax often,<\/p>\n\n<pre><code>def groupbylist(*args, **kwargs):\n    return [(k, list(g)) for k, g in groupby(*args, **kwargs)]\n<\/code><\/pre>\n\n<p>and get access to the groupby functionality while avoiding those pesky (for small data) iterators all together.<\/p>\n",
                "<p>Another example:<\/p>\n\n<pre><code>for key, igroup in itertools.groupby(xrange(12), lambda x: x \/\/ 5):\n    print key, list(igroup)\n<\/code><\/pre>\n\n<p>results in<\/p>\n\n<pre><code>0 [0, 1, 2, 3, 4]\n1 [5, 6, 7, 8, 9]\n2 [10, 11]\n<\/code><\/pre>\n\n<p>Note that igroup is an iterator (a sub-iterator as the documentation calls it).<\/p>\n\n<p>This is useful for chunking a generator:<\/p>\n\n<pre><code>def chunker(items, chunk_size):\n    '''Group items in chunks of chunk_size'''\n    for _key, group in itertools.groupby(enumerate(items), lambda x: x[0] \/\/ chunk_size):\n        yield (g[1] for g in group)\n\nwith open('file.txt') as fobj:\n    for chunk in chunker(fobj):\n        process(chunk)\n<\/code><\/pre>\n\n<p>Another example of groupby - when the keys are not sorted.  In the following example, items in xx are grouped by values in yy.  In this case, one set of zeros is output first, followed by a set of ones, followed again by a set of zeros.<\/p>\n\n<pre><code>xx = range(10)\nyy = [0, 0, 0, 1, 1, 1, 0, 0, 0, 0]\nfor group in itertools.groupby(iter(xx), lambda x: yy[x]):\n    print group[0], list(group[1])\n<\/code><\/pre>\n\n<p>Produces:<\/p>\n\n<pre><code>0 [0, 1, 2]\n1 [3, 4, 5]\n0 [6, 7, 8, 9]\n<\/code><\/pre>\n",
                "<p>A neato trick with groupby is to run length encoding in one line:<\/p>\n\n<pre><code>[(c,len(list(cgen))) for c,cgen in groupby(some_string)]\n<\/code><\/pre>\n\n<p>will give you a list of 2-tuples where the first element is the char and the 2nd is the number of repetitions.<\/p>\n",
                "<p>Can you show us your code?<\/p>\n\n<p>The example on the Python docs is quite straightforward:<\/p>\n\n<pre><code>groups = []\nuniquekeys = []\nfor k, g in groupby(data, keyfunc):\n    groups.append(list(g))      # Store group iterator as a list\n    uniquekeys.append(k)\n<\/code><\/pre>\n\n<p>So in your case, data is a list of nodes, keyfunc is where the logic of your criteria function goes and then <code>groupby()<\/code> groups the data.<\/p>\n\n<p>You must be careful to <strong>sort the data<\/strong> by the criteria before you call <code>groupby<\/code> or it won't work. <code>groupby<\/code> method actually just iterates through a list and whenever the key changes it creates a new group.<\/p>\n",
                "<p>As Sebastjan said, <strong>you first have to sort your data. This is important.<\/strong><\/p>\n\n<p>The part I didn't get is that in the example construction<\/p>\n\n<pre><code>groups = []\nuniquekeys = []\nfor k, g in groupby(data, keyfunc):\n   groups.append(list(g))    # Store group iterator as a list\n   uniquekeys.append(k)\n<\/code><\/pre>\n\n<p><code>k<\/code> is the current grouping key, and <code>g<\/code> is an iterator that you can use to iterate over the group defined by that grouping key. In other words, the <code>groupby<\/code> iterator itself returns iterators.<\/p>\n\n<p>Here's an example of that, using clearer variable names:<\/p>\n\n<pre><code>from itertools import groupby\n\nthings = [(\"animal\", \"bear\"), (\"animal\", \"duck\"), (\"plant\", \"cactus\"), (\"vehicle\", \"speed boat\"), (\"vehicle\", \"school bus\")]\n\nfor key, group in groupby(things, lambda x: x[0]):\n    for thing in group:\n        print \"A %s is a %s.\" % (thing[1], key)\n    print \" \"\n<\/code><\/pre>\n\n<p>This will give you the output:<\/p>\n\n<blockquote>\n  <p>A bear is a animal.<br>\n  A duck is a animal.<\/p>\n  \n  <p>A cactus is a plant.<\/p>\n  \n  <p>A speed boat is a vehicle.<br>\n  A school bus is a vehicle.<\/p>\n<\/blockquote>\n\n<p>In this example, <code>things<\/code> is a list of tuples where the first item in each tuple is the group the second item belongs to. <\/p>\n\n<p>The <code>groupby()<\/code> function takes two arguments: (1) the data to group and (2) the function to group it with. <\/p>\n\n<p>Here, <code>lambda x: x[0]<\/code> tells <code>groupby()<\/code> to use the first item in each tuple as the grouping key.<\/p>\n\n<p>In the above <code>for<\/code> statement, <code>groupby<\/code> returns three (key, group iterator) pairs - once for each unique key. You can use the returned iterator to iterate over each individual item in that group.<\/p>\n\n<p>Here's a slightly different example with the same data, using a list comprehension:<\/p>\n\n<pre><code>for key, group in groupby(things, lambda x: x[0]):\n    listOfThings = \" and \".join([thing[1] for thing in group])\n    print key + \"s:  \" + listOfThings + \".\"\n<\/code><\/pre>\n\n<p>This will give you the output:<\/p>\n\n<blockquote>\n  <p>animals: bear and duck.<br>\n  plants: cactus.<br>\n  vehicles: speed boat and school bus.<\/p>\n<\/blockquote>\n"
            ]
        },
        {
            "tag": "questao_972",
            "padroes": [
                "I've read that it is possible to add a method to an existing object (e.g. not in the class definition) in Python, I think this is called Monkey Patching (or in some cases Duck Punching). I understand that it's not always a good decision to do so. But, how might one do this?\n\nUPDATE 8\/04\/2008 00:21:01 EST:\n\nThat looks like a good answer John Downey, I tried it but it appears that it ends up being not a true method.\n\nYour example defines the new patch function with an argument of self, but if you write actual code that way, the now patched class method asks for an argument named self (it doesn't automagically recognize it as the object to which it is supposed to bind, which is what would happen if defined within the class definition), meaning you have to call class.patch(obj) instead of just class.patch() if you want the same functionality as a true method.\n\nIt looks like Python isn't really treating it as a method, but more just as a variable which happens to be a function (and as such is callable).  Is there any way to attach an actual method to a class?\n\nOh, and Ryan, that isn't exactly what I was looking for (it isn't a builtin functionality), but it is quite cool nonetheless.\n"
            ],
            "respostas": [
                "<p>I don't know Python syntax, but I know Ruby can do it, and it is rather trivial.  Let's say you want to add a method to Array that prints the length to standard out:<\/p>\r\n\r\n<pre><code>class Array<br>  def print_length<br>    puts length<br>  end<br>end<br><\/code><\/pre>\r\n\r\n<p>If you don't want to modify the whole class, you can just add the method to a single instance of the array, and no other arrays will have the method:<\/p>\r\n\r\n<pre><code>array = [1, 2, 3]<br>def array.print_length<br>  puts length<br>end<br><\/code><\/pre>\r\n\r\n<p>Just be aware of the issues involved in using this feature.  Jeff Atwood actually <a href=\"http:\/\/www.codinghorror.com\/blog\/archives\/001151.html\" rel=\"nofollow\">wrote about it<\/a> not too long ago.<\/p>",
                "<p>If it can be of any help, I recently released a Python library named Gorilla to make the process of monkey patching more convenient.<\/p>\n\n<p>Using a function <code>needle()<\/code> to patch a module named <code>guineapig<\/code> goes as follows:<\/p>\n\n<pre><code>import gorilla\nimport guineapig\n@gorilla.patch(guineapig)\ndef needle():\n    print(\"awesome\")\n<\/code><\/pre>\n\n<p>But it also takes care of more interesting use cases as shown in the <a href=\"http:\/\/gorilla.readthedocs.org\/en\/latest\/faq.html\" rel=\"nofollow\">FAQ<\/a> from the <a href=\"http:\/\/gorilla.readthedocs.org\/\" rel=\"nofollow\">documentation<\/a>.<\/p>\n\n<p>The code is available on <a href=\"https:\/\/github.com\/christophercrouzet\/gorilla\" rel=\"nofollow\">GitHub<\/a>.<\/p>\n",
                "<p>This question was opened years ago, but hey, there's an easy way to simulate the binding of a function to a class instance using decorators:<\/p>\n\n<pre><code>def binder (function, instance):\n  copy_of_function = type (function) (function.func_code, {)\n  copy_of_function.__bind_to__ = instance\n  def bound_function (*args, **kwargs):\n    return copy_of_function (copy_of_function.__bind_to__, *args, **kwargs)\n  return bound_function\n\n\nclass SupaClass (object):\n  def __init__ (self):\n    self.supaAttribute = 42\n\n\ndef new_method (self):\n  print self.supaAttribute\n\n\nsupaInstance = SupaClass ()\nsupaInstance.supMethod = binder (new_method, supaInstance)\n\notherInstance = SupaClass ()\notherInstance.supaAttribute = 72\notherInstance.supMethod = binder (new_method, otherInstance)\n\notherInstance.supMethod ()\nsupaInstance.supMethod ()\n<\/code><\/pre>\n\n<p>There, when you pass the function and the instance to the binder decorator, it will create a new function, with the same code object as the first one. Then, the given instance of the class is stored in an attribute of the newly created function. The decorator return a (third) function calling automatically the copied function, giving the instance as the first parameter.\n  <br\/>\n  <br\/>\nIn conclusion you get a function simulating it's binding to the class instance. Letting the original function unchanged.<\/p>\n",
                "<p>You guys should really look at <a href=\"http:\/\/github.com\/clarete\/forbiddenfruit\" rel=\"nofollow\">forbidden fruit<\/a>, it's a python library that provides support to monkey patching ANY python class, even strings.<\/p>\n",
                "<h1>This is actually an addon to the answer of \"Jason Pratt\"<\/h1>\n\n<p>Although Jasons answer works, it does only work if one wants to add a function to a class. \nIt did not work for me when I tried to reload an already existing method from the .py source code file.<\/p>\n\n<p>It took me for ages to find a workaround, but the trick seems simple...\n1.st import the code from the source code file\n2.nd force a reload\n3.rd use types.FunctionType(...) to convert the imported and bound method to a function\nyou can also pass on the current global variables, as the reloaded method would be in a different namespace\n4.th now you can continue as suggested by \"Jason Pratt\" \n  using the types.MethodType(...)<\/p>\n\n<p>Example:<\/p>\n\n<pre><code># this class resides inside ReloadCodeDemo.py\nclass A:\n    def bar( self ):\n        print \"bar1\"\n\n    def reloadCode(self, methodName):\n        ''' use this function to reload any function of class A'''\n        import types\n        import ReloadCodeDemo as ReloadMod # import the code as module\n        reload (ReloadMod) # force a reload of the module\n        myM = getattr(ReloadMod.A,methodName) #get reloaded Method\n        myTempFunc = types.FunctionType(# convert the method to a simple function\n                                myM.im_func.func_code, #the methods code\n                                globals(), # globals to use\n                                argdefs=myM.im_func.func_defaults # default values for variables if any\n                                ) \n        myNewM = types.MethodType(myTempFunc,self,self.__class__) #convert the function to a method\n        setattr(self,methodName,myNewM) # add the method to the function\n\nif __name__ == '__main__':\n    a = A()\n    a.bar()\n    # now change your code and save the file\n    a.reloadCode('bar') # reloads the file\n    a.bar() # now executes the reloaded code\n<\/code><\/pre>\n",
                "<p>What Jason Pratt posted is correct.<\/p>\n\n<pre><code>&gt;&gt;&gt; class Test(object):\n...   def a(self):\n...     pass\n... \n&gt;&gt;&gt; def b(self):\n...   pass\n... \n&gt;&gt;&gt; Test.b = b\n&gt;&gt;&gt; type(b)\n&lt;type 'function'&gt;\n&gt;&gt;&gt; type(Test.a)\n&lt;type 'instancemethod'&gt;\n&gt;&gt;&gt; type(Test.b)\n&lt;type 'instancemethod'&gt;\n<\/code><\/pre>\n\n<p>As you can see, Python doesn't consider b() any different than a(). In Python all methods are just variables that happen to be functions. <\/p>\n",
                "<p>Consolidating Jason Pratt's and the community wiki answers, with a look at the results of different methods of binding:<\/p>\n\n<p>Especially note how adding the binding function as a class method <em>works<\/em>, but the referencing scope is incorrect.<\/p>\n\n<pre><code>#!\/usr\/bin\/python -u\nimport types\nimport inspect\n\n## dynamically adding methods to a unique instance of a class\n\n\n# get a list of a class's method type attributes\ndef listattr(c):\n    for m in [(n, v) for n, v in inspect.getmembers(c, inspect.ismethod) if isinstance(v,types.MethodType)]:\n        print m[0], m[1]\n\n# externally bind a function as a method of an instance of a class\ndef ADDMETHOD(c, method, name):\n    c.__dict__[name] = types.MethodType(method, c)\n\nclass C():\n    r = 10 # class attribute variable to test bound scope\n\n    def __init__(self):\n        pass\n\n    #internally bind a function as a method of self's class -- note that this one has issues!\n    def addmethod(self, method, name):\n        self.__dict__[name] = types.MethodType( method, self.__class__ )\n\n    # predfined function to compare with\n    def f0(self, x):\n        print 'f0\\tx = %d\\tr = %d' % ( x, self.r)\n\na = C() # created before modified instnace\nb = C() # modified instnace\n\n\ndef f1(self, x): # bind internally\n    print 'f1\\tx = %d\\tr = %d' % ( x, self.r )\ndef f2( self, x): # add to class instance's .__dict__ as method type\n    print 'f2\\tx = %d\\tr = %d' % ( x, self.r )\ndef f3( self, x): # assign to class as method type\n    print 'f3\\tx = %d\\tr = %d' % ( x, self.r )\ndef f4( self, x): # add to class instance's .__dict__ using a general function\n    print 'f4\\tx = %d\\tr = %d' % ( x, self.r )\n\n\nb.addmethod(f1, 'f1')\nb.__dict__['f2'] = types.MethodType( f2, b)\nb.f3 = types.MethodType( f3, b)\nADDMETHOD(b, f4, 'f4')\n\n\nb.f0(0) # OUT: f0   x = 0   r = 10\nb.f1(1) # OUT: f1   x = 1   r = 10\nb.f2(2) # OUT: f2   x = 2   r = 10\nb.f3(3) # OUT: f3   x = 3   r = 10\nb.f4(4) # OUT: f4   x = 4   r = 10\n\n\nk = 2\nprint 'changing b.r from {0 to {1'.format(b.r, k)\nb.r = k\nprint 'new b.r = {0'.format(b.r)\n\nb.f0(0) # OUT: f0   x = 0   r = 2\nb.f1(1) # OUT: f1   x = 1   r = 10  !!!!!!!!!\nb.f2(2) # OUT: f2   x = 2   r = 2\nb.f3(3) # OUT: f3   x = 3   r = 2\nb.f4(4) # OUT: f4   x = 4   r = 2\n\nc = C() # created after modifying instance\n\n# let's have a look at each instance's method type attributes\nprint '\\nattributes of a:'\nlistattr(a)\n# OUT:\n# attributes of a:\n# __init__ &lt;bound method C.__init__ of &lt;__main__.C instance at 0x000000000230FD88&gt;&gt;\n# addmethod &lt;bound method C.addmethod of &lt;__main__.C instance at 0x000000000230FD88&gt;&gt;\n# f0 &lt;bound method C.f0 of &lt;__main__.C instance at 0x000000000230FD88&gt;&gt;\n\nprint '\\nattributes of b:'\nlistattr(b)\n# OUT:\n# attributes of b:\n# __init__ &lt;bound method C.__init__ of &lt;__main__.C instance at 0x000000000230FE08&gt;&gt;\n# addmethod &lt;bound method C.addmethod of &lt;__main__.C instance at 0x000000000230FE08&gt;&gt;\n# f0 &lt;bound method C.f0 of &lt;__main__.C instance at 0x000000000230FE08&gt;&gt;\n# f1 &lt;bound method ?.f1 of &lt;class __main__.C at 0x000000000237AB28&gt;&gt;\n# f2 &lt;bound method ?.f2 of &lt;__main__.C instance at 0x000000000230FE08&gt;&gt;\n# f3 &lt;bound method ?.f3 of &lt;__main__.C instance at 0x000000000230FE08&gt;&gt;\n# f4 &lt;bound method ?.f4 of &lt;__main__.C instance at 0x000000000230FE08&gt;&gt;\n\nprint '\\nattributes of c:'\nlistattr(c)\n# OUT:\n# attributes of c:\n# __init__ &lt;bound method C.__init__ of &lt;__main__.C instance at 0x0000000002313108&gt;&gt;\n# addmethod &lt;bound method C.addmethod of &lt;__main__.C instance at 0x0000000002313108&gt;&gt;\n# f0 &lt;bound method C.f0 of &lt;__main__.C instance at 0x0000000002313108&gt;&gt;\n<\/code><\/pre>\n\n<p>Personally, I prefer the external ADDMETHOD function route, as it allows me to dynamically assign new method names within an iterator as well.<\/p>\n\n<pre><code>def y(self, x):\n    pass\nd = C()\nfor i in range(1,5):\n    ADDMETHOD(d, y, 'f%d' % i)\nprint '\\nattributes of d:'\nlistattr(d)\n# OUT:\n# attributes of d:\n# __init__ &lt;bound method C.__init__ of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;\n# addmethod &lt;bound method C.addmethod of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;\n# f0 &lt;bound method C.f0 of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;\n# f1 &lt;bound method ?.y of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;\n# f2 &lt;bound method ?.y of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;\n# f3 &lt;bound method ?.y of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;\n# f4 &lt;bound method ?.y of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;\n<\/code><\/pre>\n",
                "<p>Since this question asked for non-Python versions, here's JavaScript:<\/p>\n\n<pre><code>a.methodname = function () { console.log(\"Yay, a new method!\") \n<\/code><\/pre>\n",
                "<p>What you're looking for is <code>setattr<\/code> I believe.\r\nUse this to set an attribute on an object.<\/p>\r\n\r\n<pre><code>&gt;&gt;&gt; def printme(s): print repr(s)<br>&gt;&gt;&gt; class A: pass<br>&gt;&gt;&gt; setattr(A,'printme',printme)<br>&gt;&gt;&gt; a = A()<br>&gt;&gt;&gt; a.printme() # s becomes the implicit 'self' variable<br>&lt; __ main __ . A instance at 0xABCDEFG&gt;<br><\/code><\/pre>",
                "<p>You can use lambda to bind a method to an instance:<\/p>\n\n<pre><code>def run(self):\n    print self._instanceString\n\nclass A(object):\n    def __init__(self):\n        self._instanceString = \"This is instance string\"\n\na = A()\na.run = lambda: run(a)\na.run()\n<\/code><\/pre>\n\n<p>This is instance string<\/p>\n\n<p>Process finished with exit code 0<\/p>\n",
                "<p>There are at least two ways for attach a method to an instance without <code>types.MethodType<\/code>:<\/p>\n\n<pre><code>&gt;&gt;&gt; class A:\n...  def m(self):\n...   print 'im m, invoked with: ', self\n\n&gt;&gt;&gt; a = A()\n&gt;&gt;&gt; a.m()\nim m, invoked with:  &lt;__main__.A instance at 0x973ec6c&gt;\n&gt;&gt;&gt; a.m\n&lt;bound method A.m of &lt;__main__.A instance at 0x973ec6c&gt;&gt;\n&gt;&gt;&gt; \n&gt;&gt;&gt; def foo(firstargument):\n...  print 'im foo, invoked with: ', firstargument\n\n&gt;&gt;&gt; foo\n&lt;function foo at 0x978548c&gt;\n<\/code><\/pre>\n\n<p>1:<\/p>\n\n<pre><code>&gt;&gt;&gt; a.foo = foo.__get__(a, A) # or foo.__get__(a, type(a))\n&gt;&gt;&gt; a.foo()\nim foo, invoked with:  &lt;__main__.A instance at 0x973ec6c&gt;\n&gt;&gt;&gt; a.foo\n&lt;bound method A.foo of &lt;__main__.A instance at 0x973ec6c&gt;&gt;\n<\/code><\/pre>\n\n<p>2:<\/p>\n\n<pre><code>&gt;&gt;&gt; instancemethod = type(A.m)\n&gt;&gt;&gt; instancemethod\n&lt;type 'instancemethod'&gt;\n&gt;&gt;&gt; a.foo2 = instancemethod(foo, a, type(a))\n&gt;&gt;&gt; a.foo2()\nim foo, invoked with:  &lt;__main__.A instance at 0x973ec6c&gt;\n&gt;&gt;&gt; a.foo2\n&lt;bound method instance.foo of &lt;__main__.A instance at 0x973ec6c&gt;&gt;\n<\/code><\/pre>\n\n<p>Useful links:<br>\n<a href=\"http:\/\/docs.python.org\/2\/reference\/datamodel.html#invoking-descriptors\">Data model - invoking descriptors<\/a><br>\n<a href=\"http:\/\/docs.python.org\/2.7\/howto\/descriptor.html#invoking-descriptors\">Descriptor HowTo Guide - invoking descriptors<\/a><\/p>\n",
                "<blockquote>\n  <h1>Adding a Method to an Existing Object Instance<\/h1>\n  \n  <p>I've read that it is possible to add a method to an existing object (e.g. not in the class definition) in python, I think this is called Monkey Patching (or in some cases Duck Punching). I understand that it's not always a good decision to do so. <strong>But, how might one do this?<\/strong><\/p>\n<\/blockquote>\n\n<h2>Yes, it is possible. (But not recommended.)<\/h2>\n\n<p>Since it's instructive, however, I'm going to show you three ways of doing this.<\/p>\n\n<p>Here's some setup code. We need a class definition. It could be imported, but it really doesn't matter.<\/p>\n\n<pre><code>class Foo(object):\n    '''An empty class to demonstrate adding a method to an instance'''\n<\/code><\/pre>\n\n<p>Create an instance:<\/p>\n\n<pre><code>foo = Foo()\n<\/code><\/pre>\n\n<p>Create a method to add to it:<\/p>\n\n<pre><code>def sample_method(self, bar, baz):\n    print(bar + baz)\n<\/code><\/pre>\n\n<h3>Method one - types.MethodType<\/h3>\n\n<p>First, import types, from which we'll get the method constructor:<\/p>\n\n<pre><code>import types\n<\/code><\/pre>\n\n<p>Now we add the method to the instance. To do this, we require the MethodType constructor from the <code>types<\/code> module (which we imported above).<\/p>\n\n<p>The argument signature for types.MethodType is <code>(function, instance, class)<\/code>:<\/p>\n\n<pre><code>foo.sample_method = types.MethodType(sample_method, foo, Foo)\n<\/code><\/pre>\n\n<p>and usage: <\/p>\n\n<pre><code>&gt;&gt;&gt; foo.sample_method(1,2)\n3\n<\/code><\/pre>\n\n<h2>Method two: lexical binding<\/h2>\n\n<p>First, we create a wrapper function that binds the method to the instance:<\/p>\n\n<pre><code>def bind(instance, method):\n    def binding_scope_fn(*args, **kwargs): \n        return method(instance, *args, **kwargs)\n    return binding_scope_fn\n<\/code><\/pre>\n\n<p>usage:<\/p>\n\n<pre><code>&gt;&gt;&gt; foo.sample_method = bind(foo, sample_method)    \n&gt;&gt;&gt; foo.sample_method(1,2)\n3\n<\/code><\/pre>\n\n<h2>Method three: functools.partial<\/h2>\n\n<pre><code>&gt;&gt;&gt; from functools import partial\n&gt;&gt;&gt; foo.sample_method = partial(sample_method, foo)\n&gt;&gt;&gt; foo.sample_method(1,2)\n3    \n<\/code><\/pre>\n\n<p>This makes sense when you consider that bound methods are partial functions of the instance.<\/p>\n\n<h2>Unbound function as an object attribute - why this doesn't work:<\/h2>\n\n<p>If we try to add the sample_method in the same way as we might add it to the class, it is unbound from the instance, and doesn't take the implicit self as the first argument.<\/p>\n\n<pre><code>&gt;&gt;&gt; foo.sample_method = sample_method\n&gt;&gt;&gt; foo.sample_method(1,2)\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: sample_method() takes exactly 3 arguments (2 given)\n<\/code><\/pre>\n\n<p>We can make the unbound function work by explicitly passing the instance (or anything, since this method doesn't actually use the <code>self<\/code> argument variable), but it would not be consistent with the expected signature of other instances (if we're monkey-patching this instance):<\/p>\n\n<pre><code>&gt;&gt;&gt; foo.sample_method(foo, 1, 2)\n3\n<\/code><\/pre>\n\n<hr>\n\n<h1>Disclaimer<\/h1>\n\n<p>Note, just because this is possible doesn't make it recommended. In fact, I suggest that you not do this unless you have a really good reason. It is far better to define the correct method in the class definition or less preferably to monkey-patch the class directly, like this:<\/p>\n\n<pre><code>Foo.sample_method = sample_method\n<\/code><\/pre>\n",
                "<p>In Python monkey patching generally works by overwriting a class or functions signature with your own. Below is an example from the <a href=\"http:\/\/wiki.zope.org\/zope2\/MonkeyPatch\">Zope Wiki<\/a>:<\/p>\r\n\r\n<pre><code>from SomeOtherProduct.SomeModule import SomeClass<br>def speak(self):<br>   return \"ook ook eee eee eee!\"<br>SomeClass.speak = speak<br><\/code><\/pre>\r\n\r\n<p>That code will overwrite\/create a method called speak on the class. In Jeff Atwood's <a href=\"http:\/\/www.codinghorror.com\/blog\/archives\/001151.html\">recent post on monkey patching<\/a>. He shows an example in C# 3.0 which is the current language I use for work.<\/p>",
                "<p>I think that the above answers missed the key point. <\/p>\n\n<p>Let's have a class with a method:<\/p>\n\n<pre><code>class A(object):\n    def m(self):\n        pass\n<\/code><\/pre>\n\n<p>Now, let's play with it in ipython:<\/p>\n\n<pre><code>In [2]: A.m\nOut[2]: &lt;unbound method A.m&gt;\n<\/code><\/pre>\n\n<p>Ok, so <em>m()<\/em> somehow becomes an unbound method of <em>A<\/em>. But is it really like that?<\/p>\n\n<pre><code>In [5]: A.__dict__['m']\nOut[5]: &lt;function m at 0xa66b8b4&gt;\n<\/code><\/pre>\n\n<p>It turns out that <em>m()<\/em> is just a function, reference to which is added to <em>A<\/em> class dictionary - there's no magic. Then why <em>A.m<\/em> gives us an unbound method? It's because the dot is not translated to a simple dictionary lookup. It's de facto a call of A.__class__.__getattribute__(A, 'm'):<\/p>\n\n<pre><code>In [11]: class MetaA(type):\n   ....:     def __getattribute__(self, attr_name):\n   ....:         print str(self), '-', attr_name\n\nIn [12]: class A(object):\n   ....:     __metaclass__ = MetaA\n\nIn [23]: A.m\n&lt;class '__main__.A'&gt; - m\n&lt;class '__main__.A'&gt; - m\n<\/code><\/pre>\n\n<p>Now, I'm not sure out of the top of my head why the last line is printed twice, but still it's clear what's going on there.<\/p>\n\n<p>Now, what the default __getattribute__ does is that it checks if the attribute is a so-called <a href=\"http:\/\/docs.python.org\/reference\/datamodel.html#implementing-descriptors\" rel=\"nofollow\">descriptor<\/a> or not, i.e. if it implements a special __get__ method. If it implements that method, then what is returned is the result of calling that __get__ method. Going back to the first version of our <em>A<\/em> class, this is what we have:<\/p>\n\n<pre><code>In [28]: A.__dict__['m'].__get__(None, A)\nOut[28]: &lt;unbound method A.m&gt;\n<\/code><\/pre>\n\n<p>And because Python functions implement the descriptor protocol, if they are called on behalf of an object, they bind themselves to that object in their __get__ method.<\/p>\n\n<p>Ok, so how to add a method to an existing object? Assuming you don't mind patching class, it's as simple as:<\/p>\n\n<pre><code>B.m = m\n<\/code><\/pre>\n\n<p>Then <em>B.m<\/em> \"becomes\" an unbound method, thanks to the descriptor magic.<\/p>\n\n<p>And if you want to add a method just to a single object, then you have to emulate the machinery yourself, by using types.MethodType:<\/p>\n\n<pre><code>b.m = types.MethodType(m, b)\n<\/code><\/pre>\n\n<p>By the way:<\/p>\n\n<pre><code>In [2]: A.m\nOut[2]: &lt;unbound method A.m&gt;\n\nIn [59]: type(A.m)\nOut[59]: &lt;type 'instancemethod'&gt;\n\nIn [60]: type(b.m)\nOut[60]: &lt;type 'instancemethod'&gt;\n\nIn [61]: types.MethodType\nOut[61]: &lt;type 'instancemethod'&gt;\n<\/code><\/pre>\n",
                "<p>Module <strong>new<\/strong> is deprecated since python 2.6 and removed in 3.0, use <strong>types<\/strong><\/p>\n\n<p>see <a href=\"http:\/\/docs.python.org\/library\/new.html\">http:\/\/docs.python.org\/library\/new.html<\/a><\/p>\n\n<p>In the example below I've deliberately removed return value from <code>patch_me()<\/code> function.\nI think that giving return value may make one believe that patch returns a new object, which is not true - it modifies the incoming one. Probably this can facilitate a more disciplined use of monkeypatching.<\/p>\n\n<pre><code>import types\n\nclass A(object):#but seems to work for old style objects too\n    pass\n\ndef patch_me(target):\n    def method(target,x):\n        print \"x=\",x\n        print \"called from\", target\n    target.method = types.MethodType(method,target)\n    #add more if needed\n\na = A()\nprint a\n#out: &lt;__main__.A object at 0x2b73ac88bfd0&gt;  \npatch_me(a)    #patch instance\na.method(5)\n#out: x= 5\n#out: called from &lt;__main__.A object at 0x2b73ac88bfd0&gt;\npatch_me(A)\nA.method(6)        #can patch class too\n#out: x= 6\n#out: called from &lt;class '__main__.A'&gt;\n<\/code><\/pre>\n",
                "<p>In Python, there is a difference between functions and bound methods.<\/p>\n\n<pre><code>&gt;&gt;&gt; def foo():\n...     print \"foo\"\n...\n&gt;&gt;&gt; class A:\n...     def bar( self ):\n...         print \"bar\"\n...\n&gt;&gt;&gt; a = A()\n&gt;&gt;&gt; foo\n&lt;function foo at 0x00A98D70&gt;\n&gt;&gt;&gt; a.bar\n&lt;bound method A.bar of &lt;__main__.A instance at 0x00A9BC88&gt;&gt;\n&gt;&gt;&gt;\n<\/code><\/pre>\n\n<p>Bound methods have been \"bound\" (how descriptive) to an instance, and that instance will be passed as the first argument whenever the method is called.<\/p>\n\n<p>Callables that are attributes of a class (as opposed to an instance) are still unbound, though, so you can modify the class definition whenever you want:<\/p>\n\n<pre><code>&gt;&gt;&gt; def fooFighters( self ):\n...     print \"fooFighters\"\n...\n&gt;&gt;&gt; A.fooFighters = fooFighters\n&gt;&gt;&gt; a2 = A()\n&gt;&gt;&gt; a2.fooFighters\n&lt;bound method A.fooFighters of &lt;__main__.A instance at 0x00A9BEB8&gt;&gt;\n&gt;&gt;&gt; a2.fooFighters()\nfooFighters\n<\/code><\/pre>\n\n<p>Previously defined instances are updated as well (as long as they haven't overridden the attribute themselves):<\/p>\n\n<pre><code>&gt;&gt;&gt; a.fooFighters()\nfooFighters\n<\/code><\/pre>\n\n<p>The problem comes when you want to attach a method to a single instance:<\/p>\n\n<pre><code>&gt;&gt;&gt; def barFighters( self ):\n...     print \"barFighters\"\n...\n&gt;&gt;&gt; a.barFighters = barFighters\n&gt;&gt;&gt; a.barFighters()\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: barFighters() takes exactly 1 argument (0 given)\n<\/code><\/pre>\n\n<p>The function is not automatically bound when it's attached directly to an instance:<\/p>\n\n<pre><code>&gt;&gt;&gt; a.barFighters\n&lt;function barFighters at 0x00A98EF0&gt;\n<\/code><\/pre>\n\n<p>To bind it, we can use the <a href=\"http:\/\/docs.python.org\/library\/types.html?highlight=methodtype#module-types\">MethodType function in the types module<\/a>:<\/p>\n\n<pre><code>&gt;&gt;&gt; import types\n&gt;&gt;&gt; a.barFighters = types.MethodType( barFighters, a )\n&gt;&gt;&gt; a.barFighters\n&lt;bound method ?.barFighters of &lt;__main__.A instance at 0x00A9BC88&gt;&gt;\n&gt;&gt;&gt; a.barFighters()\nbarFighters\n<\/code><\/pre>\n\n<p>This time other instances of the class have not been affected:<\/p>\n\n<pre><code>&gt;&gt;&gt; a2.barFighters()\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nAttributeError: A instance has no attribute 'barFighters'\n<\/code><\/pre>\n\n<p>More information can be found by reading about <a href=\"http:\/\/users.rcn.com\/python\/download\/Descriptor.htm\">descriptors<\/a> and <a href=\"http:\/\/www.onlamp.com\/pub\/a\/python\/2003\/04\/17\/metaclasses.html\">metaclass<\/a> <a href=\"http:\/\/www.gnosis.cx\/publish\/programming\/metaclass_2.html\">programming<\/a>.<\/p>\n"
            ]
        },
        {
            "tag": "questao_1476",
            "padroes": [
                "How do you express an integer as a binary number with Python literals?\n\nI was easily able to find the answer for hex:\n\n    >>> 0x12AF\n    4783\n    >>> 0x100\n    256\n\n\nand octal:\n\n    >>> 01267\n    695\n    >>> 0100\n    64\n\n\nHow do you use literals to express binary in Python?\n\n\n\nSummary of Answers\n\n\n- Python 2.5 and earlier: can express binary using int('01010101111',2) but not with a literal.- Python 2.5 and earlier: there is no way to express binary literals.- Python 2.6 beta: You can do like so: 0b1100111 or 0B1100111.- Python 2.6 beta: will also allow 0o27 or 0O27 (second character is the letter O) to represent an octal.- Python 3.0 beta: Same as 2.6, but will no longer allow the older 027 syntax for octals.\n"
            ],
            "respostas": [
                "<p>As far as I can tell Python, up through 2.5, only supports hexadecimal &amp; octal literals.  I did find some discussions about adding binary to future versions but nothing definite.<\/p>",
                "<p>I am pretty sure this is one of the things due to change in Python 3.0 with perhaps bin() to go with hex() and oct().<\/p>\n\n<p>EDIT:\nlbrandy's answer is correct in all cases.<\/p>\n",
                "<p>0 in the start here specifies that the base is 8 (not 10), which is pretty easy to see: <\/p>\n\n<pre><code>&gt;&gt;&gt; int('010101', 0)\n4161\n<\/code><\/pre>\n\n<p>If you don't start with a 0, then python assumes the number is base 10.<\/p>\n\n<pre><code>&gt;&gt;&gt; int('10101', 0)\n10101\n<\/code><\/pre>\n",
                "<blockquote>\n  <h1>How do you express binary literals in Python?<\/h1>\n<\/blockquote>\n\n<p>They're not \"binary\" literals, but rather, \"integer literals\". You can express integer literals with a binary format with a <code>0<\/code> followed by a <code>B<\/code> or <code>b<\/code> followed by a series of zeros and ones, for example:<\/p>\n\n<pre><code>&gt;&gt;&gt; 0b0010101010\n170\n&gt;&gt;&gt; 0B010101\n21\n<\/code><\/pre>\n\n<p>From the Python 3 <a href=\"https:\/\/docs.python.org\/3\/reference\/lexical_analysis.html#integer-literals\" rel=\"nofollow\">docs<\/a>, these are the ways of providing integer literals in Python:<\/p>\n\n<blockquote>\n  <p>Integer literals are described by the following lexical definitions:<\/p>\n\n<pre><code>integer        ::=  decimalinteger | octinteger | hexinteger | bininteger\ndecimalinteger ::=  nonzerodigit digit* | \"0\"+\nnonzerodigit   ::=  \"1\"...\"9\"\ndigit          ::=  \"0\"...\"9\"\noctinteger     ::=  \"0\" (\"o\" | \"O\") octdigit+\nhexinteger     ::=  \"0\" (\"x\" | \"X\") hexdigit+\nbininteger     ::=  \"0\" (\"b\" | \"B\") bindigit+\noctdigit       ::=  \"0\"...\"7\"\nhexdigit       ::=  digit | \"a\"...\"f\" | \"A\"...\"F\"\nbindigit       ::=  \"0\" | \"1\"\n<\/code><\/pre>\n  \n  <p>There is no limit for the length of integer literals apart from what\n  can be stored in available memory.<\/p>\n  \n  <p>Note that leading zeros in a non-zero decimal number are not allowed.\n  This is for disambiguation with C-style octal literals, which Python\n  used before version 3.0.<\/p>\n  \n  <p>Some examples of integer literals:<\/p>\n\n<pre><code>7     2147483647                        0o177    0b100110111\n3     79228162514264337593543950336     0o377    0xdeadbeef\n<\/code><\/pre>\n<\/blockquote>\n\n<h2>Other ways of expressing binary:<\/h2>\n\n<p>You can have the zeros and ones in a string object which can be manipulated (although you should probably just do bitwise operations on the integer in most cases) - just pass int the string of zeros and ones and the base you are converting from (2):<\/p>\n\n<pre><code>&gt;&gt;&gt; int('010101', 2)\n21\n<\/code><\/pre>\n\n<p>You can optionally have the <code>0b<\/code> or <code>0B<\/code> prefix:<\/p>\n\n<pre><code>&gt;&gt;&gt; int('0b0010101010', 2)\n170\n<\/code><\/pre>\n\n<p>If you pass it <code>0<\/code> as the base, it will assume base 10 if the string doesn't specify with a prefix:<\/p>\n\n<pre><code>&gt;&gt;&gt; int('10101', 0)\n10101\n&gt;&gt;&gt; int('0b10101', 0)\n21\n<\/code><\/pre>\n\n<h2>Converting from int back to human readable binary:<\/h2>\n\n<p>You can pass an integer to bin to see the string representation of a binary literal:<\/p>\n\n<pre><code>&gt;&gt;&gt; bin(21)\n'0b10101'\n<\/code><\/pre>\n\n<p>And you can combine <code>bin<\/code> and <code>int<\/code> to go back and forth:<\/p>\n\n<pre><code>&gt;&gt;&gt; bin(int('010101', 2))\n'0b10101'\n<\/code><\/pre>\n\n<p>You can use a format specification as well, if you want to have minimum width with preceding zeros:<\/p>\n\n<pre><code>&gt;&gt;&gt; format(int('010101', 2), '{fill{widthb'.format(width=10, fill=0))\n'0000010101'\n&gt;&gt;&gt; format(int('010101', 2), '010b')\n'0000010101'\n<\/code><\/pre>\n",
                "<pre><code>&gt;&gt;&gt; print int('01010101111',2)\n687\n&gt;&gt;&gt; print int('11111111',2)\n255\n<\/code><\/pre>\n\n<p>Another way.<\/p>\n",
                "<p>For reference&mdash;<em>future<\/em> Python possibilities:<br \/>\nStarting with Python 2.6 you can express binary literals using the prefix <strong>0b<\/strong> or <strong>0B<\/strong>:<\/p>\n\n<pre><code>&gt;&gt;&gt; 0b101111\n47\n<\/code><\/pre>\n\n<p>You can also use the new <strong>bin<\/strong> function to get the binary representation of a number:<\/p>\n\n<pre><code>&gt;&gt;&gt; bin(173)\n'0b10101101'\n<\/code><\/pre>\n\n<p>Development version of the documentation: <a href=\"http:\/\/docs.python.org\/dev\/whatsnew\/2.6.html#pep-3127-integer-literal-support-and-syntax\">What's New in Python 2.6<\/a><\/p>\n"
            ]
        },
        {
            "tag": "questao_1734",
            "padroes": [
                "I was just looking through some information about Google's protocol buffers data interchange format.  Has anyone played around with the code or even created a project around it?\r\n\r\nI'm currently using XML in a Python project for structured content created by hand in a text editor, and I was wondering what the general opinion was on Protocol Buffers as a user-facing input format.  The speed and brevity benefits definitely seem to be there, but there are so many factors when it comes to actually generating and processing the data."
            ],
            "respostas": [
                "<p>From your brief description, it sounds like protocol buffers is not the right fit.  The phrase \"structured content created by hand in a text editor\" pretty much screams for XML.<\/p>\n\n<p>But if you want efficient, low latency communications with data structures that are not shared outside your organization, binary serialization such as protocol buffers can offer a huge win.<\/p>\n",
                "<p>Another drawback of binary format like PB is that if there is a single bit of error, the entire data file is not parsable, but with JSON or XML, as the last resort you can still manually fix the error because it is human readable and has redundancy built-in..<\/p>\n",
                "<P>If you are looking for user facing interaction, stick with xml. It has more support, understanding, and general acceptance currently. If it's internal, I would say that protocol buffers are a great idea.<\/P>\r\n<P>Maybe in a few years as more tools come out to support protocol buffers, then start looking towards that for a public facing api. Until then... <A href=\"http:\/\/en.wikipedia.org\/wiki\/JSON\">JSON<\/A>?<\/P>",
                "<p>Protocol buffers are intended to optimize communications between machines. They are really not intended for human interaction. Also, the format is binary, so it could not replace XML in that use case. <\/p>\r\n\r\n<p>I would also recommend <a href=\"http:\/\/en.wikipedia.org\/wiki\/JSON\">JSON<\/a> as being the most compact text-based format.<\/p>"
            ]
        },
        {
            "tag": "questao_1829",
            "padroes": [
                "I've got a menu in Python. That part was easy. I'm using raw_input() to get the selection from the user. \n\nThe problem is that raw_input (and input) require the user to press Enter after they make a selection. Is there any way to make the program act immediately upon a keystroke? Here's what I've got so far:\n\nimport sys\nprint \"\"\"Menu\n1) Say Foo\n2) Say Bar\"\"\"\nanswer = raw_input(\"Make a selection> \")\n\nif \"1\" in answer: print \"foo\"\nelif \"2\" in answer: print \"bar\"\n\n\nIt would be great to have something like\n\nprint menu\nwhile lastKey = \"\":\n    lastKey = check_for_recent_keystrokes()\nif \"1\" in lastKey: #do stuff...\n\n"
            ],
            "respostas": [
                "<p>The  reason msvcrt fails in IDLE is because IDLE is not accessing the library that runs msvcrt. Whereas when you run the program natively in cmd.exe it works nicely. For the same reason that your program blows up on Mac and Linux terminals.<\/p>\r\n\r\n<p>But I guess if you're going to be using this specifically for windows, more power to ya.<\/p>",
                "<p>Wow, that took forever. Ok, here's what I've ended up with <\/p>\r\n\r\n<pre><code>#!C:\\python25\\python.exe<br>import msvcrt<br>print \"\"\"Menu<br>1) Say Foo <br>2) Say Bar\"\"\"<br>while 1:<br>    char = msvcrt.getch()<br>    if char == chr(27): #escape<br>        break<br>    if char == \"1\":<br>        print \"foo\"<br>        break<br>    if char == \"2\":<br>        print \"Bar\"<br>        break<br><\/code><\/pre>\r\n\r\n<p>It fails hard using IDLE, the python...thing...that comes with python. But once I tried it in DOS (er, CMD.exe), as a real program, then it ran fine.<\/p>\r\n\r\n<p>No one try it in IDLE, unless you have Task Manager handy.<\/p>\r\n\r\n<p>I've already forgotten how I lived with menus that arn't super-instant responsive.<\/p>",
                "<p><strong>On Windows:<\/strong><\/p>\n\n<pre><code>import msvcrt\nanswer=msvcrt.getch()\n<\/code><\/pre>\n",
                "<p><strong>On Linux:<\/strong><\/p>\n\n<ul>\n<li>set raw mode<\/li>\n<li>select and read the keystroke<\/li>\n<li>restore normal settings<\/li>\n<\/ul>\n\n<pre>\nimport sys\nimport select\nimport termios\nimport tty\n\ndef getkey():\n    old_settings = termios.tcgetattr(sys.stdin)\n    tty.setraw(sys.stdin.fileno())\n    select.select([sys.stdin], [], [], 0)\n    answer = sys.stdin.read(1)\n    termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)\n    return answer\n\nprint \"\"\"Menu\n1) Say Foo\n2) Say Bar\"\"\"\n\nanswer=getkey()\n\nif \"1\" in answer: print \"foo\"\nelif \"2\" in answer: print \"bar\"\n\n<\/pre>\n"
            ]
        },
        {
            "tag": "questao_1854",
            "padroes": [
                "What do I need to look at to see if I'm on Windows, Unix, etc?\n"
            ],
            "respostas": [
                "<p>Just for completeness, \"OS\" environment variable seems to be defined everywhere. On Windows XP\/7\/8\/10 it is set to \"Windows_NT\". On Linux SuSE SP2 it is set to \"x86-64 linux sles11[2]\". I don't have access to OS-X or BSD machines, would be interesting to check there as well.<\/p>\n\n<pre><code>import os\n\nos_name = os.getenv(\"OS\")\nif os_name == \"Windows_NT\":\n    # Windows\nelif \"linux\" in os_name:\n    # Linux\nelif ...\n<\/code><\/pre>\n",
                "<p>Check the available tests with module platform and print the answer out for your system:<\/p>\n\n<pre><code>import platform\n\nprint dir(platform)\n\nfor x in dir(platform):\n    if x[0].isalnum():\n        try:\n            result = getattr(platform, x)()\n            print \"platform.\"+x+\": \"+result\n        except TypeError:\n            continue\n<\/code><\/pre>\n",
                "<p>You can also use only platform module without importing os module to get all the information.<\/p>\n\n<pre><code>&gt;&gt;&gt; import platform\n&gt;&gt;&gt; platform.os.name\n'posix'\n&gt;&gt;&gt; platform.uname()\n('Darwin', 'mainframe.local', '15.3.0', 'Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1\/RELEASE_X86_64', 'x86_64', 'i386')\n<\/code><\/pre>\n\n<p>A nice and tidy layout for reporting purpose can be achieved using this line:<\/p>\n\n<pre><code>for i in zip(['system','node','release','version','machine','processor'],platform.uname()):print i[0],':',i[1]\n<\/code><\/pre>\n\n<p>That gives this output:<\/p>\n\n<pre><code>system : Darwin\nnode : mainframe.local\nrelease : 15.3.0\nversion : Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1\/RELEASE_X86_64\nmachine : x86_64\nprocessor : i386\n<\/code><\/pre>\n\n<p>What is missing usually is the operating system version but you should know if you are running windows, linux or mac a platform indipendent way is to use this test:<\/p>\n\n<pre><code>In []: for i in [platform.linux_distribution(),platform.mac_ver(),platform.win32_ver()]:\n   ....:     if i[0]:\n   ....:         print 'Version: ',i[0]\n<\/code><\/pre>\n",
                "<p>try this:<\/p>\n\n<pre><code>import os\n\nos.uname()\n<\/code><\/pre>\n\n<p>and you can make it :<\/p>\n\n<pre><code>info=os.uname()\ninfo[0]\ninfo[1]\n<\/code><\/pre>\n",
                "<p>Watch out if you're on Windows with Cygwin where <code>os.name<\/code> is <code>posix<\/code>.<\/p>\n\n<pre><code>&gt;&gt;&gt; import os, platform\n&gt;&gt;&gt; print os.name\nposix\n&gt;&gt;&gt; print platform.system()\nCYGWIN_NT-6.3-WOW\n<\/code><\/pre>\n",
                "<p>If you not looking for the kernel version etc, but looking for the linux distribution you may want to use the following <\/p>\n\n<p>in python2.6+ <\/p>\n\n<pre><code>&gt;&gt;&gt; import platform\n&gt;&gt;&gt; print platform.linux_distribution()\n('CentOS Linux', '6.0', 'Final')\n&gt;&gt;&gt; print platform.linux_distribution()[0]\nCentOS Linux\n&gt;&gt;&gt; print platform.linux_distribution()[1]\n6.0\n<\/code><\/pre>\n\n<p>in python2.4<\/p>\n\n<pre><code>&gt;&gt;&gt; import platform\n&gt;&gt;&gt; print platform.dist()\n('centos', '6.0', 'Final')\n&gt;&gt;&gt; print platform.dist()[0]\ncentos\n&gt;&gt;&gt; print platform.dist()[1]\n6.0\n<\/code><\/pre>\n\n<p>Obviously, this will work only if you are running this on linux. If you want to have more generic script across platforms, you can mix this with code samples given in other answers.<\/p>\n",
                "<p>in the same vein....<\/p>\n\n<pre><code>import platform\nis_windows=(platform.system().lower().find(\"win\") &gt; -1)\n\nif(is_windows): lv_dll=LV_dll(\"my_so_dll.dll\")\nelse:           lv_dll=LV_dll(\".\/my_so_dll.so\")\n<\/code><\/pre>\n",
                "<p>\/usr\/bin\/python3.2<\/p>\n\n<pre><code>def cls():\n    from subprocess import call\n    from platform import system\n\n    os = system()\n    if os == 'Linux':\n        call('clear', shell = True)\n    elif os == 'Windows':\n        call('cls', shell = True)\n<\/code><\/pre>\n",
                "<p>Interesting results on windows 8:<\/p>\n\n<pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; os.name\n'nt'\n&gt;&gt;&gt; import platform\n&gt;&gt;&gt; platform.system()\n'Windows'\n&gt;&gt;&gt; platform.release()\n'post2008Server'\n<\/code><\/pre>\n\n<p><strong>Edit:<\/strong> That's a <a href=\"http:\/\/bugs.python.org\/issue16176\" rel=\"nofollow\">bug<\/a><\/p>\n",
                "<p>For Jython the only way to get os name I found is to check <code>os.name<\/code> Java property (tried with <code>sys<\/code>, <code>os<\/code> and <code>platform<\/code> modules for Jython 2.5.3 on WinXP):<\/p>\n\n<pre><code>def get_os_platform():\n    \"\"\"return platform name, but for Jython it uses os.name Java property\"\"\"\n    ver = sys.platform.lower()\n    if ver.startswith('java'):\n        import java.lang\n        ver = java.lang.System.getProperty(\"os.name\").lower()\n    print('platform: %s' % (ver))\n    return ver\n<\/code><\/pre>\n",
                "<p>I am using the WLST tool that comes with weblogic, and it doesn't implement the platform package. <\/p>\n\n<pre><code>wls:\/offline&gt; import os\nwls:\/offline&gt; print os.name\njava \nwls:\/offline&gt; import sys\nwls:\/offline&gt; print sys.platform\n'java1.5.0_11'\n<\/code><\/pre>\n\n<p>Apart from patching the system <em>javaos.py<\/em> (<a href=\"http:\/\/osdir.com\/ml\/lang.jython.devel\/2006-08\/msg00035.html\" rel=\"nofollow\">issue with os.system() on windows 2003 with jdk1.5<\/a>) (which I can't do, I have to use weblogic out of the box), this is what I use:<\/p>\n\n<pre><code>def iswindows():\n  os = java.lang.System.getProperty( \"os.name\" )\n  return \"win\" in os.lower()\n<\/code><\/pre>\n",
                "<pre><code>&gt;&gt;&gt; import platform\n&gt;&gt;&gt; platform.system()\n<\/code><\/pre>\n",
                "<p>I do this<\/p>\n\n<pre><code>import sys\nprint sys.platform\n<\/code><\/pre>\n\n<p>Docs here : <a href=\"http:\/\/docs.python.org\/library\/sys.html#sys.platform\">sys.platform<\/a>. <\/p>\n\n<p>Everything you need is probably in the sys module.<\/p>\n",
                "<p>A comparison between the different methods, and what they return on different operating systems can be found here:\n<a href=\"https:\/\/github.com\/hpcugent\/easybuild\/wiki\/OS_flavor_name_version\">OS_flavor_name_version<\/a><\/p>\n\n<p>Methods that are compared:<\/p>\n\n<pre><code>import platform\nimport sys\n\ndef linux_distribution():\n  try:\n    return platform.linux_distribution()\n  except:\n    return \"N\/A\"\n\nprint(\"\"\"Python version: %s\ndist: %s\nlinux_distribution: %s\nsystem: %s\nmachine: %s\nplatform: %s\nuname: %s\nversion: %s\nmac_ver: %s\n\"\"\" % (\nsys.version.split('\\n'),\nstr(platform.dist()),\nlinux_distribution(),\nplatform.system(),\nplatform.machine(),\nplatform.platform(),\nplatform.uname(),\nplatform.version(),\nplatform.mac_ver(),\n))\n<\/code><\/pre>\n",
                "<p>You can also use sys.platform if you already have imported sys and you don't want to import another module<\/p>\n\n<pre><code>&gt;&gt;&gt; import sys\n&gt;&gt;&gt; sys.platform\n'linux2'\n<\/code><\/pre>\n",
                "<p>Sample code to differentiate OS's using python: <\/p>\n\n<pre><code>from sys import platform as _platform\n\nif _platform == \"linux\" or _platform == \"linux2\":\n   # linux\nelif _platform == \"darwin\":\n   # MAC OS X\nelif _platform == \"win32\":\n   # Windows\n<\/code><\/pre>\n",
                "<p>For the record here's the results on Mac:<\/p>\n\n<pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; os.name\n'posix'\n&gt;&gt;&gt; import platform\n&gt;&gt;&gt; platform.system()\n'Darwin'\n&gt;&gt;&gt; platform.release()\n'8.11.1'\n<\/code><\/pre>\n",
                "<p>Dang -- lbrandy beat me to the punch, but that doesn't mean I can't provide you with the system results for Vista!<\/p>\n\n<pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; os.name\n'nt'\n&gt;&gt;&gt; import platform\n&gt;&gt;&gt; platform.system()\n'Windows'\n&gt;&gt;&gt; platform.release()\n'Vista'\n<\/code><\/pre>\n",
                "<pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; print os.name\nposix\n&gt;&gt;&gt; import platform\n&gt;&gt;&gt; platform.system()\n'Linux'\n&gt;&gt;&gt; platform.release()\n'2.6.22-15-generic'\n<\/code><\/pre>\n\n<p>See: <a href=\"https:\/\/docs.python.org\/2\/library\/platform.html\">platform ÃÃÃ¶ Access to underlying platformÃÃÃs identifying data<\/a><\/p>\n"
            ]
        },
        {
            "tag": "questao_1983",
            "padroes": [
                "In many places, (1,2,3) and [1,2,3] can be used interchangeably.\n\nWhen should I use one or the other, and why?\n"
            ],
            "respostas": [
                "<p>Basically, <code>(1, 2, 3)<\/code> is a tuple, while <code>[1, 2, 3]<\/code> is a list. <\/p>\n\n<p>A tuple is a non-mutable data type which means you are not able to change its contents once it has been created. Tuples are mostly used in order to return more than one value from a function. For example:<\/p>\n\n<pre><code>def returnNameAndLastName(wholeName):\n    \"\"\"\n    @param wholeName: string in the format Name LastName\n    \"\"\"\n    data = wholeName.split()\n    name = data[0]\n    lastName = data[1]\n    return (name, lastName) # parenthesis are optional here\n<\/code><\/pre>\n\n<p>you can store in a variable the whole tuple or in two independent variables the content of the tuple. <code>myTuple = wholeName(\"Sam Smith\")<\/code> or <code>name, lastName = wholeName(\"Sam Smith\")<\/code>. Another application for tuples is use them as dictionaries' keys because, as mention, they are not mutable. Therefore, this is a way to assure the key will not be changed. It is not needed that all the elements of the tuple having the same type. <code>(1, 'Hello', ('version', 2.5), [1, 2, 3])<\/code> is completely valid. As shown a tuple can be an element of a tuple, and a list can be an element of a tuple too.<\/p>\n\n<p>On the other hand, a list is a mutable data type which means its content can be change after being created. A list is similar to an array, but to be more specific it is like an array list because an array has a fixed size which cannot be changed, while a list has a variable size depending on the number of elements it contains. Although lists are used to store data that are related, because of Python is not a strongly typed programming language, it is possible to have list which elements have different types like <code>[1, \"Goodbye\", [1, 'music'], (1, 2, 3)]<\/code>. As shown, a list can be an element of a list, and a tuple also can be an element of a list.<\/p>\n",
                "<p><code>(1,2,3)<\/code> is a tuple while <code>[1,2,3]<\/code> is a list.  A tuple is an immutable object while a list is mutable.<\/p>\n",
                "<p><code>(1,2,3)<\/code> is a tuple and <code>[1,2,3]<\/code> is a list. You either of the two represent sequences of numbers but note that tuples are immutable and list are mutable Python objects. <\/p>\n",
                "<p>open a console and run python.\nTry this:<\/p>\n\n<pre><code>  &gt;&gt;&gt; list = [1, 2, 3]     \n  &gt;&gt;&gt; dir(list)\n    ['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__delsli\n    ce__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getit\n    em__', '__getslice__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__',\n     '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__r\n    educe__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__'\n    , '__setitem__', '__setslice__', '__sizeof__', '__str__', '__subclasshook__', \n'append', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n<\/code><\/pre>\n\n<p>As you may see the last on the last line list have the following methods:\n<strong>'append', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort'<\/strong><\/p>\n\n<p>Now try the same for tuple:<\/p>\n\n<pre><code>&gt;&gt;&gt; tuple = (1, 2, 3)\n&gt;&gt;&gt; dir(tuple)\n    ['__add__', '__class__', '__contains__', '__delattr__', '__doc__', '__eq__', '__\n    format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__get\n    slice__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__\n    lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__'\n    , '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'count', 'index']\n<\/code><\/pre>\n\n<p>Only <strong>'count' and 'index'<\/strong> from list methods appears here.<\/p>\n\n<p>This is because tuples are immutable and they don't support any modifications. Instead they are simpler and faster in internal implementation.<\/p>\n",
                "<p><code>[1,2,3]<\/code> is a list.<\/p>\n\n<p><code>(1,2,3)<\/code> is a tuple and immutable.<\/p>\n",
                "<P>As others have mentioned, Lists and tuples are both containers which can be used to store python objects. Lists are extensible and their contents can change by assignment, on the other hand tuples are immutable.<\/P>\r\n<P>Also, lists cannot be used as keys in a dictionary whereas tuples can. <\/P>",
                "<p>If you can find a solution that works with tuples, use them, as it forces immutability which kind of drives you down a more functional path. You almost never regret going down the functional\/immutable path.<\/p>",
                "<p>Whenever I need to pass in a collection of items to a function, if I want the function to not change the values passed in - I use tuples. <\/p>\n\n<p>Else if I want to have the function to alter the values, I use list. <\/p>\n\n<p>Always if you are using external libraries and need to pass in a list of values to a function and are unsure about the integrity of the data, use a tuple. <\/p>\n",
                "<p>[1, 2, 3] is a list in which one can add or delete items.<br>\n(1, 2, 3) is a tuple in which once defined, modification cannot be done.<\/p>\n",
                "<p>The notion of tuples are highly expressive:<\/p>\n\n<ul>\n<li><p>Pragmatically, they are great for packing and unpacking values (<code>x,y=coord<\/code>).<\/p><\/li>\n<li><p>In combination with dictionaries (hash tables), they allow forms of mapping that would otherwise require many levels of association.  For example, consider marking that (x,y) has been found.<\/p>\n\n<pre><code>\/\/ PHP\nif (!isset($found[$x])) {\n    $found[$x] = Array();\n    $found[$x][$y] = true;\n else if (!isset($found[$x][$y])) {\n    $found[$x][$y] = true;\n\n\n\n# Python\nfound[(x,y)] = True # parens added for clarity\n<\/code><\/pre><\/li>\n<li><p>Lists should be used with the expectation of operations on its contents (hence the various mentions of immutability).  One will want to pop, push, splice, slice, search, insert before, insert after, etc with a list.<\/p><\/li>\n<li><p>Tuples should be a low-level representation of an object, where simple comparisons are made, or operations such as extracting the n'th element or n elements in a predictable fashion, such as the coordinates example given earlier.<\/p><\/li>\n<li><p>Lastly, lists are not hashable, so the type of mapping done with dictionaries (hash tables in Perl, associative arrays in PHP) must be done with tuples.<\/p>\n\n<p>Here's a simple example of tuples and dictionaries, together at last:<\/p>\n\n<pre><code>\"\"\"\ncouple is a tuple of two people\ndoesLike is a dictionary mapping couples to True or False\n\"\"\"\ncouple = \"john\", \"jane\"\ndoesLike = dict()\ndoesLike[couple] = True\ndoesLike[\"jane\", \"john\"] = False # unrequited love :'(\n<\/code><\/pre><\/li>\n<\/ul>\n",
                "<p>Tuples are a quick\\flexible way to create <em>composite<\/em> data-types.\r\nLists are containers for, well, lists of objects.<\/p>\r\n\r\n<p>For example, you would use a List to store a list of student details in a class.<\/p>\r\n\r\n<p>Each student detail in that list may be a 3-tuple containing their roll number, name and test score.<\/p>\r\n\r\n<pre><code> `[(1,'Mark',86),(2,'John',34)...]`<br><\/code><\/pre>\r\n\r\n<p>Also, because tuples are immutable they can be used as keys in dictionaries.<\/p>",
                "<p>The list [1,2,3] is dynamic and flexible but that flexibility comes at a speed cost.<\/p>\n\n<p>The tuple (1,2,3) is fixed (immutable) and therefore faster.<\/p>\n",
                "<p>From the <a href=\"http:\/\/www.python.org\/doc\/faq\/general\/#why-are-there-separate-tuple-and-list-data-types\">Python FAQ<\/a>:<\/p>\r\n\r\n<blockquote>\r\n  <p>Lists and tuples, while similar in many respects, are generally used in fundamentally different ways. Tuples can be thought of as being similar to Pascal records or C structs; they're small collections of related data which may be of different types which are operated on as a group. For example, a Cartesian coordinate is appropriately represented as a tuple of two or three numbers.<\/p>\r\n  \r\n  <p>Lists, on the other hand, are more like arrays in other languages. They tend to hold a varying number of objects all of which have the same type and which are operated on one-by-one.<\/p>\r\n<\/blockquote>\r\n\r\n<p>Generally by convention you wouldn't choose a list or a tuple just based on its (im)mutability.  You would choose a tuple for small collections of completely different pieces of data in which a full-blown class would be too heavyweight, and a list for collections of any reasonable size where you have a homogeneous set of data.<\/p>"
            ]
        },
        {
            "tag": "questao_2311",
            "padroes": [
                "I have created a PHP-script to update a webserver that is live inside a local directory.\nI'm migrating the script into Python. It works fine for the most part, but after a PUT command the size of the file appears to change. Thus, the size of the file is different from that of the file on the server. \n\nOnce I download again the file from the FTP server, the only difference is the CR\/LF mark. This annoys me because the same script is comparing the size of the files to update. Also, in case it means anything, the script works perfectly in PHP v+Â¡a ftp_put.\n\nfrom ftplib import FTP\n\nftpserver = \"myserver\"\nftpuser = \"myuser\"\nftppass = \"mypwd\"\n\nlocfile =  \"g:\/test\/style.css\"\nftpfile =  \"\/temp\/style.css\"\n\ntry:\n    ftp = FTP(ftpserver, ftpuser, ftppass)\nexcept:\n    exit (\"Cannot connect\")\n\nf = open (locfile, \"r\")\ntry:\n    ftp.delete (ftpfile)\nexcept:\n    pass\n\n# ftp.sendcmd (\"TYPE I\")\n# ftp.storlines(\"STOR %s\" % ftpfile, f)\nftp.storbinary(\"STOR %s\" % ftpfile, f)\nf.close()\n\nftp.dir (ftpfile)\nftp.quit()\n\n\nAny suggestions?\n"
            ],
            "respostas": [
                "<p>Small files take up a whole node on the filesystem whatever size that is.<\/p>\r\n\r\n<p>My host tends to report all small files as 4kb in ftp but in a shell gives an accurate size so it might be a 'feature' common to ftp clients.<\/p>",
                "<p>Well if you go under the properties of your file in Windows or a *nix environment, you will notice two sizes.  One is the sector size, and one is the actual size.  The sector size is the number of sectors in bytes that are used up on your hard disk.  That is because two files cannot be in the same sector with most modern file systems, so if your file fills up half of the sector the whole sector is marked as filled.<\/p>\r\n\r\n<p>So you might be comparing the sector file size to the actual file size on the FTP server or vice versa.<\/p>",
                "<p>Do you need to open the locfile in binary using <code>rb<\/code>?<\/p>\n\n<pre><code>f = open (locfile, \"rb\")\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_2933",
            "padroes": [
                "Python works on multiple platforms and can be used for desktop and web applications, thus I conclude that there is some way to compile it into an executable for Mac, Windows and Linux.\r\n\r\nThe problem being I have no idea where to start or how to write a GUI with it, can anybody shed some light on this and point me in the right direction please?"
            ],
            "respostas": [
                "<p>You don't need to <em>compile<\/em> python for Mac\/Windows\/Linux.  It is an interpreted language, so you simply need to have the Python interpreter installed on the system of your choice (it is available for all three platforms).<\/p>\r\n\r\n<p>As for a GUI library that works cross platform, Python's <a href=\"http:\/\/www.tcl.tk\/\" rel=\"nofollow\">Tk\/Tcl<\/a> widget library works very well, and I believe is sufficiently cross platform.<\/p>\r\n\r\n<p><a href=\"http:\/\/docs.python.org\/lib\/module-Tkinter.html\" rel=\"nofollow\">Tkinter<\/a> is the python interface to Tk\/Tcl<\/p>\r\n\r\n<p>From the python project webpage: <\/p>\r\n\r\n<blockquote>\r\n  <p>Tkinter is not the only GuiProgramming\r\n  toolkit for Python.  It is however the\r\n  most commonly used one, and almost the\r\n  only  one that is portable between\r\n  Unix, Mac and Windows<\/p>\r\n<\/blockquote>",
                "<p>Since python is installed on nearly every non-Windows OS by default now, the only thing you really need to make sure of is that all of the non-standard libraries you use are installed.<\/p>\r\n\r\n<p>Having said that, it is possible to build executables that include the python interpreter, and any libraries you use.  This is likely to create a large executable, however.<\/p>\r\n\r\n<p>MacOS X even includes support in the Xcode IDE for creating full standalone GUI apps.  These can be run by any user running OS X.<\/p>",
                "<p>I'm not sure that this is the best way to do it, but when I'm deploying Ruby GUI apps (not Python, but has the same \"problem\" as far as .exe's are concerned) on Windows, I just write a short launcher in C# that calls on my main script. It compiles to an executable, and I then have an application executable.<\/p>\n",
                "<p>For the GUI itself:<\/p>\n\n<p><a href=\"http:\/\/wiki.python.org\/moin\/PyQt\" rel=\"nofollow\">PyQT<\/a> is pretty much the reference.<\/p>\n\n<p>Another way to develop a rapid user interface is to write a web app,\nhave it run locally and display the app in the browser.<\/p>\n\n<p>Plus, if you go for the Tkinter option suggested by lubos hasko\nyou may want to try portablepy to have your app run on Windows environment\nwithout Python.<\/p>\n",
                "<p>There's also <a href=\"http:\/\/pygtk.org\/\">PyGTK<\/a>, which is basically a Python wrapper for the Gnome Toolkit.  I've found it easier to wrap my mind around than Tkinter, coming from pretty much no knowledge of GUI programming previously.  It works pretty well and has some good tutorials.  Unfortunately there isn't an installer for Python 2.6 for Windows yet, and may not be for a while.<\/p>\n",
                "<p>An alternative tool to py2exe is <a href=\"http:\/\/pypi.python.org\/pypi\/bbfreeze\/\">bbfreeze<\/a> which generates executables for windows and linux. It's newer than py2exe and handles eggs quite well. I've found it magically works better without configuration for a wide variety of applications.<\/p>\n",
                "<p>Another system (not mentioned in the accepted answer yet) is PyInstaller, which worked for a PyQt project of mine when py2exe would not. I found it easier to use.<\/p>\n\n<p><a href=\"http:\/\/www.pyinstaller.org\/\">http:\/\/www.pyinstaller.org\/<\/a><\/p>\n\n<p>Pyinstaller is based on Gordon McMillan's Python Installer. Which is no longer available.<\/p>\n",
                "<p>First you will need some GUI library with Python bindings and then (if you want) some program that will convert your python scripts into standalone executables.<\/p>\n\n<p><strong>Cross-platform GUI libraries with Python bindings (Windows, Linux, Mac)<\/strong><\/p>\n\n<p>Of course, there are many, but the most popular that I've seen in wild are:<\/p>\n\n<ul>\n<li><a href=\"http:\/\/wiki.python.org\/moin\/TkInter\">Tkinter<\/a>  - based on <a href=\"http:\/\/www.tcl.tk\/\">Tk GUI toolkit<\/a> (de-facto standard GUI library for python, free for commercial projects)<\/li>\n<li><a href=\"http:\/\/www.wxpython.org\/\">WxPython<\/a> - based on <a href=\"http:\/\/www.wxwidgets.org\/\">WxWidgets<\/a> (very popular, free for commercial projects)<\/li>\n<li><a href=\"http:\/\/www.riverbankcomputing.co.uk\/news\">PyQt<\/a> - based on <a href=\"http:\/\/trolltech.com\/products\/qt\/\">Qt<\/a> (also very popular and more stable than WxWidgets but costly license for commercial projects)<\/li>\n<\/ul>\n\n<p>Complete list is at <a href=\"http:\/\/wiki.python.org\/moin\/GuiProgramming\">http:\/\/wiki.python.org\/moin\/GuiProgramming<\/a><\/p>\n\n<p><strong>Single executable (Windows)<\/strong><\/p>\n\n<ul>\n<li><a href=\"http:\/\/www.py2exe.org\/\">py2exe<\/a> - Probably the most popular out there (<a href=\"http:\/\/stackoverflow.com\/questions\/2933\/an-executable-python-app\/31859#31859\">PyInstaller<\/a> is also gaining in popularity)<\/li>\n<\/ul>\n\n<p><strong>Single executable (Linux)<\/strong><\/p>\n\n<ul>\n<li><a href=\"http:\/\/wiki.python.org\/moin\/Freeze\">Freeze<\/a> - works the same way like py2exe but targets Linux platform<\/li>\n<\/ul>\n\n<p><strong>Single executable (Mac)<\/strong><\/p>\n\n<ul>\n<li><a href=\"https:\/\/pythonhosted.org\/py2app\/\">py2app<\/a> - again, works like py2exe but targets Mac OS<\/li>\n<\/ul>\n"
            ]
        },
        {
            "tag": "questao_3061",
            "padroes": [
                "What is the best way to go about calling a function given a string with the function's name in a Python program.  For example, let's say that I have a module foo, and I have a string whose contents are \"bar\". What is the best way to go about calling foo.bar()?\n\nI need to get the return value of the function, which is why I don't just use eval. I figured out how to do it by using eval to define a temp function that returns the result of that function call, but I'm hoping that there is a more elegant way to do this.\n"
            ],
            "respostas": [
                "<p>none of what was suggested helped me. I did discover this though.<\/p>\n\n<pre><code>&lt;object&gt;.__getattribute__(&lt;string name&gt;)(&lt;params&gt;)\n<\/code><\/pre>\n\n<p>I am using python 2.66 <\/p>\n\n<p>Hope this helps<\/p>\n",
                "<p>For what it's worth, if you needed to pass the function (or class) name and app name as a string, then you could do this:<\/p>\n\n<pre><code>myFnName  = \"MyFn\"\nmyAppName = \"MyApp\"\napp = sys.modules[myAppName]\nfn  = getattr(app,myFnName)\n<\/code><\/pre>\n",
                "<p>The answer (I hope) no one ever wanted<\/p>\n\n<p>Eval like behavior<\/p>\n\n<pre><code>getattr(locals().get(\"foo\") or globals().get(\"foo\"), \"bar\")()\n<\/code><\/pre>\n\n<p>Why not add auto-importing<\/p>\n\n<pre><code>getattr(\n    locals().get(\"foo\") or \n    globals().get(\"foo\") or\n    __import__(\"foo\"), \n\"bar\")()\n<\/code><\/pre>\n\n<p>In case we have extra dictionaries we want to check<\/p>\n\n<pre><code>getattr(next((x for x in (f(\"foo\") for f in \n                          [locals().get, globals().get, \n                           self.__dict__.get, __import__]) \n              if x)),\n\"bar\")()\n<\/code><\/pre>\n\n<p>We need to go deeper<\/p>\n\n<pre><code>getattr(next((x for x in (f(\"foo\") for f in \n              ([locals().get, globals().get, self.__dict__.get] +\n               [d.get for d in (list(dd.values()) for dd in \n                                [locals(),globals(),self.__dict__]\n                                if isinstance(dd,dict))\n                if isinstance(d,dict)] + \n               [__import__])) \n        if x)),\n\"bar\")()\n<\/code><\/pre>\n",
                "<p>Given a string, with a complete python path to a function, this is how I went about getting the result of said function:<\/p>\n\n<pre><code>import importlib\nfunction_string = 'mypackage.mymodule.myfunc'\nmod_name, func_name = function_string.rsplit('.',1)\nmod = importlib.import_module(mod_name)\nfunc = getattr(mod, func_name)\nresult = func()\n<\/code><\/pre>\n",
                "<p>Just a simple contribution. If the class that we need to instance is in the same file, we can use something like this:<\/p>\n\n<pre><code># Get class from globals and create an instance\nm = globals()['our_class']()\n\n# Get the function (from the instance) that we need to call\nfunc = getattr(m, 'function_name')\n\n# Call it\nfunc()\n<\/code><\/pre>\n\n<p>For example:<\/p>\n\n<pre><code>class A:\n    def __init__(self):\n        pass\n\n    def sampleFunc(self, arg):\n        print('you called sampleFunc({)'.format(arg))\n\nm = globals()['A']()\nfunc = getattr(m, 'sampleFunc')\nfunc('sample arg')\n\n# Sample, all on one line\ngetattr(globals()['A'](), 'sampleFunc')('sample arg')\n<\/code><\/pre>\n\n<p>And, if not a class:<\/p>\n\n<pre><code>def sampleFunc(arg):\n    print('you called sampleFunc({)'.format(arg))\n\nglobals()['sampleFunc']('sample arg')\n<\/code><\/pre>\n",
                "<p>Patrick's solution is probably the cleanest.\nIf you need to dynamically pick up the module as well, you can import it like:<\/p>\n\n<pre><code>m = __import__ ('foo')\nfunc = getattr(m,'bar')\nfunc()\n<\/code><\/pre>\n",
                "<pre><code>locals()[\"myfunction\"]()\n<\/code><\/pre>\n\n<p>or<\/p>\n\n<pre><code>globals()[\"myfunction\"]()\n<\/code><\/pre>\n\n<p><a href=\"http:\/\/docs.python.org\/library\/functions.html#locals\">locals<\/a> returns a dictionary with a current local symbol table. <a href=\"http:\/\/docs.python.org\/library\/functions.html#globals\">globals<\/a> returns a dictionary with global symbol table.<\/p>\n",
                "<p>Assuming module <code>foo<\/code> with method <code>bar<\/code>:<\/p>\n\n<pre><code>import foo\nmethodToCall = getattr(foo, 'bar')\nresult = methodToCall()\n<\/code><\/pre>\n\n<p>As far as that goes, lines 2 and 3 can be compressed to:<\/p>\n\n<pre><code>result = getattr(foo, 'bar')()\n<\/code><\/pre>\n\n<p>if that makes more sense for your use case.  You can use <code>getattr<\/code> in this fashion on class instance bound methods, module-level methods, class methods... the list goes on.<\/p>\n"
            ]
        },
        {
            "tag": "questao_3976",
            "padroes": [
                "I have a Prolite LED sign that I like to set up to show scrolling search queries from a apache logs and other fun statistics. The problem is, my G5 does not have a serial port, so I have to use a usb to serial dongle. It shows up as \/dev\/cu.usbserial and \/dev\/tty.usbserial . \n\nWhen i do this everything seems to be hunky-dory:\n\nstty -f \/dev\/cu.usbserial\nspeed 9600 baud;\nlflags: -icanon -isig -iexten -echo\niflags: -icrnl -ixon -ixany -imaxbel -brkint\noflags: -opost -onlcr -oxtabs\ncflags: cs8 -parenb\n\n\nEverything also works when I use the serial port tool to talk to it.\n\nIf I run this piece of code while the above mentioned serial port tool, everthing also works. But as soon as I disconnect the tool the connection gets lost. \n\n#!\/usr\/bin\/python\n\nimport serial\n\nser = serial.Serial('\/dev\/cu.usbserial', 9600, timeout=10) \nser.write(\" \\r\\n\") \nread_chars = ser.read(20)\nprint read_chars\n\nser.close()\n\n\nSo the question is, what magicks do I need to perform to start talking to the serial port without the serial port tool? Is that a permissions problem? Also, what's the difference between \/dev\/cu.usbserial and \/dev\/tty.usbserial?\n\n\n\nNope, no serial numbers. The thing is, the problem persists even with sudo-running the python script, and the only thing that makes it go through if I open the connection in the gui tool that I mentioned.\n"
            ],
            "respostas": [
                "<p>have you tried watching the traffic between the GUI and the serial port to see if there is some kind of special command being sent across?  Also just curious, Python is sending ASCII and not UTF-8 or something else right?  The reason I ask is because I noticed your quote changes for the strings and in some languages that actually is the difference between ASCII and UTF-8.<\/p>\n",
                "<p><code>\/dev\/cu.xxxxx<\/code> is the \"callout\" device, it's what you use when you establish a connection to the serial device and start talking to it. <code>\/dev\/tty.xxxxx<\/code> is the \"dialin\" device, used for monitoring a port for incoming calls for e.g. a fax listener.<\/p>"
            ]
        },
        {
            "tag": "questao_4942",
            "padroes": [
                "When asked to create system XYZ and you ask to do it in Python over PHP or Ruby, what are the main features you can mention when they require you to explain it?"
            ],
            "respostas": [
                "<p>I agree with mreggen. Tell them by working in Python you can get things done faster. Getting things done faster possibly means money saved by the client. In the least it means that you are working with a language you a more comfortable in, meaning faster development, debugging, and refactoring time. There will be less time spent looking up documentation on what function to use to find the length of a string, etc. <\/p>\n",
                "<p>Give them a snippet of code in each (no more than a page) that performs some cool function that they will like. (e.g show outliers in a data set).<\/p>\n\n<p>Show them each page. One in PHP, Ruby and Python.<\/p>\n\n<p>Ask them which they find easiest to understand\/read.<\/p>\n\n<p>Tell them thats why you want to use Python. It's easier to read if you've not written it, more manageable, less buggy and quicker to build features because it is the most elegant (pythonic)<\/p>\n",
                "<p>Though <em>All 3 languages are versatile and used worldwide by programmers<\/em>, Python still have some advantages over the other two. Like From my personal experience :-<\/p>\n\n<blockquote>\n  <ol>\n  <li>Non-programmers love it (most of 'em choose Python as their first computer language,check this infographic <a href=\"https:\/\/blog.udemy.com\/wp-content\/uploads\/2012\/01\/PROGRAMMING-LANGUAGE-3.png\" rel=\"nofollow\">php vs python vs ruby<\/a> here)<\/li>\n  <li>Multiple frameworks (You can automate your system tasks, can develop apps for web and windows\/mac\/android OSes)<\/li>\n  <li>Making OpenCV apps easily than MATLAB <\/li>\n  <li>Testing done easy (you can work on Selenium for all kind of web testing)<\/li>\n  <\/ol>\n<\/blockquote>\n\n<p>OOPS concepts are followed by most languages now , so how come Python can stay behind! Inheritance, Abstraction and Encapsulation are followed by Python as well.<\/p>\n\n<p>Python as of now is divided into two versions popularly that are not much different in terms of performance but features. <strong>Python2.x and Python 3.x<\/strong> both have same syntax ,except for some statements like :-<\/p>\n\n<ol>\n<li><strong>print \"...\"<\/strong> in Python2.x and <strong>print()<\/strong> in Python3.x<\/li>\n<li><strong>raw_input()<\/strong> in Python2.x and <strong>input()<\/strong> in Python3.x (<em>for getting user input<\/em>)<\/li>\n<\/ol>\n\n<p>In the end, client only cares about money and Python helps you save a lot as compared to PHP and Ruby , because instead of hiring experienced programmers , you can make a newbie learn and use Python expertly.<\/p>\n",
                "<p>Focus on the shorter time needed for development\/prototype and possibly easier maintenance (none of this may apply against Ruby).<\/p>",
                "<p>I would consider that using python on a new project is completely dependent on what problem you are trying to solve with python.  If you want someone to agree with you that you should use python, then show them how python's features apply specifically to that problem.<\/p>\r\n\r\n<p>In the case of web development with python, talk about WSGI and other web libraries and frameworks you could use that would make your life easier.  One note for python is that most of the frameworks for python web development can be plugged right into any current project. With ruby on rails, you're practically working in a DSL that anyone who uses your project will have to learn.  If they know python, then they can figure out what you are doing with django, etc in a day.<\/p>\r\n\r\n<p>I'm only talking about web development because it appears that's what you are going to be working on seeing ruby, python and PHP in the same list.  The real message that's important is applying to whatever it is you like about python <em>directly<\/em> to some problem you are trying to solve.<\/p>",
                "<p>It's one of the preferred languages over at Google - It's several years ahead of Ruby in terms of \"maturity\" (what ever that really means - but managers like that). Since it's prefered by Google you can also run it on the Google App Engine.<\/p>\n\n<p>Mircosoft is also embracing Python, and will have a v2.0 of IronPython coming out shortly. They are working on a Ruby implementation as well, but the Python version is way ahead, and is actually \"ready for primetime\". That give you the possibility for easy integration with .NET code, as well as being able to write client side RIAs in Python when Silverlight 2 ships.<\/p>\n",
                "<p>The best sell of Python I've ever seen was by a manager in our group who had a young daughter.  He used a quote attributed to Einstein:<\/p>\n\n<blockquote>\n  <p>If you can't explain something to a six-year-old, you really don't understand it yourself.<\/p>\n<\/blockquote>\n\n<p>The next few slides of his presentation demonstrated how he was able to teach his young daughter some basic Python in less than 30 minutes, with examples of the code she wrote and an explanation of what it did.<\/p>\n\n<p>He ended the presentation with a picture of his daughter and her quote \"Programming is fun!\"<\/p>\n\n<p>I would focus on Python's user friendliness and wealth of libraries and frameworks.  There are also a lot of little libraries that you might not get in other languages, and would have to write yourself (i.e. <a href=\"http:\/\/blog.programmerslog.com\/?p=124\">How a C++ developer writes Python<\/a>).<\/p>\n\n<p>Good luck!<\/p>\n",
                "<p>This is one of those cases that really boil down to personal preference or situational details. If you're more comfortable and experienced with Python, then say so. Are they asking you to justify it because they're more comfortable with one of the other environments? After you're done, will the system be passed off to someone else for long-term maintenance?<\/p>\r\n\r\n<p>If they ask you to use a technology or language that you're not as familiar with, then make sure they know up-front that it's going to take you longer.<\/p>"
            ]
        },
        {
            "tag": "questao_5102",
            "padroes": [
                "I tried to follow a couple of googled up tutorials on setting up mod_python, but failed every time. Do you have a good, step-by step, rock-solid howto?\r\n\r\nMy dev box is OS X, production - Centos."
            ],
            "respostas": [
                "<p>The problem for me wasn't in Apache set up, but in understanding how mod_apache actually uses the .py files. Module-level statements (including those in a <code>if __name__=='__main__'<\/code> section) are <em>not<\/em> executed--I assumed that the stdout from running the script at the commandline would be what the server would output, but that's not how it works.<\/p>\n\n<p>Instead, I wrote a module-level function called <code>index()<\/code>, and had it return as a string the HTML of the page. It's also possible to have other module-level functions (e.g., <code>otherFunction()<\/code>) that can be accessed as further segments in the URI (e.g., <code>testScript\/otherFunction<\/code> for the file <code>testScript.py<\/code>.)<\/p>\n\n<p>Obviously, this makes more sense than my original stdout conception. Better capability of actually using Python as a scripting language and not a humongous markup language.<\/p>\n",
                "<p>Are you running Python on UNIX or Windows?<\/p>\n\n<p>An alternative to mod_python and FastCGI is mod_wsgi. You can find out more at <a href=\"http:\/\/code.google.com\/p\/modwsgi\/\" rel=\"nofollow\">modwsgi<\/a><\/p>\n\n<p>I have built and installed this on Solaris without problems. I had previously tried mod_python but ran into problems with shared libraries as part of the build. There are <a href=\"http:\/\/code.google.com\/p\/modwsgi\/wiki\/InstallationInstructions\" rel=\"nofollow\">good install docs<\/a> available.<\/p>\n",
                "<p>Yes, mod_python is pretty confusing to set up.  Here's how I did it.<\/p>\r\n\r\n<p>In httpd.conf:<\/p>\r\n\r\n<pre><code>LoadModule python_module modules\/mod_python.so<br><br>&lt;Directory \"\/serverbase\/htdocs\/myapp\"&gt;<br>  AddHandler mod_python .py<br>  PythonHandler myapp<br>  PythonDebug On<br><\/code><\/pre>\r\n\r\n<p>and in your application directory:<\/p>\r\n\r\n<pre><code>$ \/serverbase\/htdocs\/myapp$ ls -l<br>total 16<br>-r-xr-xr-x 1 root sys        6484 May 21 15:54 myapp.py<br><\/code><\/pre>\r\n\r\n<p>Repeat the configuration for each python program you wish to have running under mod_python.<\/p>",
                "<p>There are two main ways of running Python on Apache. The simplest would be to use CGI and write normal Python scripts while the second is using a web framework like Django or Pylons.<\/p>\n\n<p>Using CGI is straightforward. Make sure your Apache config file has a cgi-bin set up. If not, follow their documentation (<a href=\"http:\/\/httpd.apache.org\/docs\/2.0\/howto\/cgi.html\" rel=\"nofollow\">http:\/\/httpd.apache.org\/docs\/2.0\/howto\/cgi.html<\/a>). At that point all you need to do is place your Python scripts in the cgi-bin directory and the standard output will become the HTTP response. Refer to Python's documentation for further info (<a href=\"https:\/\/docs.python.org\/library\/cgi.html\" rel=\"nofollow\">https:\/\/docs.python.org\/library\/cgi.html<\/a>).<\/p>\n\n<p>If you want to use a web framework you'll need to setup mod_python or FastCGI. These steps are dependent on which framework you want to use. Django provides clear instructions on how to setup mod_python and Django with Apache (<a href=\"http:\/\/www.djangoproject.com\/documentation\/modpython\/\" rel=\"nofollow\">http:\/\/www.djangoproject.com\/documentation\/modpython\/<\/a>)<\/p>\n"
            ]
        },
        {
            "tag": "questao_5136",
            "padroes": [
                "A researcher has created a small simulation in MATLAB, and we want to make it accessible to others. My plan is to take the simulation, clean up a few things, and turn it into a set of functions. Then, I plan to compile it into a C library and use SWIG to create a Python wrapper. At that point, I should be able to call the simulation from a small Django app. At least, I hope so.\r\n\r\nDo I have the right plan? Has anyone else done something similar? Can you let me know if there are some serious pitfalls I'm not aware of at the moment?"
            ],
            "respostas": [
                "<p>Perhaps try <a href=\"http:\/\/python.net\/crew\/theller\/ctypes\/\" rel=\"nofollow\">ctypes <\/a>instead of SWIG. If it has been included as a part of Python 2.5, then it must be good :-)<\/p>\n",
                "<p>I'd also try ctypes first. <\/p>\n\n<ol>\n<li>Use the Matlab compiler to compile the code into C. <\/li>\n<li>Compile the C code into a DLL.<\/li>\n<li>Use ctypes to load and call code from this DLL<\/li>\n<\/ol>\n\n<p>The hardest step is probably 1, but if you already know Matlab and have used the Matlab compiler, you should not have serious problems with it.<\/p>\n",
                "<p>I won't help much but I remember that I was able to wrap MATLAB simulation into DLL and then call it from Delphi app. It work really well.<\/p>\r\n\r\n<p>Anyway: good luck!!!<\/p>",
                "<p>One thing to remember is that the Matlab compiler does not actually compile the Matlab code into native machine instructions.  It simply wraps it into a standalone executable or a library with its own runtime engine that runs it.  You would be able to run your code without Matlab installed, and you would be able to interface it with other languages, but it will still be interpreted Matlab code, so there would be no speedup.<\/p>\n"
            ]
        },
        {
            "tag": "questao_5313",
            "padroes": [
                "I learned Swing back in the day but now I've moved to Python and want to make some apps with GUIs. I haven't had the time to learn a new GUI API so I've been using Jython, but I would prefer to use CPython. \r\n\r\nIt would be great if I can have one simple markup that allows me to switch GUI libraries. It would be even better if I can use the same markup language across languages so I can quickly make GUIs for any language I'm using. Does anyone know of such a markup\/library?\r\n\r\nI've seen markups like Glade and wxWidget's markup (I forget the name). They're partly what I'm looking for (making a GUI without coding it in a language) but they're intertwined with a specific library. And neither are really nice looking or friendly to human editting."
            ],
            "respostas": [
                "<p>I read a little on XML User Interface Language (XUL) and it looks really robust and well supported. The main problem for me is it's tied to the Gecko rendering engine so it's cross platform the way wxWidgets, QT and GTK+ are cross platform. Also, there Python bindings don't seem as good as those other libraries.<\/p>\n\n<p>GladeXML and XRC seem like better markups<\/p>\n",
                "<p>I would go with XSLT, therefore it could be embedded in other interfaces as well.<\/p>\n",
                "<p>If you switch to .NET then you can use a common GUI language, for example Razor in MVC (if you are doing web development), and have a choice of C# or VB or a number of other languages.<\/p>\n",
                "<p>@Cristian and Antony Cramp: while XUL is a nice choice for UI development (cross-platform, open-source licensed, used in Firefox and other major software), it's certainly not language agnostic. You're tied to Gecko, with JS for scripting. There is experimental support for Python scripting, but it's only experimental, AFAIK.<\/p>\n\n<p>You can define the UI in XUL+JS and use back-end components written in C++ though (there are Python and Java bridges available too).<\/p>\n",
                "<p>The <a href=\"http:\/\/www.wxwidgets.org\/\" rel=\"nofollow\" title=\"wxWidgets\">wxWidgets<\/a> (formerly known as wxWindows) library might be what you're looking for. There's a particularly good port for Python, <a href=\"http:\/\/wxpython.org\/\" rel=\"nofollow\" title=\"wxPython\">wxPython<\/a>, as well as versions for different languages -- C#, C++, Perl and Ruby come to mind -- and for various GUIs: Win32, Mac OS X, GTK+, X11, Motif, WinCE. The library's been around for a while and is pretty solid.<\/p>",
                "<P>Not sure if this is what you're looking for, but there's <A href=\"http:\/\/glade.gnome.org\/\" rel=\"nofollow\">Glade<\/A> (or <A href=\"http:\/\/gladewin32.sourceforge.net\/\" rel=\"nofollow\">Windows download<\/A>) which is a designer for GTK+. It generates an XML file which can then be used to build the GUI in a number of different languages.<\/P>",
                "<p><a href=\"http:\/\/www.mozilla.org\/projects\/xul\/\" rel=\"nofollow\">XML User Interface Language<\/a>. Don't know much about it so not sure if it meets your desires. Post back with your experience if you play with it.<\/p>",
                "<p>I seriously doubt you're going to find a markup language for GIU's that's <em>not<\/em> tied to a specific library.  For such a thing to exist, there would need to be a standardized GUI markup language, with several implementations.<\/p>\n",
                "<p><a href=\"http:\/\/en.wikipedia.org\/wiki\/Qt_%28toolkit%29\">Qt<\/a> (pronounced \"cute\" by its creators[1]) is a cross-platform application development framework, widely used for the development of GUI programs.<\/p>\r\n\r\n<p>Qt uses <strong>C++<\/strong> with several non-standard extensions implemented by an additional pre-processor that generates standard C++ code before compilation. Qt can also be used in several other programming languages; bindings exist for <strong>Ada<\/strong> (QtAda)[4], C<strong>#<\/strong> (Qyoto\/Kimono)[5], <strong>Java<\/strong> (Qt Jambi)[6], <strong>Pascal<\/strong>, <strong>Perl<\/strong>, <strong>PHP<\/strong> (PHP-Qt), <strong>Ruby<\/strong> (RubyQt), and <strong>Python<\/strong> (PyQt). It runs on all major platforms, and has extensive internationalization support. Non-GUI features include SQL database access, XML parsing, thread management, network support and a unified cross-platform API for file handling.<\/p>",
                "<p>erm.. HTML? (trying to be funny here... while we wait for real answers..)<\/p>"
            ]
        },
        {
            "tag": "questao_5419",
            "padroes": [
                "When I try to print a Unicode string in a Windows console, I get a UnicodeEncodeError: 'charmap' codec can't encode character .... error.  I assume this is because the Windows console does not accept Unicode-only characters. What's the best way around this? Is there any way I can make Python automatically print a ? instead of failing in this situation?\n\nEdit:  I'm using Python 2.5.\n\n\n\nNote: @LasseV.Karlsen answer with the checkmark is sort of outdated (from 2008). Please use the solutions\/answers\/suggestions below with care!!\n\n@JFSebastian answer is more relevant as of today (6 Jan 2016).\n"
            ],
            "respostas": [
                "<p>The cause of your problem is <strong>NOT<\/strong> the Win console not willing to accept Unicode (as it does this since I guess Win2k by default). It is the default system encoding. Try this code and see what it gives you:<\/p>\n\n<pre><code>import sys\nsys.getdefaultencoding()\n<\/code><\/pre>\n\n<p>if it says ascii, there's your cause ;-)\nYou have to create a file called sitecustomize.py and put it under python path (I put it under \/usr\/lib\/python2.5\/site-packages, but that is differen on Win - it is c:\\python\\lib\\site-packages or something), with the following contents:<\/p>\n\n<pre><code>import sys\nsys.setdefaultencoding('utf-8')\n<\/code><\/pre>\n\n<p>and perhaps you might want to specify the encoding in your files as well:<\/p>\n\n<pre><code># -*- coding: UTF-8 -*-\nimport sys,time\n<\/code><\/pre>\n\n<p>Edit: more info can be found <a href=\"http:\/\/www.diveintopython.net\/xml_processing\/unicode.html\" rel=\"nofollow\">in excellent the Dive into Python book<\/a><\/p>\n",
                "<p>Kind of related on the answer by J. F. Sebastian, but more direct.<\/p>\n\n<p>If you are having this problem when printing to the console\/terminal, then do this:<\/p>\n\n<pre><code>&gt;set PYTHONIOENCODING=UTF-8\n<\/code><\/pre>\n",
                "<p>James Sulak asked,<\/p>\n\n<blockquote>\n  <p>Is there any way I can make Python automatically print a ? instead of failing in this situation?<\/p>\n<\/blockquote>\n\n<p>Other solutions recommend we attempt to modify the Windows environment or replace Python's <code>print()<\/code> function.  The answer below comes closer to fulfilling Sulak's request.<\/p>\n\n<p>Under Windows 7, Python 3.5 can be made to print Unicode without throwing a <code>UnicodeEncodeError<\/code> as follows:<\/p>\n\n<p>&nbsp; &nbsp; In place of:\n&nbsp; &nbsp;<code>print(text)<\/code><br>\n&nbsp; &nbsp; substitute:\n&nbsp; &nbsp; <code>print(str(text).encode('utf-8'))<\/code><\/p>\n\n<p>Instead of throwing an exception, Python now displays unprintable Unicode characters as <em>\\xNN<\/em> hex codes, e.g.:<\/p>\n\n<p>&nbsp; <em>Halmalo n\\xe2\\x80\\x99\\xc3\\xa9tait plus qu\\xe2\\x80\\x99un point noir<\/em><\/p>\n\n<p>Instead of<\/p>\n\n<p>&nbsp; <em>Halmalo nÃÃÃ+Â®tait plus quÃÃÃun point noir<\/em><\/p>\n\n<p>Granted, the latter is preferable <em>ceteris paribus<\/em>, but otherwise the former is completely accurate for diagnostic messages.  Because it displays Unicode as literal byte values the former may also assist in diagnosing encode\/decode problems.<\/p>\n\n<p><strong>Note:<\/strong> The <code>str()<\/code> call above is needed because otherwise <code>encode()<\/code> causes Python to reject a Unicode character as a tuple of numbers.<\/p>\n",
                "<p>Like Giampaolo Rodol+Ã¡'s answer, but even more dirty: I really, really intend to spend a long time (soon) understanding the whole subject of encodings and how they apply to Windoze consoles, <\/p>\n\n<p>For the moment I just wanted sthg which would mean my program would NOT CRASH, and which I understood ... and also which didn't involve importing too many exotic modules (in particular I'm using Jython, so half the time a Python module turns out not in fact to be available).<\/p>\n\n<pre><code>def pr(s):\n    try:\n        print(s)\n    except UnicodeEncodeError:\n        for c in s:\n            try:\n                print( c, end='')\n            except UnicodeEncodeError:\n                print( '?', end='')\n<\/code><\/pre>\n\n<p>NB \"pr\" is shorter to type than \"print\" (and quite a bit shorter to type than \"safeprint\")...!<\/p>\n",
                "<p>The below code will make Python output to console as UTF-8 even on Windows. <\/p>\n\n<p>The console will display the characters well on Windows 7 but on Windows XP it will not display them well, but at least it will work and most important you will have a consistent output from your script on all platforms. You'll be able to redirect the output to a file.<\/p>\n\n<p>Below code was tested with Python 2.6 on Windows.<\/p>\n\n<pre><code>\n#!\/usr\/bin\/python\n# -*- coding: UTF-8 -*-\n\nimport codecs, sys\n\nreload(sys)\nsys.setdefaultencoding('utf-8')\n\nprint sys.getdefaultencoding()\n\nif sys.platform == 'win32':\n    try:\n        import win32console \n    except:\n        print \"Python Win32 Extensions module is required.\\n You can download it from https:\/\/sourceforge.net\/projects\/pywin32\/ (x86 and x64 builds are available)\\n\"\n        exit(-1)\n    # win32console implementation  of SetConsoleCP does not return a value\n    # CP_UTF8 = 65001\n    win32console.SetConsoleCP(65001)\n    if (win32console.GetConsoleCP() != 65001):\n        raise Exception (\"Cannot set console codepage to 65001 (UTF-8)\")\n    win32console.SetConsoleOutputCP(65001)\n    if (win32console.GetConsoleOutputCP() != 65001):\n        raise Exception (\"Cannot set console output codepage to 65001 (UTF-8)\")\n\n#import sys, codecs\nsys.stdout = codecs.getwriter('utf8')(sys.stdout)\nsys.stderr = codecs.getwriter('utf8')(sys.stderr)\n\nprint \"This is an Ã°Ã²ÃµÂ¦Ã©+Â¦mp+Ã­+Ã  testing Unicode support using Arabic, Latin, Cyrillic, Greek, Hebrew and CJK code points.\\n\"\n<\/code><\/pre>\n",
                "<p>If you're not interested in getting a reliable representation of the bad character(s) you might use something like this (working with python >= 2.6, including 3.x):<\/p>\n\n<pre><code>from __future__ import print_function\nimport sys\n\ndef safeprint(s):\n    try:\n        print(s)\n    except UnicodeEncodeError:\n        if sys.version_info &gt;= (3,):\n            print(s.encode('utf8').decode(sys.stdout.encoding))\n        else:\n            print(s.encode('utf8'))\n\nsafeprint(u\"\\N{EM DASH\")\n<\/code><\/pre>\n\n<p>The bad character(s) in the string will be converted in a representation which is printable by the Windows console.<\/p>\n",
                "<p><strong>Update:<\/strong> <a href=\"https:\/\/docs.python.org\/3.6\/whatsnew\/3.6.html#pep-528-change-windows-console-encoding-to-utf-8\" rel=\"nofollow\">Python 3.6<\/a> implements <a href=\"https:\/\/www.python.org\/dev\/peps\/pep-0528\/\" rel=\"nofollow\">PEP 528: Change Windows console encoding to UTF-8<\/a>: <em>the default console on Windows will now accept all Unicode characters.<\/em> Internally, it uses the same Unicode API as <a href=\"https:\/\/github.com\/Drekin\/win-unicode-console\" rel=\"nofollow\">the <code>win-unicode-console<\/code> package mentioned below<\/a>. <code>print(unicode_string)<\/code> should just work now.<\/p>\n\n<hr>\n\n<blockquote>\n  <p>I get a <code>UnicodeEncodeError: 'charmap' codec can't encode character...<\/code>  error. <\/p>\n<\/blockquote>\n\n<p>The error means that Unicode characters that you are trying to print can't be represented using the current (<code>chcp<\/code>) console character encoding. The codepage is often 8-bit encoding such as <code>cp437<\/code> that can represent only ~0x100 characters from ~1M Unicode characters:<\/p>\n\n<pre>>>> u\"\\N{EURO SIGN\".encode('cp437')\nTraceback (most recent call last):\n...\nUnicodeEncodeError: 'charmap' codec can't encode character '\\u20ac' in position 0:\ncharacter maps to <\/pre>\n\n<blockquote>\n  <p>I assume this is because the Windows console does not accept Unicode-only characters. What's the best way around this? <\/p>\n<\/blockquote>\n\n<p>Windows console does accept Unicode characters and it can even display them (BMP only) <strong>if the corresponding font is configured<\/strong>. <code>WriteConsoleW()<\/code> API should be used as suggested in <a href=\"http:\/\/stackoverflow.com\/a\/4637795\/4279\">@Daira Hopwood's answer<\/a>. It can be called transparently i.e., you don't need to and should not modify your scripts if you use <a href=\"https:\/\/github.com\/Drekin\/win-unicode-console\" rel=\"nofollow\"><code>win-unicode-console<\/code> package<\/a>:<\/p>\n\n<pre><code>T:\\&gt; py -mpip install win-unicode-console\nT:\\&gt; py -mrun your_script.py\n<\/code><\/pre>\n\n<p>See <a href=\"http:\/\/stackoverflow.com\/a\/30551552\/4279\">What's the deal with Python 3.4, Unicode, different languages and Windows?<\/a><\/p>\n\n<blockquote>\n  <p>Is there any way I can make Python\n  automatically print a <code>?<\/code> instead of failing in this situation?<\/p>\n<\/blockquote>\n\n<p>If it is enough to replace all unencodable characters with <code>?<\/code> in your case then you could set <a href=\"https:\/\/docs.python.org\/3\/using\/cmdline.html#envvar-PYTHONIOENCODING\" rel=\"nofollow\"><code>PYTHONIOENCODING<\/code> envvar<\/a>:<\/p>\n\n<pre><code>T:\\&gt; set PYTHONIOENCODING=:replace\nT:\\&gt; python3 -c \"print(u'[\\N{EURO SIGN]')\"\n[?]\n<\/code><\/pre>\n\n<p>In Python 3.6+, the encoding specified by <code>PYTHONIOENCODING<\/code> envvar is ignored for interactive console buffers unless <code>PYTHONLEGACYWINDOWSIOENCODING<\/code> envvar is set to a non-empty string. <\/p>\n",
                "<p>Despite the other plausible-sounding answers that suggest changing the code page to 65001, that <a href=\"http:\/\/bugs.python.org\/issue1602\">does not work<\/a>. (Also, changing the default encoding using <code>sys.setdefaultencoding<\/code> is <a href=\"http:\/\/stackoverflow.com\/questions\/3578685\/how-to-display-utf-8-in-windows-console\/3580165#3580165\">not a good idea<\/a>.)<\/p>\n\n<p>See <a href=\"http:\/\/stackoverflow.com\/questions\/878972\/windows-cmd-encoding-change-causes-python-crash\/3259271\">this question<\/a> for details and code that does work.<\/p>\n",
                "<p><strong>Note:<\/strong> This answer is sort of outdated (from 2008). Please use the solution below with care!!<\/p>\n\n<hr>\n\n<p>Here is a page that details the problem and a solution (search the page for the text <em>Wrapping sys.stdout into an instance<\/em>):<\/p>\n\n<p><a href=\"http:\/\/wiki.python.org\/moin\/PrintFails\">PrintFails - Python Wiki<\/a><\/p>\n\n<p>Here's a code excerpt from that page:<\/p>\n\n<pre><code>$ python -c 'import sys, codecs, locale; print sys.stdout.encoding; \\\n    sys.stdout = codecs.getwriter(locale.getpreferredencoding())(sys.stdout); \\\n    line = u\"\\u0411\\n\"; print type(line), len(line); \\\n    sys.stdout.write(line); print line'\n  UTF-8\n  &lt;type 'unicode'&gt; 2\n  Ã°Ã¦\n  Ã°Ã¦\n\n  $ python -c 'import sys, codecs, locale; print sys.stdout.encoding; \\\n    sys.stdout = codecs.getwriter(locale.getpreferredencoding())(sys.stdout); \\\n    line = u\"\\u0411\\n\"; print type(line), len(line); \\\n    sys.stdout.write(line); print line' | cat\n  None\n  &lt;type 'unicode'&gt; 2\n  Ã°Ã¦\n  Ã°Ã¦\n<\/code><\/pre>\n\n<p>There's some more information on that page, well worth a read.<\/p>\n"
            ]
        },
        {
            "tag": "questao_5415",
            "padroes": [
                "I have a binary file that I have to parse and I'm using Python. Is there a way to take 4 bytes and convert it to a single precision floating point number?"
            ],
            "respostas": [
                "<p>You'll want the <a href=\"https:\/\/docs.python.org\/3.4\/library\/struct.html\" rel=\"nofollow\">struct<\/a> package.<\/p>\n",
                "<pre><code>&gt;&gt;&gt; import struct\n&gt;&gt;&gt; struct.pack('f', 3.141592654)\nb'\\xdb\\x0fI@'\n&gt;&gt;&gt; struct.unpack('f', b'\\xdb\\x0fI@')\n(3.1415927410125732,)\n&gt;&gt;&gt; struct.pack('4f', 1.0, 2.0, 3.0, 4.0)\n'\\x00\\x00\\x80?\\x00\\x00\\x00@\\x00\\x00@@\\x00\\x00\\x80@'\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_5909",
            "padroes": [
                "I'm downloading an entire directory from a web server. It works OK, but I can't figure how to get the file size before download to compare if it was updated on the server or not. Can this be done as if I was downloading the file from a FTP server?\n\nimport urllib\nimport re\n\nurl = \"http:\/\/www.someurl.com\"\n\n# Download the page locally\nf = urllib.urlopen(url)\nhtml = f.read()\nf.close()\n\nf = open (\"temp.htm\", \"w\")\nf.write (html)\nf.close()\n\n# List only the .TXT \/ .ZIP files\nfnames = re.findall('^.*\n\n\n\n@Jon: thank for your quick answer. It works, but the filesize on the web server is slightly less than the filesize of the downloaded file. \n\nExamples:\n\nLocal Size  Server Size\n 2.223.533  2.115.516\n   664.603    662.121\n\n\nIt has anything to do with the CR\/LF conversion?\n"
            ],
            "respostas": [
                "<p>In Python3:<\/p>\n\n<pre><code>&gt;&gt;&gt; import urllib.request\n&gt;&gt;&gt; site = urllib.request.urlopen(\"http:\/\/python.org\")\n&gt;&gt;&gt; print(\"FileSize: \", site.length)\n<\/code><\/pre>\n",
                "<p>Also if the server you are connecting to supports it, look at <a href=\"http:\/\/en.wikipedia.org\/wiki\/HTTP_ETag\" rel=\"nofollow\">Etags<\/a> and the <a href=\"http:\/\/en.wikipedia.org\/wiki\/List_of_HTTP_headers#Requests\" rel=\"nofollow\">If-Modified-Since<\/a> and <a href=\"http:\/\/en.wikipedia.org\/wiki\/List_of_HTTP_headers#Requests\" rel=\"nofollow\">If-None-Match<\/a> headers.<\/p>\r\n\r\n<p>Using these will take advantage of the webserver's caching rules and will return a <a href=\"http:\/\/en.wikipedia.org\/wiki\/List_of_HTTP_status_codes#3xx_Redirection\" rel=\"nofollow\">304 Not Modified<\/a> status code if the content hasn't changed.<\/p>",
                "<p>The size of the file is sent as the Content-Length header. Here is how to get it with urllib:<\/p>\r\n\r\n<pre><code>&gt;&gt;&gt; site = urllib.urlopen(\"http:\/\/python.org\")<br>&gt;&gt;&gt; meta = site.info()<br>&gt;&gt;&gt; print meta.getheaders(\"Content-Length\")<br>['16535']<br>&gt;&gt;&gt;<br><\/code><\/pre>",
                "<p>Using the returned-urllib-object method <code>info()<\/code>, you can get various information on the retrived document. Example of grabbing the current Google logo:<\/p>\r\n\r\n<pre><code>&gt;&gt;&gt; import urllib<br>&gt;&gt;&gt; d = urllib.urlopen(\"http:\/\/www.google.co.uk\/logos\/olympics08_opening.gif\")<br>&gt;&gt;&gt; print d.info()<br><br>Content-Type: image\/gif<br>Last-Modified: Thu, 07 Aug 2008 16:20:19 GMT  <br>Expires: Sun, 17 Jan 2038 19:14:07 GMT <br>Cache-Control: public <br>Date: Fri, 08 Aug 2008 13:40:41 GMT <br>Server: gws <br>Content-Length: 20172 <br>Connection: Close<br><\/code><\/pre>\r\n\r\n<p>It's a dict, so to get the size of the file, you do <code>urllibobject.info()['Content-Length']<\/code><\/p>\r\n\r\n<pre><code>print f.info()['Content-Length']<br><\/code><\/pre>\r\n\r\n<p>And to get the size of the local file (for comparison), you can use the os.stat() command:<\/p>\r\n\r\n<pre><code>os.stat(\"\/the\/local\/file.zip\").st_size<br><\/code><\/pre>",
                "<p>I have reproduced what you are seeing:<\/p>\r\n\r\n<pre><code>import urllib, os<br>link = \"http:\/\/python.org\"<br>print \"opening url:\", link<br>site = urllib.urlopen(link)<br>meta = site.info()<br>print \"Content-Length:\", meta.getheaders(\"Content-Length\")[0]<br><br>f = open(\"out.txt\", \"r\")<br>print \"File on disk:\",len(f.read())<br>f.close()<br><br><br>f = open(\"out.txt\", \"w\")<br>f.write(site.read())<br>site.close()<br>f.close()<br><br>f = open(\"out.txt\", \"r\")<br>print \"File on disk after download:\",len(f.read())<br>f.close()<br><br>print \"os.stat().st_size returns:\", os.stat(\"out.txt\").st_size<br><\/code><\/pre>\r\n\r\n<p>Outputs this:<\/p>\r\n\r\n<pre><code>opening url: http:\/\/python.org<br>Content-Length: 16535<br>File on disk: 16535<br>File on disk after download: 16535<br>os.stat().st_size returns: 16861<br><\/code><\/pre>\r\n\r\n<p>What am I doing wrong here? Is os.stat().st_size not returning the correct size?<\/p>\r\n\r\n<hr>\r\n\r\n<p>Edit:\r\nOK, I figured out what the problem was:<\/p>\r\n\r\n<pre><code>import urllib, os<br>link = \"http:\/\/python.org\"<br>print \"opening url:\", link<br>site = urllib.urlopen(link)<br>meta = site.info()<br>print \"Content-Length:\", meta.getheaders(\"Content-Length\")[0]<br><br>f = open(\"out.txt\", \"rb\")<br>print \"File on disk:\",len(f.read())<br>f.close()<br><br><br>f = open(\"out.txt\", \"wb\")<br>f.write(site.read())<br>site.close()<br>f.close()<br><br>f = open(\"out.txt\", \"rb\")<br>print \"File on disk after download:\",len(f.read())<br>f.close()<br><br>print \"os.stat().st_size returns:\", os.stat(\"out.txt\").st_size<br><\/code><\/pre>\r\n\r\n<p>this outputs:<\/p>\r\n\r\n<pre><code>$ python test.py<br>opening url: http:\/\/python.org<br>Content-Length: 16535<br>File on disk: 16535<br>File on disk after download: 16535<br>os.stat().st_size returns: 16535<br><\/code><\/pre>\r\n\r\n<p>Make sure you are opening both files for binary read\/write.<\/p>\r\n\r\n<pre><code>\/\/ open for binary write<br>open(filename, \"wb\")<br>\/\/ open for binary read<br>open(filename, \"rb\")<br><\/code><\/pre>"
            ]
        },
        {
            "tag": "questao_5966",
            "padroes": [
                "Basically, I've written an API to www.thetvdb.com in Python. The current code can be found here.\r\n\r\nIt grabs data from the API as requested, and has to store the data somehow, and make it available by doing:\r\n\r\nprint tvdbinstance[1][23]['episodename'] # get the name of episode 23 of season 1\r\n\r\n\r\nWhat is the \"best\" way to abstract this data within the Tvdb() class?\r\n\r\nI originally used a extended Dict() that automatically created sub-dicts (so you could do x[1][2][3][4] = \"something\" without having to do if x[1].has_key(2): x[1][2] = [] and so on)\r\n\r\nThen I just stored the data by doing self.data[show_id][season_number][episode_number][attribute_name] = \"something\"\r\n\r\nThis worked okay, but there was no easy way of checking if x[3][24] was supposed to exist or not (so I couldn't raise the season_not_found exception)\r\n\r\nCurrently it's using four classes. ShowContainer, Show, Season and Episode. Each one is a very basic dict, which I can easily add extra functionality in (the search() function on Show() for example). Each has a __setitem__, __getitem_ and has_key\r\n\r\nThis works mostly fine, I can check in Shows if it has that season in it's self.data dict, if not, raise season_not_found. Check in Season() if it has that episode and so on.\r\n\r\nThe problem now is it's presenting itself as a dict, but doesn't have all the functionality, and because I'm overriding the _getitem_ and _setitem_ functions, it's easy to accidently recursively call _getitem_ (so I'm not sure if extending the Dict class will cause problems)\r\n\r\nThe other slight problem is adding data into the dict is a lot more work than the old Ddict method (which was self.data[seas_no][ep_no]['attribute'] = 'something'). See _setItem and _setData. It's not too bad, since it's currently only a read-only API interface (so the users of the API should only ever retrieve data, not add more), but it's hardly.. elegant..\r\n\r\nI think the series-of-classes system is probably the best way, but does anyone have a better idea for storing the data? And would extending the ShowContainer\/etc classes with Dict cause problems?"
            ],
            "respostas": [
                "<P>I have done something similar in the past and used an in-memory XML document as a quick and dirty hierachical database for storage. You can store each show\/season\/episode as an element (nested appropriately) and attributes of these things as xml attributes on the elements. Then you can use XQuery to get info back out.<\/P>\r\n<P><STRONG>NOTE:<\/STRONG> I'm not a Python guy so I don't know what your xml support is like.<\/P>\r\n<P><STRONG>NOTE 2:<\/STRONG> You'll want to profile this because it'll be bigger and slower than the solution you've already got. Likely enough if you are doing some high-volume processing then XML is probably not going to be your friend.<\/P>",
                "<p>I don't get this part here:<\/p>\n\n<blockquote>\n  <p>This worked okay, but there was no easy way of checking if x[3][24] was supposed to exist or not (so I couldn't raise the season<em>not<\/em>found exception)<\/p>\n<\/blockquote>\n\n<p>There is a way to do it - called <strong>in<\/strong>:<\/p>\n\n<pre><code>&gt;&gt;&gt;x={\n&gt;&gt;&gt;x[1]={\n&gt;&gt;&gt;x[1][2]={\n&gt;&gt;&gt;x\n{1: {2: {\n&gt;&gt;&gt; 2 in x[1]\nTrue\n&gt;&gt;&gt; 3 in x[1]\nFalse\n<\/code><\/pre>\n\n<p>what seems to be the problem with that?<\/p>\n",
                "<p>Bartosz\/To clarify \"This worked okay, but there was no easy way of checking if x[3][24] was supposed to exist or not\"<\/p>\n\n<p><code>x['some show'][3][24]<\/code> would return season 3, episode 24 of \"some show\". If there was no season 3, I want the pseudo-dict to raise tvdb<em>seasonnotfound, if \"some show\" doesn't exist, then raise tvdb<\/em>shownotfound<\/p>\n\n<p>The current system of a series of classes, each with a <code>__getitem__<\/code> - Show checks <code>if self.seasons.has_key(requested_season_number)<\/code>, the Season class checks <code>if self.episodes.has_key(requested_episode_number)<\/code> and so on.<\/p>\n\n<p>It works, but it there seems to be a lot of repeated code (each class is basically the same, but raises a different error)<\/p>\n",
                "<p>Why not use SQLite? There is good support in Python and you can write SQL queries to get the data out. Here is the Python docs for <a href=\"http:\/\/docs.python.org\/lib\/module-sqlite3.html\" rel=\"nofollow\">sqlite3<\/a><\/p>\r\n\r\n<hr>\r\n\r\n<p>If you don't want to use SQLite you could do an array of dicts.<\/p>\r\n\r\n<pre><code>episodes = []<br>episodes.append({'season':1, 'episode': 2, 'name':'Something')<br>episodes.append({'season':1, 'episode': 2, 'name':'Something', 'actors':['Billy Bob', 'Sean Penn'])<br><\/code><\/pre>\r\n\r\n<p>That way you add metadata to any record and search it very easily<\/p>\r\n\r\n<pre><code>season_1 = [e for e in episodes if e['season'] == 1]<br>billy_bob = [e for e in episodes if 'actors' in e and 'Billy Bob' in e['actors']]<br><br>for episode in billy_bob:<br>    print \"Billy bob was in Season %s Episode %s\" % (episode['season'], episode['episode'])<br><\/code><\/pre>",
                "<p>OK, what you need is <code>classobj<\/code> from new module. That would allow you to construct exception classes dynamically (<code>classobj<\/code> takes a string as an argument for the class name). <\/p>\n\n<pre><code>import new\nmyexc=new.classobj(\"ExcName\",(Exception,),{)\ni=myexc(\"This is the exc msg!\")\nraise i\n<\/code><\/pre>\n\n<p>this gives you:<\/p>\n\n<pre><code>Traceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n__main__.ExcName: This is the exc msg!\n<\/code><\/pre>\n\n<p>remember that you can always get the class name through:<\/p>\n\n<pre><code>self.__class__.__name__\n<\/code><\/pre>\n\n<p>So, after some string mangling and concatenation, you should be able to obtain appropriate exception class name and construct a class object using that name and then raise that exception.<\/p>\n\n<p>P.S. - you can also raise strings, but this is deprecated.<\/p>\n\n<pre><code>raise(self.__class__.__name__+\"Exception\")\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_8692",
            "padroes": [
                "What is the library? Is there a full implementation? How is the library used? Where is its website?\n"
            ],
            "respostas": [
                "<p><a href=\"http:\/\/pyxml.sourceforge.net\" rel=\"nofollow\" title=\"PyXML\">PyXML<\/a> works well.  <\/p>\n\n<p>You didn't say what platform you're using, however if you're on Ubuntu you can get it with <code>sudo apt-get install python-xml<\/code>.  I'm sure other Linux distros have it as well.  <\/p>\n\n<p>If you're on a Mac, xpath is already installed but not immediately accessible.  You can set <code>PY_USE_XMLPLUS<\/code> in your environment or do it the Python way before you import xml.xpath:<\/p>\n\n<pre><code>if sys.platform.startswith('darwin'):\n    os.environ['PY_USE_XMLPLUS'] = '1'\n<\/code><\/pre>\n\n<p>In the worst case you may have to build it yourself.  This package is no longer maintained but still builds fine and works with modern 2.x Pythons.  Basic docs are <a href=\"http:\/\/pyxml.sourceforge.net\/topics\/howto\/section-XPath.html\" rel=\"nofollow\">here<\/a>.<\/p>\n",
                "<p>Another library is 4Suite: <a href=\"http:\/\/sourceforge.net\/projects\/foursuite\/\" rel=\"nofollow\">http:\/\/sourceforge.net\/projects\/foursuite\/<\/a><\/p>\n\n<p>I do not know how spec-compliant it is. But it has worked very well for my use. It looks abandoned.<\/p>\n",
                "<p>You can use the simple <code>soupparser<\/code> from <code>lxml<\/code><\/p>\n\n<h2>Example:<\/h2>\n\n<pre><code>from lxml.html.soupparser import fromstring\n\ntree = fromstring(\"&lt;a&gt;Find me!&lt;\/a&gt;\")\nprint tree.xpath(\"\/\/a\/text()\")\n<\/code><\/pre>\n",
                "<p>The latest version of <a href=\"http:\/\/effbot.org\/zone\/element-xpath.htm\">elementtree<\/a> supports XPath pretty well.  Not being an XPath expert I can't say for sure if the implementation is full but it has satisfied most of my needs when working in Python.  I've also use lxml and PyXML and I find etree nice because it's a standard module.<\/p>\n\n<p>NOTE: I've since found lxml and for me it's definitely the best XML lib out there for Python.  It does XPath nicely as well (though again perhaps not a full implementation).<\/p>\n",
                "<p>You can use:<\/p>\n\n<p><strong>PyXML<\/strong>:<\/p>\n\n<pre><code>from xml.dom.ext.reader import Sax2\nfrom xml import xpath\ndoc = Sax2.FromXmlFile('foo.xml').documentElement\nfor url in xpath.Evaluate('\/\/@Url', doc):\n  print url.value\n<\/code><\/pre>\n\n<p><strong>libxml2<\/strong>:<\/p>\n\n<pre><code>import libxml2\ndoc = libxml2.parseFile('foo.xml')\nfor url in doc.xpathEval('\/\/@Url'):\n  print url.content\n<\/code><\/pre>\n",
                "<p>Another option is <a href=\"http:\/\/code.google.com\/p\/py-dom-xpath\/\">py-dom-xpath<\/a>, it works seamlessly with minidom and is pure Python so works on appengine.<\/p>\n\n<pre><code>import xpath\nxpath.find('\/\/item', doc)\n<\/code><\/pre>\n",
                "<p>Sounds like an lxml advertisement in here. ;)  ElementTree is included in the std library.  Under 2.6 and below its xpath is pretty weak, but in <a href=\"http:\/\/docs.python.org\/2\/library\/xml.etree.elementtree.html#xpath-support\">2.7 much improved<\/a>:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import xml.etree.ElementTree as ET\nroot = ET.parse(filename)\nresult = ''\n\nfor elem in root.findall('.\/\/child\/grandchild'):\n    # How to make decisions based on attributes even in 2.6:\n    if elem.attrib.get('name') == 'foo':\n        result = elem.text\n        break\n<\/code><\/pre>\n",
                "<p>Use LXML. LXML uses the full power of libxml2 and libxslt, but wraps them in more \"Pythonic\" bindings than the Python bindings that are native to those libraries. As such, it gets the full XPath 1.0 implementation. Native ElemenTree supports a limited subset of XPath, although it may be good enough for your needs.<\/p>\n",
                "<p>The <a href=\"http:\/\/lxml.de\/\">lxml package<\/a> supports xpath.  It seems to work pretty well, although I've had some trouble with the self:: axis.  There's also <a href=\"http:\/\/pypi.python.org\/pypi\/Amara\/1.1.6\">Amara<\/a>, but I haven't used it personally.<\/p>\n",
                "<p><a href=\"http:\/\/xmlsoft.org\/python.html\">libxml2<\/a> has a number of advantages:<\/p>\n\n<ol>\n<li>Compliance to the <a href=\"http:\/\/www.w3.org\/TR\/xpath\">spec<\/a><\/li>\n<li>Active development and a community participation <\/li>\n<li>Speed. This is really a python wrapper around a C implementation. <\/li>\n<li>Ubiquity. The libxml2 library is pervasive and thus well tested.<\/li>\n<\/ol>\n\n<p>Downsides include:<\/p>\n\n<ol>\n<li>Compliance to the <a href=\"http:\/\/www.w3.org\/TR\/xpath\">spec<\/a>. It's strict. Things like default namespace handling are easier in other libraries.<\/li>\n<li>Use of native code. This can be a pain depending on your how your application is distributed \/ deployed. RPMs are available that ease some of this pain.<\/li>\n<li>Manual resource handling. Note in the sample below the calls to freeDoc() and xpathFreeContext(). This is not very Pythonic.<\/li>\n<\/ol>\n\n<p>If you are doing simple path selection, stick with <a href=\"http:\/\/effbot.org\/zone\/element-xpath.htm\">ElementTree<\/a> ( which is included in Python 2.5 ). If you need full spec compliance or raw speed and can cope with the distribution of native code, go with libxml2.<\/p>\n\n<p><strong>Sample of libxml2 XPath Use<\/strong><\/p>\n\n<hr>\n\n<pre><code>import libxml2\n\ndoc = libxml2.parseFile(\"tst.xml\")\nctxt = doc.xpathNewContext()\nres = ctxt.xpathEval(\"\/\/*\")\nif len(res) != 2:\n    print \"xpath query: wrong node set size\"\n    sys.exit(1)\nif res[0].name != \"doc\" or res[1].name != \"foo\":\n    print \"xpath query: wrong node set value\"\n    sys.exit(1)\ndoc.freeDoc()\nctxt.xpathFreeContext()\n<\/code><\/pre>\n\n<p><strong>Sample of ElementTree XPath Use<\/strong><\/p>\n\n<hr>\n\n<pre><code>from elementtree.ElementTree import ElementTree\nmydoc = ElementTree(file='tst.xml')\nfor e in mydoc.findall('\/foo\/bar'):\n    print e.get('title').text<\/code><\/pre>\n\n<hr>\n"
            ]
        },
        {
            "tag": "questao_8948",
            "padroes": [
                "What is the best way to retrieve mp3 metadata in python?  I've seen a couple frameworks out there, but I'm unsure as to which would be the best to use.... Any ideas?\n"
            ],
            "respostas": [
                "<p>If you can use IronPython, there is TagLibSharp.  <a href=\"http:\/\/stackoverflow.com\/questions\/28664\/what-is-the-besta-very-good-meta-data-reader-library#28687\">It can be used from any .NET language<\/a>.<\/p>\n",
                "<p>After some initial research I thought songdetails might fit my use case, but it doesn't handle .m4b files.  Mutagen does.  Note that while some have (reasonably) taken issue with Mutagen's surfacing of format-native keys, that vary from format to format (TIT2 for mp3, title for ogg, \\xa9nam for mp4, Title for WMA etc.), mutagen.File() has a (new?) easy=True parameter that provides EasyMP3\/EasyID3 tags, which have a consistent, albeit limited, set of keys.  I've only done limited testing so far, but the common keys, like album, artist, albumartist, genre, tracknumber, discnumber, etc. are all present and identical for .mb4 and .mp3 files when using easy=True, making it very convenient for my purposes.<\/p>\n",
                "<p>easiest method is <a href=\"https:\/\/github.com\/Ciantic\/songdetails\" rel=\"nofollow\">songdetails<\/a>..<\/p>\n\n<p>for read data<\/p>\n\n<pre><code>import songdetails\nsong = songdetails.scan(\"blah.mp3\")\nif song is not None:\n    print song.artist\n<\/code><\/pre>\n\n<p>similarly for edit<\/p>\n\n<pre><code>import songdetails\nsong = songdetails.scan(\"blah.mp3\")\nif song is not None:\n    song.artist = u\"The Great Blah\"\n    song.save()\n<\/code><\/pre>\n\n<p>Don't forget to add <strong>u<\/strong> before name until you know chinese language.<\/p>\n\n<p>u can read and edit in bulk using python glob module<\/p>\n\n<p>ex.<\/p>\n\n<pre><code>import glob\nsongs = glob.glob('*')   \/\/ script should be in directory of songs.\nfor song in songs:\n    \/\/ do the above work.\n<\/code><\/pre>\n",
                "<p><a href=\"http:\/\/www.dotfunk.com\/projects\/mp3\/\" rel=\"nofollow\">This toolkit<\/a> may do what you need. I can't say if it's the \"best\", but really, if it does what you need, that's all that matters, right?<\/p>\n\n<p>HTH<\/p>\n",
                "<p>It can depend on exactly what you want to do in addition to reading the metadata. If it is just simply the bitrate \/ name etc. that you need, and nothing else, something lightweight is probably best.<\/p>\n\n<p>If you're manipulating the mp3 past that PyMedia may be suitable.<\/p>\n\n<p>There are quite a few, whatever you do get, make sure and test it out on plenty of sample media. There are a few different versions of ID3 tags in particular, so make sure it's not too out of date. <\/p>\n\n<p>Personally I've used this small MP3Info class with luck. It is quite old though.<\/p>\n\n<p><a href=\"http:\/\/www.omniscia.org\/~vivake\/python\/MP3Info.py\" rel=\"nofollow\">http:\/\/www.omniscia.org\/~vivake\/python\/MP3Info.py<\/a><\/p>\n",
                "<p>Just additional information to you guys:<\/p>\n\n<p>take a look at the section \"MP3 stuff and Metadata editors\" in the page of <a href=\"http:\/\/wiki.python.org\/moin\/PythonInMusic\" rel=\"nofollow\">PythonInMusic<\/a>.<\/p>\n",
                "<p>A problem with <code>eyed3<\/code> is that it will throw <code>NotImplementedError(\"Unable to write ID3 v2.2\")<\/code> for common MP3 files.<\/p>\n\n<p>In my experience, the <code>mutagen<\/code> class <code>EasyID3<\/code> works more reliably. Example:<\/p>\n\n<pre><code>from mutagen.easyid3 import EasyID3\n\naudio = EasyID3(\"example.mp3\")\naudio['title'] = u\"Example Title\"\naudio['artist'] = u\"Me\"\naudio['album'] = u\"My album\"\naudio['composer'] = u\"\" # clear\naudio.save()\n<\/code><\/pre>\n\n<p>All other tags can be accessed this way and saved, which will serve most purposes. More information can be found in the <a href=\"https:\/\/mutagen.readthedocs.org\/en\/latest\/tutorial.html#easy-id3\" rel=\"nofollow\">Mutagen Tutorial<\/a>.<\/p>\n",
                "<p>I looked the above answers and found out that they are not good for my project because of licensing problems with GPL.<\/p>\n\n<p>And I found out this: <a href=\"http:\/\/pyid3lib.sourceforge.net\/\" rel=\"nofollow\">PyID3Lib<\/a>, while that particular <em>python binding<\/em> release date is old, it uses the <a href=\"http:\/\/id3lib.sourceforge.net\/\" rel=\"nofollow\">ID3Lib<\/a>, which itself is up to date.<\/p>\n\n<p>Notable to mention is that both are <strong>LGPL<\/strong>, and are good to go.<\/p>\n",
                "<p>A simple example from the book Dive Into Python works ok for me, <a href=\"http:\/\/www.diveintopython.org\/download\/diveintopython-examples-5.4.zip\" rel=\"nofollow\">this<\/a> is the download link, the example is fileinfo.py. Don't know if it's the best, but it can do the basic job.<\/p>\n\n<p>The entire book is available online <a href=\"http:\/\/www.diveintopython.org\/\" rel=\"nofollow\">here<\/a>.<\/p>\n",
                "<p>check this one out:<\/p>\n\n<p><a href=\"https:\/\/github.com\/Ciantic\/songdetails\">https:\/\/github.com\/Ciantic\/songdetails<\/a><\/p>\n\n<p>Usage example:<\/p>\n\n<pre><code>&gt;&gt;&gt; import songdetails\n&gt;&gt;&gt; song = songdetails.scan(\"data\/song.mp3\")\n&gt;&gt;&gt; print song.duration\n0:03:12\n<\/code><\/pre>\n\n<p>Saving changes:<\/p>\n\n<pre><code>&gt;&gt;&gt; import songdetails\n&gt;&gt;&gt; song = songdetails.scan(\"data\/commit.mp3\")\n&gt;&gt;&gt; song.artist = \"Great artist\"\n&gt;&gt;&gt; song.save()\n<\/code><\/pre>\n",
                "<p>What you're after is the <a href=\"http:\/\/id3-py.sourceforge.net\/\">ID3<\/a> module.  It's very simple and will give you exactly what you need.  Just copy the ID3.py file into your site-packages directory and you'll be able to do something like the following:<\/p>\n\n<pre><code>from ID3 import *\ntry:\n  id3info = ID3('file.mp3')\n  print id3info\n  # Change the tags\n  id3info['TITLE'] = \"Green Eggs and Ham\"\n  id3info['ARTIST'] = \"Dr. Seuss\"\n  for k, v in id3info.items():\n    print k, \":\", v\nexcept InvalidTagError, message:\n  print \"Invalid ID3 tag:\", message\n<\/code><\/pre>\n",
                "<p>I've used <a href=\"https:\/\/bitbucket.org\/lazka\/mutagen\">mutagen<\/a> to edit tags in media files before.  The nice thing about mutagen is that it can handle other formats, such as mp4, FLAC etc.  I've written several scripts with a lot of success using this API.<\/p>\n",
                "<p>I used <a href=\"http:\/\/eyed3.nicfit.net\/\">eyeD3<\/a> the other day with a lot of success.  I found that it could add artwork to the ID3 tag which the other modules I looked at couldn't.  You'll have to download the tar and execute <code>python setup.py install<\/code> from the source folder.  <\/p>\n\n<p>Relevant examples from the website are below.<\/p>\n\n<p>Reading the contents of an mp3 file containing either v1 or v2 tag info:<\/p>\n\n<pre><code> import eyeD3\n tag = eyeD3.Tag()\n tag.link(\"\/some\/file.mp3\")\n print tag.getArtist()\n print tag.getAlbum()\n print tag.getTitle()\n<\/code><\/pre>\n\n<p>Read an mp3 file (track length, bitrate, etc.) and access it's tag:<\/p>\n\n<pre><code>if eyeD3.isMp3File(f):\n     audioFile = eyeD3.Mp3AudioFile(f)\n     tag = audioFile.getTag()\n<\/code><\/pre>\n\n<p>Specific tag versions can be selected:<\/p>\n\n<pre><code> tag.link(\"\/some\/file.mp3\", eyeD3.ID3_V2)\n tag.link(\"\/some\/file.mp3\", eyeD3.ID3_V1)\n tag.link(\"\/some\/file.mp3\", eyeD3.ID3_ANY_VERSION)  # The default.\n<\/code><\/pre>\n\n<p>Or you can iterate over the raw frames:<\/p>\n\n<pre><code> tag = eyeD3.Tag()\n tag.link(\"\/some\/file.mp3\")\n for frame in tag.frames:\n    print frame\n<\/code><\/pre>\n\n<p>Once a tag is linked to a file it can be modified and saved:<\/p>\n\n<pre><code> tag.setArtist(u\"Cro-Mags\")\n tag.setAlbum(u\"Age of Quarrel\")\n tag.update()\n<\/code><\/pre>\n\n<p>If the tag linked in was v2 and you'd like to save it as v1:<\/p>\n\n<pre><code> tag.update(eyeD3.ID3_V1_1)\n<\/code><\/pre>\n\n<p>Read in a tag and remove it from the file:<\/p>\n\n<pre><code> tag.link(\"\/some\/file.mp3\")\n tag.remove()\n tag.update()\n<\/code><\/pre>\n\n<p>Add a new tag:<\/p>\n\n<pre><code> tag = eyeD3.Tag()\n tag.link('\/some\/file.mp3')    # no tag in this file, link returned False\n tag.header.setVersion(eyeD3.ID3_V2_3)\n tag.setArtist('Fugazi')\n tag.update()\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_10123",
            "padroes": [
                "I'm trying to decode the result of the Python os.wait() function. This returns, according to the Python docs:\n\n\n  a tuple containing its pid and exit status indication: a 16-bit number, whose low byte is the signal number that killed the process, and whose high byte is the exit status (if the signal number is zero); the high bit of the low byte is set if a core file was produced.\n\n\nHow do I decode the exit status indication (which is an integer) to obtain the high and low byte? To be specific, how do I implement the decode function used in the following code snippet:\n\n(pid,status) = os.wait()\n(exitstatus, signum) = decode(status)\n\n"
            ],
            "respostas": [
                "<p>The folks before me've nailed it, but if you really want it on one line, you can do this:<\/p>\n\n<pre><code>(signum, exitstatus) = (status &amp; 0xFF, (status &gt;&gt; 8) &amp; 0xFF)\n<\/code><\/pre>\n\n<p>EDIT: Had it backwards.<\/p>\n",
                "<p>You can unpack the status using <a href=\"http:\/\/docs.python.org\/ref\/shifting.html\" rel=\"nofollow\">bit-shifting<\/a> and <a href=\"http:\/\/docs.python.org\/ref\/bitwise.html\" rel=\"nofollow\">masking<\/a> operators.<\/p>\n\n<pre><code>low = status &amp; 0x00FF\nhigh = (status &amp; 0xFF00) &gt;&gt; 8\n<\/code><\/pre>\n\n<p>I'm not a Python programmer, so I hope got the syntax correct.<\/p>\n",
                "<p>You can get break your int into a string of unsigned bytes with the <a href=\"http:\/\/docs.python.org\/library\/struct.html\" rel=\"nofollow\">struct<\/a> module:<\/p>\n\n<pre><code>import struct\ni = 3235830701  # 0xC0DEDBAD\ns = struct.pack(\"&gt;L\", i)  # \"&gt;\" = Big-endian, \"&lt;\" = Little-endian\nprint s         # '\\xc0\\xde\\xdb\\xad'\nprint s[0]      # '\\xc0'\nprint ord(s[0]) # 192 (which is 0xC0)\n<\/code><\/pre>\n\n<p>If you couple this with the <a href=\"http:\/\/docs.python.org\/library\/array.html\" rel=\"nofollow\">array<\/a> module you can do this more conveniently:<\/p>\n\n<pre><code>import struct\ni = 3235830701  # 0xC0DEDBAD\ns = struct.pack(\"&gt;L\", i)  # \"&gt;\" = Big-endian, \"&lt;\" = Little-endian\n\nimport array\na = array.array(\"B\")  # B: Unsigned bytes\na.fromstring(s)\nprint a   # array('B', [192, 222, 219, 173])\n<\/code><\/pre>\n",
                "<pre><code>exitstatus, signum= divmod(status, 256)\n<\/code><\/pre>\n",
                "<p>This will do what you want:<\/p>\n\n<pre><code>signum = status &amp; 0xff\nexitstatus = (status &amp; 0xff00) &gt;&gt; 8\n<\/code><\/pre>\n",
                "<p>To answer your general question, you can use <a href=\"http:\/\/en.wikipedia.org\/wiki\/Bit_twiddling\" rel=\"nofollow\">bit manipulation<\/a> techniques:<\/p>\n\n<pre><code>pid, status = os.wait()\nexitstatus, signum = status &amp; 0xFF, (status &amp; 0xFF00) &gt;&gt; 8\n<\/code><\/pre>\n\n<p>However, there are also <a href=\"http:\/\/docs.python.org\/lib\/os-process.html#l2h-2780\" rel=\"nofollow\">built-in functions<\/a> for interpreting exit status values:<\/p>\n\n<pre><code>pid, status = os.wait()\nexitstatus, signum = os.WEXITSTATUS( status ), os.WTERMSIG( status )\n<\/code><\/pre>\n\n<p>See also:<\/p>\n\n<ul>\n<li>os.WCOREDUMP()<\/li>\n<li>os.WIFCONTINUED()<\/li>\n<li>os.WIFSTOPPED()<\/li>\n<li>os.WIFSIGNALED()<\/li>\n<li>os.WIFEXITED()<\/li>\n<li>os.WSTOPSIG()<\/li>\n<\/ul>\n"
            ]
        },
        {
            "tag": "questao_11060",
            "padroes": [
                "This is a difficult and open-ended question I know, but I thought I'd throw it to the floor and see if anyone had any interesting suggestions.\n\nI have developed a code-generator that takes our python interface to our C++ code (generated via SWIG) and generates code needed to expose this as WebServices.  When I developed this code I did it using TDD, but I've found my tests to be brittle as hell.  Because each test essentially wanted to verify that for a given bit of input code (which happens to be a C++ header) I'd get a given bit of outputted code I wrote a small engine that reads test definitions from XML input files and generates test cases from these expectations.\n\nThe problem is I dread going in to modify the code at all.  That and the fact that the unit tests themselves are a: complex, and b: brittle.\n\nSo I'm trying to think of alternative approaches to this problem, and it strikes me I'm perhaps tackling it the wrong way.  Maybe I need to focus more on the outcome, IE: does the code I generate actually run and do what I want it to, rather than, does the code look the way I want it to.\n\nHas anyone got any experiences of something similar to this they would care to share?\n"
            ],
            "respostas": [
                "<p>Just wanted to point out that you can still achieve fine-grained testing while verifying the results: you can test individual chunks of code by nesting them inside some setup and verification code:<\/p>\n\n<pre><code>int x = 0;\nGENERATED_CODE\nassert(x == 100);\n<\/code><\/pre>\n\n<p>Provided you have your generated code assembled from smaller chunks, and the chunks do not change frequently, you can exercise more conditions and test a little better, and hopefully avoid having all your tests break when you change specifics of one chunk.<\/p>\n",
                "<p>Unit testing is just that testing a specific unit. So if you are writing a specification for class A, it is ideal if class A does not have the real concrete versions of class B and C.<\/p>\n\n<p>Ok I noticed afterwards the tag for this question includes C++ \/ Python, but the principles are the same:<\/p>\n\n<pre><code>    public class A : InterfaceA \n    {   \n      InterfaceB b;\n\n      InterfaceC c;\n\n      public A(InterfaceB b, InterfaceC c)   {\n          this._b = b;\n          this._c = c;   \n\n      public string SomeOperation(string input)   \n      {\n          return this._b.SomeOtherOperation(input) \n               + this._c.EvenAnotherOperation(input); \n       \n    \n<\/code><\/pre>\n\n<p>Because the above System A injects interfaces to systems B and C, you can unit test just system A, without having real functionality being executed by any other system. This is unit testing.<\/p>\n\n<p>Here is a clever manner for approaching a System from creation to completion, with a different When specification for each piece of behaviour:<\/p>\n\n<pre><code>public class When_system_A_has_some_operation_called_with_valid_input : SystemASpecification\n{\n    private string _actualString;\n\n    private string _expectedString;\n\n    private string _input;\n\n    private string _returnB;\n\n    private string _returnC;\n\n    [It]\n    public void Should_return_the_expected_string()\n    {\n        _actualString.Should().Be.EqualTo(this._expectedString);\n    \n\n    public override void GivenThat()\n    {\n        var randomGenerator = new RandomGenerator();\n        this._input = randomGenerator.Generate&lt;string&gt;();\n        this._returnB = randomGenerator.Generate&lt;string&gt;();\n        this._returnC = randomGenerator.Generate&lt;string&gt;();\n\n        Dep&lt;InterfaceB&gt;().Stub(b =&gt; b.SomeOtherOperation(_input))\n                         .Return(this._returnB);\n        Dep&lt;InterfaceC&gt;().Stub(c =&gt; c.EvenAnotherOperation(_input))\n                         .Return(this._returnC);\n\n        this._expectedString = this._returnB + this._returnC;\n    \n\n    public override void WhenIRun()\n    {\n        this._actualString = Sut.SomeOperation(this._input);\n    \n\n<\/code><\/pre>\n\n<p>So in conclusion, a single unit \/ specification can have multiple behaviours, and the specification grows as you develop the unit \/ system; and if your system under test depends on other concrete systems within it, watch out.<\/p>\n",
                "<p>My recommendation would be to figure out a set of known input-output results, such as some simpler cases that you already have in place, and <em>unit test the code that is produced<\/em>. It's entirely possible that as you change the generator that the exact string that is produced may be slightly different... but what you really care is whether it is interpreted in the same way. Thus, if you test the results as you would test that code if it were your feature, you will find out if it succeeds in the ways you want.<\/p>\n\n<p>Basically, what you really want to know is whether your generator will produce what you expect without physically testing every possible combination (also: impossible). By ensuring that your generator is consistent in the ways you expect, you can feel better that the generator will succeed in ever-more-complex situations.<\/p>\n\n<p>In this way, you can also build up a suite of regression tests (unit tests that need to keep working correctly). This will help you make sure that changes to your generator aren't breaking other forms of code. When you encounter a bug that your unit tests didn't catch, you may want to include it to prevent similar breakage.<\/p>\n",
                "<p>I find that you need to test what you're generating more than how you generate it.<\/p>\n\n<p>In my case, the program generates many types of code (C#, HTML, SCSS, JS, etc.) that compile into a web application. The best way I've found to reduce regression bugs overall is to test the web application itself, not by testing the generator.  <\/p>\n\n<p>Don't get me wrong, there are still unit tests checking out some of the generator code, but our biggest bang for our buck has been UI tests on the generated app itself.<\/p>\n\n<p>Since we're generating it we also generate a nice abstraction in JS we can use to programatically test the app. We followed some ideas outlined here: <a href=\"http:\/\/code.tutsplus.com\/articles\/maintainable-automated-ui-tests--net-35089\" rel=\"nofollow\">http:\/\/code.tutsplus.com\/articles\/maintainable-automated-ui-tests--net-35089<\/a><\/p>\n\n<p>The great part is that it really tests your system end-to-end, from code generation out to what you're actually generating.  Once a test fails, its easy to track it back to where the generator broke.<\/p>\n\n<p>It's pretty sweet.<\/p>\n\n<p>Good luck!<\/p>\n",
                "<p>Yes, results are the ONLY thing that matters. The real chore is writing a framework that allows your generated code to run independently... spend your time there.<\/p>\n",
                "<p>If you are running on *nux you might consider dumping the unittest framework in favor of a bash script or makefile. on windows you might consider building a shell app\/function that runs the generator and then uses the code (as another process) and unittest that.<\/p>\n\n<p>A third option would be to generate the code and then build an app from it that includes nothing but a unittest. Again you would need a shell script or whatnot to run this for each input. As to how to encode the expected behavior, it occurs to me that it could be done in much the same way as you would for the C++ code just using the generated interface rather than the C++ one.<\/p>\n",
                "<p>Recall that \"unit testing\" is only one kind of testing.  You should be able to unit test the <strong>internal<\/strong> pieces of your code generator.  What you're really looking at here is system level testing (a.k.a. regression testing).  It's not just semantics... there are different mindsets, approaches, expectations, etc.  It's certainly more work, but you probably need to bite the bullet and set up an end-to-end regression test suite: fixed C++ files -> SWIG interfaces -> python modules -> known output.  You really want to check the known input (fixed C++ code) against expected output (what comes out of the final Python program).  Checking the code generator results directly would be like diffing object files...<\/p>\n",
                "<p>I started writing up a summary of my experience with my own code generator, then went back and re-read your question and found you had already touched upon the same issues yourself, focus on the execution results instead of the code layout\/look.<\/p>\n\n<p>Problem is, this is hard to test, the generated code might not be suited to actually run in the environment of the unit test system, and how do you encode the expected results?<\/p>\n\n<p>I've found that you need to break down the code generator into smaller pieces and unit test those. Unit testing a full code generator is more like integration testing than unit testing if you ask me.<\/p>\n"
            ]
        },
        {
            "tag": "questao_12592",
            "padroes": [
                "Is it possible to write a doctest unit test that will check that an exception is raised?For example, if I have a function foo(x) that is supposed to raise an exception if x, how would I write the doctest for that? \n"
            ],
            "respostas": [
                "<pre><code>&gt;&gt;&gt; import math\n&gt;&gt;&gt; math.log(-2)\nTraceback (most recent call last):\n ...\nValueError: math domain error\n<\/code><\/pre>\n\n<p>ellipsis flag <em># doctest: +ELLIPSIS<\/em> is not required to use ... in Traceback doctest <\/p>\n",
                "<p>Yes. You can do it. The <a href=\"https:\/\/docs.python.org\/3\/library\/doctest.html\">doctest module documentation<\/a> and Wikipedia has an <a href=\"http:\/\/en.wikipedia.org\/wiki\/Doctest#Example_2%3a_doctests_embedded_in_a_README.txt_file\">example<\/a> of it.<\/p>\n\n<pre><code>   &gt;&gt;&gt; x\n   Traceback (most recent call last):\n     ...\n   NameError: name 'x' is not defined\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_12591",
            "padroes": [
                "Is there a way, when I parse an XML document using lxml, to validate that document against its DTD using an external catalog file?   I need to be able to work the fixed attributes defined in a documentÃÃÃs DTD.\n"
            ],
            "respostas": [
                "<p>It seems that lxml does not expose this libxml2 feature, grepping the source only turns up some #defines for the error handling:<\/p>\n\n<pre><code>C:\\Dev&gt;grep -ir --include=*.px[id] catalog lxml-2.1.1\/src | sed -r \"s\/\\s+\/ \/g\"\nlxml-2.1.1\/src\/lxml\/dtd.pxi: catalog.\nlxml-2.1.1\/src\/lxml\/xmlerror.pxd: XML_FROM_CATALOG = 20 # The Catalog module\nlxml-2.1.1\/src\/lxml\/xmlerror.pxd: XML_WAR_CATALOG_PI = 93 # 93\nlxml-2.1.1\/src\/lxml\/xmlerror.pxd: XML_CATALOG_MISSING_ATTR = 1650\nlxml-2.1.1\/src\/lxml\/xmlerror.pxd: XML_CATALOG_ENTRY_BROKEN = 1651 # 1651\nlxml-2.1.1\/src\/lxml\/xmlerror.pxd: XML_CATALOG_PREFER_VALUE = 1652 # 1652\nlxml-2.1.1\/src\/lxml\/xmlerror.pxd: XML_CATALOG_NOT_CATALOG = 1653 # 1653\nlxml-2.1.1\/src\/lxml\/xmlerror.pxd: XML_CATALOG_RECURSION = 1654 # 1654\nlxml-2.1.1\/src\/lxml\/xmlerror.pxi:CATALOG=20\nlxml-2.1.1\/src\/lxml\/xmlerror.pxi:WAR_CATALOG_PI=93\nlxml-2.1.1\/src\/lxml\/xmlerror.pxi:CATALOG_MISSING_ATTR=1650\nlxml-2.1.1\/src\/lxml\/xmlerror.pxi:CATALOG_ENTRY_BROKEN=1651\nlxml-2.1.1\/src\/lxml\/xmlerror.pxi:CATALOG_PREFER_VALUE=1652\nlxml-2.1.1\/src\/lxml\/xmlerror.pxi:CATALOG_NOT_CATALOG=1653\nlxml-2.1.1\/src\/lxml\/xmlerror.pxi:CATALOG_RECURSION=1654\n<\/code><\/pre>\n\n<p>From the <a href=\"http:\/\/xmlsoft.org\/catalog.html\" rel=\"nofollow\">catalog implementation in libxml2 page<\/a> it seems possible that the 'transparent' handling through installation in \/etc\/xml\/catalog may still work in lxml, but if you need more than that you can always abandon lxml and use the default python bindings, which do expose the catalog functions.<\/p>\n",
                "<p>Can you give an example? According to the <a href=\"http:\/\/codespeak.net\/lxml\/validation.html\" rel=\"nofollow\">lxml validation docs<\/a>, lxml can handle DTD validation (specified in the XML doc or externally in code) and system catalogs, which covers most cases I can think of.<\/p>\n\n<pre><code>f = StringIO(\"&lt;!ELEMENT b EMPTY&gt;\")\ndtd = etree.DTD(f)\ndtd = etree.DTD(external_id = \"-\/\/OASIS\/\/DTD DocBook XML V4.2\/\/EN\")\n<\/code><\/pre>\n",
                "<p>You can add the catalog to the <code>XML_CATALOG_FILES<\/code> environment variable:<\/p>\n\n<pre><code>os.environ['XML_CATALOG_FILES'] = 'file:\/\/\/to\/my\/catalog.xml'\n<\/code><\/pre>\n\n<p>See <a href=\"http:\/\/thread.gmane.org\/gmane.comp.python.lxml.devel\/5907\" rel=\"nofollow\">this thread<\/a>. Note that entries in <code>XML_CATALOG_FILES<\/code> are space-separated URLs. You can use Python's <code>pathname2url<\/code> and <code>urljoin<\/code> (with <code>file:<\/code>) to generate the URL from a pathname.<\/p>\n"
            ]
        },
        {
            "tag": "questao_13396",
            "padroes": [
                "I love list comprehensions in Python, because they concisely represent a transformation of a list.\n\nHowever, in other languages, I frequently find myself writing something along the lines of:\n\nforeach (int x in intArray)\n  if (x > 3) \/\/generic condition on x\n    x++ \n    \/\/do other processing\n\n\nThis example is in C#, where I'm under the impression LINQ can help with this, but is there some common programming construct which can replace this slightly less-than-elegant solution?  Perhaps a data structure I'm not considering?\n"
            ],
            "respostas": [
                "<p>Depends on the language and what you need to do, a \"map\" as it's called in many languages could be what you're looking for. I don't know C#, but according to <a href=\"http:\/\/blogs.msdn.com\/devdev\/archive\/2006\/06\/30\/652802.aspx\" rel=\"nofollow\">this<\/a> page, .NET 2.0 calls map \"ConvertAll\".<\/p>\n\n<p>The meaning of \"map\" is pretty simple - take a list, and apply a function to each element of it, returning a new list. You may also be looking for \"filter\", which would give you a list of items that satisfy a predicate in another list.<\/p>\n",
                "<p>in Ruby:<\/p>\n\n<pre><code>intArray.select { |x| x &gt; 3 .each do |x|\n  # do other processing\nend\n<\/code><\/pre>\n\n<p>or if \"other processing\" is a short one-liner:<\/p>\n\n<pre><code>intArray.select { |x| x &gt; 3 .each { |x| something_that_uses x \n<\/code><\/pre>\n\n<p>lastly, if you want to return a new array containing the results of the processing of those elements greater than 3:<\/p>\n\n<pre><code>intArray.select { |x| x &gt; 3 .map { |x| do_something_to x \n<\/code><\/pre>\n",
                "<pre><code>map(lambda x: test(x + 1) filter(lambda x: x &gt; 3, arr))\n<\/code><\/pre>\n",
                "<p>In Python, you have <a href=\"http:\/\/docs.python.org\/tut\/node7.html#SECTION007130000000000000000\" rel=\"nofollow\" title=\"Human Interface Guidelines\">filter and map<\/a>, which can so what you want:<\/p>\n\n<pre><code>map(lambda x: foo(x + 1) filter(lambda x: x &gt; 3, intArray))\n<\/code><\/pre>\n\n<p>There's also <a href=\"http:\/\/docs.python.org\/tut\/node7.html#SECTION007140000000000000000\" rel=\"nofollow\">list comprehensions<\/a> which can do both in one easy statement:<\/p>\n\n<pre><code>[f(x + 1) for x in intArray if x &gt; 3]\n<\/code><\/pre>\n",
                "<p>In C# you can apply selective processing on anything that lives inside an IEnumerable like this:  <\/p>\n\n<pre><code>intArray.Where(i =&gt; i &gt; 3).ConvertAll();\nDoStuff(intArray.Where(i =&gt; i 3));\n<\/code><\/pre>\n\n<p>Etc..<\/p>\n",
                "<p>The increment in the original <code>foreach<\/code> loop will not affect the contents of the array, the only way to do this remains a <code>for<\/code> loop:<\/p>\n\n<pre><code>for(int i = 0; i &lt; intArray.Length; ++i)\n{\n    if(intArray[i] &gt; 3) ++intArray[i];\n\n<\/code><\/pre>\n\n<p>Linq is not intended to modify existing collections or sequences. It creates new sequences based on existing ones. It is possible to achieve the above code using Linq, though it is slightly against its purposes:<\/p>\n\n<pre><code>var newArray1 = from i in intArray select ((i &gt; 3) ? (i + 1) : (i));\nvar newArray2 = intArray.Select(i =&gt; (i &gt; 3) ? (i + 1) : (i));\n<\/code><\/pre>\n\n<p>Using <code>where<\/code> (or equivalent), as shown in some of the other answers, will exclude any values less than or equal to 3 from the resulting sequence.<\/p>\n\n<pre><code>var intArray = new int[] { 10, 1, 20, 2 ;\nvar newArray = from i in intArray where i &gt; 3 select i + 1;\n\/\/ newArray == { 11, 21 \n<\/code><\/pre>\n\n<p>There is a <code>ForEach<\/code> method on arrays that will allow you to use a lambda function instead of a <code>foreach<\/code> block, though for anything more than a method call I would stick with <code>foreach<\/code>.<\/p>\n\n<pre><code>intArray.ForEach(i =&gt; DoSomething(i));\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_13454",
            "padroes": [
                "I wrote a piece of code to convert PHP's striplashes into valid Python [backslash] escapes:\n\ncleaned = stringwithslashes\ncleaned = cleaned.replace('\\\\n', '\\n')\ncleaned = cleaned.replace('\\\\r', '\\n')\ncleaned = cleaned.replace('\\\\', '')\n\n\nHow can I condense it? \n"
            ],
            "respostas": [
                "<p>Python has a built-in escape() function analogous to PHP's addslashes, but no unescape() function (stripslashes), which in my mind is kind of ridiculous.<\/p>\n\n<p>Regular expressions to the rescue (code not tested):<\/p>\n\n<pre><code>p = re.compile( '\\\\(\\\\\\S)')\np.sub('\\1',escapedstring)\n<\/code><\/pre>\n\n<p>In theory that takes anything of the form \\\\(not whitespace) and returns \\(same char)<\/p>\n\n<p>edit: Upon further inspection, Python regular expressions are broken as all hell;<\/p>\n\n<pre><code>&gt;&gt;&gt; escapedstring\n'This is a \\\\n\\\\n\\\\n test'\n&gt;&gt;&gt; p = re.compile( r'\\\\(\\S)' )\n&gt;&gt;&gt; p.sub(r\"\\1\",escapedstring)\n'This is a nnn test'\n&gt;&gt;&gt; p.sub(r\"\\\\1\",escapedstring)\n'This is a \\\\1\\\\1\\\\1 test'\n&gt;&gt;&gt; p.sub(r\"\\\\\\1\",escapedstring)\n'This is a \\\\n\\\\n\\\\n test'\n&gt;&gt;&gt; p.sub(r\"\\(\\1)\",escapedstring)\n'This is a \\\\(n)\\\\(n)\\\\(n) test'\n<\/code><\/pre>\n\n<p>In conclusion, what the hell, Python.<\/p>\n",
                "<p>You can obviously concatenate everything together:<\/p>\n\n<pre><code>cleaned = stringwithslashes.replace(\"\\\\n\",\"\\n\").replace(\"\\\\r\",\"\\n\").replace(\"\\\\\",\"\")\n<\/code><\/pre>\n\n<p>Is that what you were after? Or were you hoping for something more terse?<\/p>\n",
                "<p>use <code>decode('string_escape')<\/code><\/p>\n\n<pre><code>cleaned = stringwithslashes.decode('string_escape')\n<\/code><\/pre>\n\n<p>Using <\/p>\n\n<blockquote>\n  <p><strong>string_escape<\/strong> : Produce a string that is suitable as string literal in Python source code<\/p>\n<\/blockquote>\n\n<p>or concatenate the replace() like Wilson-Â¦s answer.<\/p>\n\n<pre><code>cleaned = stringwithslashes.replace(\"\\\\\",\"\").replace(\"\\\\n\",\"\\n\").replace(\"\\\\r\",\"\\n\")\n<\/code><\/pre>\n",
                "<p>It sounds like what you want could be reasonably efficiently handled through regular expressions:<\/p>\n\n<pre><code>import re\ndef stripslashes(s):\n    r = re.sub(r\"\\\\(n|r)\", \"\\n\", s)\n    r = re.sub(r\"\\\\\", \"\", r)\n    return r\ncleaned = stripslashes(stringwithslashes)\n<\/code><\/pre>\n",
                "<p>Not totally sure this is what you want, but..<\/p>\n\n<pre><code>cleaned = stringwithslashes.decode('string_escape')\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_13791",
            "padroes": [
                "I'm trying to implement string unescaping with Python regex and backreferences, and it doesn't seem to want to work very well. I'm sure it's something I'm doing wrong but I can't figure out what...\n\n>>> import re\n>>> mystring = r\"This is \\n a test \\r\"\n>>> p = re.compile( \"\\\\\\\\(\\\\S)\" )\n>>> p.sub( \"\\\\1\", mystring )\n'This is n a test r'\n>>> p.sub( \"\\\\\\\\\\\\1\", mystring )\n'This is \\\\n a test \\\\r'\n>>> p.sub( \"\\\\\\\\1\", mystring )\n'This is \\\\1 a test \\\\1'\n\n\nI'd like to replace \\\\[char] with \\[char], but backreferences in Python don't appear to follow the same rules they do in every other implementation I've ever used. Could someone shed some light?\n"
            ],
            "respostas": [
                "<p>You are being tricked by Python's representation of the result string. The Python expression:<\/p>\n\n<pre><code>'This is \\\\n a test \\\\r'\n<\/code><\/pre>\n\n<p>represents the string<\/p>\n\n<pre><code>This is \\n a test \\r\n<\/code><\/pre>\n\n<p>which is I think what you wanted. Try adding 'print' in front of each of your p.sub() calls to print the actual string returned instead of a Python representation of the string.<\/p>\n\n<pre><code>&gt;&gt;&gt; mystring = r\"This is \\n a test \\r\"\n&gt;&gt;&gt; mystring\n'This is \\\\n a test \\\\r'\n&gt;&gt;&gt; print mystring\nThis is \\n a test \\r\n<\/code><\/pre>\n",
                "<p>The idea is that I'll read in an escaped string, and unescape it (a feature notably lacking from Python, which you shouldn't need to resort to regular expressions for in the first place). Unfortunately I'm not being tricked by the backslashes...<\/p>\n\n<p>Another illustrative example:<\/p>\n\n<pre><code>&gt;&gt;&gt; mystring = r\"This is \\n ridiculous\"\n&gt;&gt;&gt; print mystring\nThis is \\n ridiculous\n&gt;&gt;&gt; p = re.compile( r\"\\\\(\\S)\" )\n&gt;&gt;&gt; print p.sub( 'bloody', mystring )\nThis is bloody ridiculous\n&gt;&gt;&gt; print p.sub( r'\\1', mystring )\nThis is n ridiculous\n&gt;&gt;&gt; print p.sub( r'\\\\1', mystring )\nThis is \\1 ridiculous\n&gt;&gt;&gt; print p.sub( r'\\\\\\1', mystring )\nThis is \\n ridiculous\n<\/code><\/pre>\n\n<p>What I'd like it to print is<\/p>\n\n<pre><code>This is \nridiculous\n<\/code><\/pre>\n",
                "<p>Mark; his second example requires every escaped character thrown into an array initially, which generates a KeyError if the escape sequence happens not to be in the array. It will die on anything but the three characters provided (give \\v a try), and enumerating every possible escape sequence every time you want to unescape a string (or keeping a global array) is a really bad solution. Analogous to PHP, that's using <code>preg_replace_callback()<\/code> with a lambda instead of <code>preg_replace()<\/code>, which is utterly unnecessary in this situation.<\/p>\n\n<p>I'm sorry if I'm coming off as a dick about it, I'm just utterly frustrated with Python. This is supported by every other regular expression engine I've ever used, and I can't understand why this wouldn't work.<\/p>\n\n<p>Thank you for responding; the <code>string.decode('string-escape')<\/code> function is precisely what i was looking for initially. If someone has a general solution to the regex backreference problem, feel free to post it and I'll accept that as an answer as well.<\/p>\n",
                "<p>Well, I think you might have missed the r or miscounted the backslashes...<\/p>\n\n<pre><code>\"\\\\n\" == r\"\\n\"\n\n&gt;&gt;&gt; import re\n&gt;&gt;&gt; mystring = r\"This is \\\\n a test \\\\r\"\n&gt;&gt;&gt; p = re.compile( r\"[\\\\][\\\\](.)\" )\n&gt;&gt;&gt; print p.sub( r\"\\\\\\1\", mystring )\nThis is \\n a test \\r\n&gt;&gt;&gt;\n<\/code><\/pre>\n\n<p>Which, if I understood is what was requested.<\/p>\n\n<p>I suspect the more common request is this:<\/p>\n\n<pre><code>&gt;&gt;&gt; d = {'n':'\\n', 'r':'\\r', 'f':'\\f'\n&gt;&gt;&gt; p = re.compile(r\"[\\\\]([nrfv])\")\n&gt;&gt;&gt; print p.sub(lambda mo: d[mo.group(1)], mystring)\nThis is \\\n a test \\\n&gt;&gt;&gt;\n<\/code><\/pre>\n\n<p>The interested student should also read Ken Thompson's <a href=\"http:\/\/cm.bell-labs.com\/who\/ken\/trust.html\" rel=\"nofollow\" title=\"Cherry G80-11900\">Reflections on Trusting Trust\"<\/a>, wherein our hero uses a similar example to explain the perils of trusting compilers you haven't bootstrapped from machine code yourself.<\/p>\n",
                "<p>Isn't that what <a href=\"#13844\">Anders' second example<\/a> does?<\/p>\n\n<p>In 2.5 there's also a <code>string-escape<\/code> encoding you can apply:<\/p>\n\n<pre><code>&gt;&gt;&gt; mystring = r\"This is \\n a test \\r\"\n&gt;&gt;&gt; mystring.decode('string-escape')\n'This is \\n a test \\r'\n&gt;&gt;&gt; print mystring.decode('string-escape')\nThis is \n a test \n&gt;&gt;&gt;\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_13857",
            "padroes": [
                "I've been reading a lot about closures and I think I understand them, but without clouding the picture for myself and others, I am hoping someone can explain closures as succinctly and clearly as possible.  I'm looking for a simple explanation that might help me understand where and why I would want to use them.\n"
            ],
            "respostas": [
                "<p>The best explanation I ever saw of a closure was to explain the mechanism.  It went something like this:<\/p>\n\n<p>Imagine your program stack as a degenerate tree where each node has only one child and the single leaf node is the context of your currently executing procedure.<\/p>\n\n<p>Now relax the constraint that each node can have only one child.<\/p>\n\n<p>If you do this, you can have a construct ('yield') that can return from a procedure without discarding the local context (i.e. it doesn't pop it off the stack when you return).  The next time the procedure is invoked, the invocation picks up the old stack (tree) frame and continues executing where it left off.<\/p>\n",
                "<p>For me, \"closures\" are functions which are capable to remember the environment they were created. This functionality, allows you to use variables or methods within the closure wich, in other way,you wouldn't be able to use either because they don't exist anymore or  they are out of reach due to scope. Let's look at this code in ruby:<\/p>\n\n<pre><code>def makefunction (x)\n  def multiply (a,b)\n    puts a*b\n  end\n  return lambda {|n| multiply(n,x) # =&gt; returning a closure\nend\n\nfunc = makefunction(2) # =&gt; we capture the closure\nfunc.call(6)    # =&gt; Result equal \"12\"  \n<\/code><\/pre>\n\n<p>it works even when both, \"multiply\" method and \"x\" variable,not longer exist. All because the closure capability to remember.<\/p>\n",
                "<p>In Python, a closure is an instance of a function that has variables bound to it immutably.<\/p>\n\n<p>In fact, the <a href=\"https:\/\/docs.python.org\/3.3\/reference\/datamodel.html#the-standard-type-hierarchy\" rel=\"nofollow\">data model explains this<\/a> in its description of functions' <code>__closure__<\/code> attribute: <\/p>\n\n<blockquote>\n  <p>None or a <strong>tuple of cells<\/strong> that contain bindings for the functionÃÃÃs free variables. Read-only<\/p>\n<\/blockquote>\n\n<p>To demonstrate this:<\/p>\n\n<pre><code>def enclosure(foo):\n    def closure(bar):\n        print(foo, bar)\n    return closure\n\nclosure_instance = enclosure('foo')\n<\/code><\/pre>\n\n<p>Clearly, we know that we now have a function pointed at from the variable name <code>closure_instance<\/code>. Ostensibly, if we call it with an object, <code>bar<\/code>, it should print the string, <code>'foo'<\/code> and whatever the string representation of <code>bar<\/code> is.<\/p>\n\n<p>In fact, the string 'foo' <em>is<\/em> bound to the instance of the function, and we can directly read it here, by accessing the <code>cell_contents<\/code> attribute of the first (and only) cell in the tuple of the <code>__closure__<\/code> attribute:<\/p>\n\n<pre><code>&gt;&gt;&gt; closure_instance.__closure__[0].cell_contents\n'foo'\n<\/code><\/pre>\n\n<p>As an aside, cell objects are described in the C API documentation:<\/p>\n\n<blockquote>\n  <p><a href=\"https:\/\/docs.python.org\/2\/c-api\/cell.html\" rel=\"nofollow\">\"Cell\" objects are used to implement variables referenced by multiple\n  scopes<\/a><\/p>\n<\/blockquote>\n\n<p>And we can demonstrate our closure's usage, noting that <code>'foo'<\/code> is stuck in the function and doesn't change:<\/p>\n\n<pre><code>&gt;&gt;&gt; closure_instance('bar')\nfoo bar\n&gt;&gt;&gt; closure_instance('baz')\nfoo baz\n&gt;&gt;&gt; closure_instance('quux')\nfoo quux\n<\/code><\/pre>\n\n<p>And nothing can change it:<\/p>\n\n<pre><code>&gt;&gt;&gt; closure_instance.__closure__ = None\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: readonly attribute\n<\/code><\/pre>\n\n<h3>Partial Functions<\/h3>\n\n<p>The example given uses the closure as a partial function, but if this is our only goal, the same goal can be accomplished with <code>functools.partial<\/code><\/p>\n\n<pre><code>&gt;&gt;&gt; from __future__ import print_function # use this if you're in Python 2.\n&gt;&gt;&gt; partial_function = functools.partial(print, 'foo')\n&gt;&gt;&gt; partial_function('bar')\nfoo bar\n&gt;&gt;&gt; partial_function('baz')\nfoo baz\n&gt;&gt;&gt; partial_function('quux')\nfoo quux\n<\/code><\/pre>\n\n<p>There are more complicated closures as well that would not fit the partial function example, and I'll demonstrate them further as time allows.<\/p>\n",
                "<p>Here is an example of Python3 closures <\/p>\n\n<pre><code>def closure(x):\n    def counter():\n        nonlocal x\n        x += 1\n        return x\n    return counter;\n\ncounter1 = closure(100);\ncounter2 = closure(200);\n\nprint(\"i from closure 1 \" + str(counter1()))\nprint(\"i from closure 1 \" + str(counter1()))\nprint(\"i from closure 2 \" + str(counter2()))\nprint(\"i from closure 1 \" + str(counter1()))\nprint(\"i from closure 1 \" + str(counter1()))\nprint(\"i from closure 1 \" + str(counter1()))\nprint(\"i from closure 2 \" + str(counter2()))\n\n# result\n\ni from closure 1 101\ni from closure 1 102\ni from closure 2 201\ni from closure 1 103\ni from closure 1 104\ni from closure 1 105\ni from closure 2 202\n<\/code><\/pre>\n",
                "<p>Here's a typical use case for closures - callbacks for GUI elements (this would be an alternative to subclassing the button class). For example, you can construct a function that will be called in response to a button press, and \"close\" over the relevant variables in the parent scope that are necessary for processing the click. This way you can wire up pretty complicated interfaces from the same initialization function, building all the dependencies into the closure.<\/p>\n",
                "<p>I've never heard of transactions being used in the same context as explaining what a closure is and there really aren't any transaction semantics here.<\/p>\n\n<p>It's called a closure because it \"closes over\" the outside variable (constant)--i.e., it's not just a function but an enclosure of the environment where the function was created. <\/p>\n\n<p>In the following example, calling the closure g after changing x will also change the value of x within g, since g closes over x:<\/p>\n\n<pre><code>x = 0\n\ndef f():\n    def g(): \n        return x * 2\n    return g\n\n\nclosure = f()\nprint(closure()) # 0\nx = 2\nprint(closure()) # 4\n<\/code><\/pre>\n",
                "<p>To be honest, I understand closures perfectly well except I've never been clear about what exactly is the thing which is the \"closure\" and what's so \"closure\" about it. I recommend you give up looking for any logic behind the choice of term.<\/p>\n\n<p>Anyway, here's my explanation:<\/p>\n\n<pre><code>def foo():\n   x = 3\n   def bar():\n      print x\n   x = 5\n   return bar\n\nbar = foo()\nbar()   # print 5\n<\/code><\/pre>\n\n<p>A key idea here is that the function object returned from foo retains a hook to the local var 'x' even though 'x' has gone out of scope and should be defunct. This hook is to the var itself, not just the value that var had at the time, so when bar is called, it prints 5, not 3.<\/p>\n\n<p>Also be clear that Python 2.x has limited closure: there's no way I can modify 'x' inside 'bar' because writing 'x = bla' would declare a local 'x' in bar, not assign to 'x' of foo. This is a side-effect of Python's assignment=declaration. To get around this, Python 3.0 introduces the nonlocal keyword:<\/p>\n\n<pre><code>def foo():\n   x = 3\n   def bar():\n      print x\n   def ack():\n      nonlocal x\n      x = 7\n   x = 5\n   return (bar, ack)\n\nbar, ack = foo()\nack()   # modify x of the call to foo\nbar()   # print 7\n<\/code><\/pre>\n",
                "<p>I like <a href=\"http:\/\/effbot.org\/zone\/closure.htm\">this rough, succinct definition<\/a>:<\/p>\n\n<blockquote>\n  <p>A function that can refer to environments that are no longer active.<\/p>\n<\/blockquote>\n\n<p>I'd add<\/p>\n\n<blockquote>\n  <p>A closure allows you to bind variables into a function <em>without passing them as parameters<\/em>.<\/p>\n<\/blockquote>\n\n<p>Decorators which accept parameters are a common use for closures.  Closures are a common implementation mechanism for that sort of \"function factory\".  I frequently choose to use closures in the <a href=\"http:\/\/c2.com\/cgi\/wiki?StrategyPattern\">Strategy Pattern<\/a> when the strategy is modified by data at run-time.<\/p>\n\n<p>In a language that allows anonymous block definition -- e.g., Ruby, C# -- closures can be used to implement (what amount to) novel new control structures.  The lack of anonymous blocks is among <a href=\"http:\/\/ivan.truemesh.com\/archives\/000411.html\">the limitations of closures in Python<\/a>.<\/p>\n",
                "<p>It's simple: A function that references variables from a containing scope, potentially after flow-of-control has left that scope. That last bit is very useful:<\/p>\n\n<pre><code>&gt;&gt;&gt; def makeConstantAdder(x):\n...     constant = x\n...     def adder(y):\n...         return y + constant\n...     return adder\n... \n&gt;&gt;&gt; f = makeConstantAdder(12)\n&gt;&gt;&gt; f(3)\n15\n&gt;&gt;&gt; g = makeConstantAdder(4)\n&gt;&gt;&gt; g(3)\n7\n<\/code><\/pre>\n\n<p>Note that 12 and 4 have \"disappeared\" inside f and g, respectively, this feature is what make f and g proper closures.<\/p>\n",
                "<p><a href=\"http:\/\/mrevelle.blogspot.com\/2006\/10\/closure-on-closures.html\">Closure on closures<\/a><\/p>\n\n<blockquote>\n  <p>Objects are data with methods\n  attached, closures are functions with\n  data attached.<\/p>\n<\/blockquote>\n\n<pre><code>def make_counter():\n    i = 0\n    def counter(): # counter() is a closure\n        nonlocal i\n        i += 1\n        return i\n    return counter\n\nc1 = make_counter()\nc2 = make_counter()\n\nprint (c1(), c1(), c2(), c2())\n# -&gt; 1 2 1 2\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_13941",
            "padroes": [
                "I'd like to have a python program alert me when it has completed its task by making a beep noise.  Currently,  I use import os and then use a command line speech program to say \"Process complete.\"  I much rather it be a simple \"bell.\"\n\nI know that there's a function that can be used in Cocoa apps, NSBeep, but I don't think that has much anything to do with this.\n\nI've also tried print(\\a) but that didn't work.\n\nI'm using a Mac, if you couldn't tell by my Cocoa comment, so that may help.\n\nThanks!\n"
            ],
            "respostas": [
                "<p>I had to turn off the \"Silence terminal bell\" option in my active Terminal Profile in iTerm for <code>print('\\a')<\/code> to work. It seemed to work fine by default in Terminal.<\/p>\n\n<p>You can also use the Mac module <code>Carbon.Snd<\/code> to play the system beep:<\/p>\n\n<pre><code>&gt;&gt;&gt; import Carbon.Snd\n&gt;&gt;&gt; Carbon.Snd.SysBeep(1)\n&gt;&gt;&gt;\n<\/code><\/pre>\n\n<p>The Carbon modules don't have any documentation, so I had to use <code>help(Carbon.Snd)<\/code> to see what functions were available. It seems to be a direct interface onto Carbon, so the docs on Apple Developer Connection probably help.<\/p>\n",
                "<p>I tried the mixer from the pygame module, and it works fine. First install the module:<\/p>\n\n<pre><code>$ sudo apt-get install python-pygame\n<\/code><\/pre>\n\n<p>Then in the program, write this:<\/p>\n\n<pre><code>from pygame import mixer\nmixer.init() #you must initialize the mixer\nalert=mixer.Sound('bell.wav')\nalert.play()\n<\/code><\/pre>\n\n<p>With pygame you have a lot of customization options, which you may additionally experiment with.<\/p>\n",
                "<p>If you have PyObjC (the Python - Objective-C bridge) installed or are running on OS X 10.5's system python (which ships with PyObjC), you can do<\/p>\n\n<pre><code>from AppKit import NSBeep\nNSBeep()\n<\/code><\/pre>\n\n<p>to play the system alert.<\/p>\n",
                "<p>Have you tried :<\/p>\n\n<pre><code>import sys\nsys.stdout.write('\\a')\nsys.stdout.flush()\n<\/code><\/pre>\n\n<p>That works for me here on Mac OS 10.5<\/p>\n\n<p>Actually, I think your original attempt works also with a little modification:<\/p>\n\n<pre><code>print('\\a')\n<\/code><\/pre>\n\n<p>(You just need the single quotes around the character sequence).<\/p>\n"
            ]
        },
        {
            "tag": "questao_14281",
            "padroes": [
                "I have over a million text files compressed into 40 zip files. I also have a list of about 500 model names of phones. I want to find out the number of times a particular model was mentioned in the text files. \n\nIs there any python module which can do a regex match on the files without unzipping it. Is there a simple way to solve this problem without unzipping?\n"
            ],
            "respostas": [
                "<p>You could loop through the zip files, reading individual files using the zipfile module and running your regex on those, eliminating to unzip all the files at once. <\/p>\n\n<p>I'm fairly certain that you can't run a regex over the zipped data, at least not meaningfully.<\/p>\n",
                "<p>To access the contents of a zip file you have to unzip it, although the zipfile package makes this fairly easy, as you can unzip each file within an archive individually.<\/p>\n\n<p><a href=\"http:\/\/docs.python.org\/lib\/module-zipfile.html\" rel=\"nofollow\">Python zipfile module<\/a><\/p>\n",
                "<p>Isn't it (at least theoretically) possible, to read in the ZIP's Huffman coding and then translate the regexp into the Huffman code? Might this be more efficient than first de-compressing the data, then running the regexp?<\/p>\n\n<p>(Note: I know it wouldn't be quite that simple: you'd also have to deal with other aspects of the ZIP coding&mdash;file layout, block structures, back-references&mdash;but one imagines this could be fairly lightweight.)<\/p>\n\n<p>EDIT: Also note that it's probably much more sensible to just use the <code>zipfile<\/code> solution.<\/p>\n",
                "<p>There's nothing that will automatically do what you want.<\/p>\n\n<p>However, there is a python zipfile module that will make this easy to do.  Here's how to iterate over the lines in the file.<\/p>\n\n<pre><code>#!\/usr\/bin\/python\n\nimport zipfile\nf = zipfile.ZipFile('myfile.zip')\n\nfor subfile in f.namelist():\n    print subfile\n    data = f.read(subfile)\n    for line in data.split('\\n'):\n        print line\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_14389",
            "padroes": [
                "I have a script that parses the filenames of TV episodes (show.name.s01e02.avi for example), grabs the episode name (from the www.thetvdb.com API) and automatically renames them into something nicer (Show Name - [01x02].avi)\n\nThe script works fine, that is until you try and use it on files that have Unicode show-names (something I never really thought about, since all the files I have are English, so mostly pretty-much all fall within [a-zA-Z0-9'\\-])\n\nHow can I allow the regular expressions to match accented characters and the likes? Currently the regex's config section looks like..\n\nconfig['valid_filename_chars'] = \"\"\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!@-Ãº$%^&*()_+=-[]{\"'.,`~? \"\"\"\nconfig['valid_filename_chars_regex'] = re.escape(config['valid_filename_chars'])\n\nconfig['name_parse'] = [\n    # foo_[s01]_[e01]\n    re.compile('''^([%s]+?)[ \\._\\-]\\[[Ss]([0-9]+?)\\]_\\[[Ee]([0-9]+?)\\]?[^\\\\\/]*$'''% (config['valid_filename_chars_regex'])),\n    # foo.1x09*\n    re.compile('''^([%s]+?)[ \\._\\-]\\[?([0-9]+)x([0-9]+)[^\\\\\/]*$''' % (config['valid_filename_chars_regex'])),\n    # foo.s01.e01, foo.s01_e01\n    re.compile('''^([%s]+?)[ \\._\\-][Ss]([0-9]+)[\\.\\- ]?[Ee]([0-9]+)[^\\\\\/]*$''' % (config['valid_filename_chars_regex'])),\n    # foo.103*\n    re.compile('''^([%s]+)[ \\._\\-]([0-9]{1)([0-9]{2)[\\._ -][^\\\\\/]*$''' % (config['valid_filename_chars_regex'])),\n    # foo.0103*\n    re.compile('''^([%s]+)[ \\._\\-]([0-9]{2)([0-9]{2,3)[\\._ -][^\\\\\/]*$''' % (config['valid_filename_chars_regex'])),\n]\n\n"
            ],
            "respostas": [
                "<p>\\X seems to be available as a generic word-character in some languages, it allows you to match a single character disregarding of how many bytes it takes up. Might be useful.<\/p>\n",
                "<p>In Mastering Regular Expressions from Jeffrey Friedl (great book) it is mentioned that you could use \\p{Letter which will match unicode stuff that is considered a letter.<\/p>\n",
                "<p>Python's re module doesn't support \\p{Letter or \\X. However, the <a href=\"http:\/\/pypi.python.org\/pypi\/regex\" rel=\"nofollow\">new regex implementation on PyPI<\/a> does.<\/p>\n",
                "<p>Use a subrange of [\\u0000-\\uFFFF] for what you want.<\/p>\n\n<p>You can also use the re.UNICODE compile flag. <a href=\"http:\/\/docs.python.org\/lib\/re-syntax.html\">The docs<\/a> say that if UNICODE is set, \\w will match the characters [0-9_] plus whatever is classified as alphanumeric in the Unicode character properties database. <\/p>\n\n<p>See also <a href=\"http:\/\/coding.derkeiler.com\/Archive\/Python\/comp.lang.python\/2004-05\/2560.html\">http:\/\/coding.derkeiler.com\/Archive\/Python\/comp.lang.python\/2004-05\/2560.html<\/a>.<\/p>\n"
            ]
        },
        {
            "tag": "questao_8154",
            "padroes": [
                "[I hope this isn't too obscure&hellip; I'll ask the newsgroup if nobody knows here]\n\nI'm using Pylons (a python framework) to serve a simple web application, but it seems to die from time to time, with this in the error log: (2006, 'MySQL server has gone away')\n\nI did a bit of checking, and saw that this was because the connections to MySQL were not being renewed. This shouldn't be a problem though, because the sqlalchemy.pool_recycle in the config file should automatically keep it alive. The default was 3600, but I dialed it back to 1800 because of this problem. It helped a bit, but 3600 should be fine according to the docs. The errors still happen semi-regularly. I don't want to lower it too much though and DOS my own database :).\n\nMaybe something in my MySQL config is goofy? Not sure where to look exactly.\n\nOther relevant details:\n\n  Python 2.5\n  Pylons: 0.9.6.2 (w\/ sql_alchemy)\n  MySQL: 5.0.51\n\n"
            ],
            "respostas": [
                "<p>You might want to check MySQL's timeout variables:<\/p>\n\n<pre><code>show variables like '%timeout%';\n<\/code><\/pre>\n\n<p>You're probably interested in <code>wait_timeout<\/code> (less likely but possible: <code>interactive_timeout<\/code>).  On Debian and Ubuntu, the defaults are 28800 (MySQL kills connections after 8 hours), but maybe the default for your platform is different or whoever administrates the server has configured things differently.<\/p>\n\n<p>AFAICT, <code>pool_recycle<\/code> doesn't actually keep the connections alive, it expires them on its own before MySQL kills them.  I'm not familiar with pylons, but if causing the connections to intermittently do a <code>SELECT 1;<\/code> is an option, that will keep them alive at the cost of basically no server load and minimal network traffic.  One final thought: are you somehow managing to use a connection that pylons thinks it has expired?<\/p>\n",
                "<p>I think I fixed it. It's turns out I had a simple config error. My ini file read:<\/p>\n\n<pre><code>sqlalchemy.default.url = [connection string here]\nsqlalchemy.pool_recycle = 1800\n<\/code><\/pre>\n\n<p>The problem is that my <code>environment.py<\/code> file declared that the engine would only map keys with the prefix: <code>sqlalchemy.default<\/code> so <code>pool_recycle<\/code> was ignored.<\/p>\n\n<p>The solution is to simply change the second line in the ini to:<\/p>\n\n<pre><code>sqlalchemy.default.pool_recycle = 1800\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_15798",
            "padroes": [
                "I need to validate an XML string (and not a file)\nagainst a DTD description file. \n\nHow can that be done in python?\n"
            ],
            "respostas": [
                "<p>from the examples directory in the libxml2 python bindings:<\/p>\n\n<pre><code>#!\/usr\/bin\/python -u\nimport libxml2\nimport sys\n\n# Memory debug specific\nlibxml2.debugMemory(1)\n\ndtd=\"\"\"&lt;!ELEMENT foo EMPTY&gt;\"\"\"\ninstance=\"\"\"&lt;?xml version=\"1.0\"?&gt;\n&lt;foo&gt;&lt;\/foo&gt;\"\"\"\n\ndtd = libxml2.parseDTD(None, 'test.dtd')\nctxt = libxml2.newValidCtxt()\ndoc = libxml2.parseDoc(instance)\nret = doc.validateDtd(ctxt, dtd)\nif ret != 1:\n    print \"error doing DTD validation\"\n    sys.exit(1)\n\ndoc.freeDoc()\ndtd.freeDtd()\ndel dtd\ndel ctxt\n<\/code><\/pre>\n",
                "<p>Another good option is <a href=\"http:\/\/lxml.de\/validation.html\" rel=\"nofollow\">lxml's validation<\/a> which I find quite pleasant to use.<\/p>\n\n<p>A simple example taken from the lxml site:<\/p>\n\n<pre><code>from StringIO import StringIO\n\nfrom lxml import etree\n\ndtd = etree.DTD(StringIO(\"\"\"&lt;!ELEMENT foo EMPTY&gt;\"\"\"))\nroot = etree.XML(\"&lt;foo\/&gt;\")\nprint(dtd.validate(root))\n# True\n\nroot = etree.XML(\"&lt;foo&gt;bar&lt;\/foo&gt;\")\nprint(dtd.validate(root))\n# False\nprint(dtd.error_log.filter_from_errors())\n# &lt;string&gt;:1:0:ERROR:VALID:DTD_NOT_EMPTY: Element foo was declared EMPTY this one has content\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_16067",
            "padroes": [
                "I have been mulling over writing a peak fitting library for a while. I know Python fairly well and plan on implementing everything in Python to begin with but envisage that I may have to re-implement some core routines in a compiled language eventually.\n\nIIRC, one of Python's original remits was as a prototyping language, however Python is pretty liberal in allowing functions, functors, objects to be passed to functions and methods, whereas I suspect the same is not true of say C or Fortran.\n\nWhat should I know about designing functions\/classes which I envisage will have to interface into the compiled language? And how much of these potential problems are dealt with by libraries such as cTypes, bgen, SWIG, Boost.Python, Cython or Python SIP?\n\nFor this particular use case, (a fitting library) I imagine allowing users to define mathematical functions (Guassian, Lorentzian etc.) as Python functions which can then to be passed an interpreted by the compiled code fitting library. Passing and returning arrays is also essential.\n"
            ],
            "respostas": [
                "<blockquote>\n  <p>Python is pretty liberal in allowing functions, functors, objects to be passed to functions and methods, whereas I suspect the same is not true of say C or Fortran.<\/p>\n<\/blockquote>\n\n<p>In C you cannot pass a function as an argument to a function but you can pass a function pointer which is just as good a function.<\/p>\n\n<p>I don't know how much that would help when you are trying to integrate C and Python code but I just wanted to clear up one misconception.<\/p>\n",
                "<p>In addition to the tools above, I can recommend using <a href=\"http:\/\/www.cosc.canterbury.ac.nz\/greg.ewing\/python\/Pyrex\/\" rel=\"nofollow\" title=\"Pyrex\">Pyrex<\/a> \n(for creating Python extension modules) or <a href=\"http:\/\/psyco.sourceforge.net\/\" rel=\"nofollow\" title=\"Psyco\">Psyco<\/a> (as JIT compiler for Python).<\/p>\n",
                "<p>In my experience, there are two easy ways to call into C code from Python code.  There are other approaches, all of which are more annoying and\/or verbose.<\/p>\n\n<p>The first and easiest is to compile a bunch of C code as a separate shared library and then call functions in that library using ctypes.  Unfortunately, passing anything other than basic data types is non-trivial.<\/p>\n\n<p>The second easiest way is to write a Python module in C and then call functions in that module.  You can pass anything you want to these C functions without having to jump through any hoops.  And it's easy to call Python functions or methods from these C functions, as described here: <a href=\"https:\/\/docs.python.org\/extending\/extending.html#calling-python-functions-from-c\" rel=\"nofollow\">https:\/\/docs.python.org\/extending\/extending.html#calling-python-functions-from-c<\/a><\/p>\n\n<p>I don't have enough experience with SWIG to offer intelligent commentary.  And while it is possible to do things like pass custom Python objects to C functions through ctypes, or to define new Python classes in C, these things are annoying and verbose and I recommend taking one of the two approaches described above.<\/p>\n",
                "<p><a href=\"http:\/\/cens.ioc.ee\/projects\/f2py2e\/usersguide\/index.html#the-quick-and-smart-way\" rel=\"nofollow\">f2py<\/a> (part of <code>numpy<\/code>) is a simpler alternative to SWIG and boost.python for wrapping C\/Fortran number-crunching code.<\/p>\n",
                "<p>The best way to plan for an eventual transition to compiled code is to write the performance sensitive portions as a module of simple functions in a <a href=\"http:\/\/en.wikipedia.org\/wiki\/Functional_programming\" rel=\"nofollow\">functional style<\/a> (stateless and without side effects), which accept and return basic data types.<\/p>\n\n<p>This will provide a one-to-one mapping from your Python prototype code to the eventual compiled code, and will let you use <a href=\"https:\/\/docs.python.org\/library\/ctypes.html\" rel=\"nofollow\">ctypes<\/a> easily and avoid a whole bunch of headaches.<\/p>\n\n<p>For peak fitting, you'll almost certainly need to use arrays, which will complicate things a little, but is still very doable with ctypes.<\/p>\n\n<p>If you really want to use more complicated data structures, or modify the passed arguments, <a href=\"http:\/\/www.swig.org\/\" rel=\"nofollow\">SWIG<\/a> or <a href=\"https:\/\/docs.python.org\/extending\/\" rel=\"nofollow\">Python's standard C-extension interface<\/a> will let you do what you want, but with some amount of hassle.<\/p>\n\n<p>For what you're doing, you may also want to check out <a href=\"http:\/\/numpy.scipy.org\/\" rel=\"nofollow\">NumPy<\/a>, which might do some of the work you would want to push to C, as well as offering <a href=\"http:\/\/projects.scipy.org\/scipy\/numpy\/wiki\/NumPyCAPI\" rel=\"nofollow\">some additional help in moving data back and forth between Python and C<\/a>.<\/p>\n",
                "<p>I haven't used SWIG or SIP, but I find writing Python wrappers with <a href=\"http:\/\/www.boost.org\/doc\/libs\/1_35_0\/libs\/python\/doc\/index.html\" rel=\"nofollow\">boost.python<\/a> to be very powerful and relatively easy to use.<\/p>\n\n<p>I'm not clear on what your requirements are for passing types between C\/C++ and python, but you can do that easily by either exposing a C++ type to python, or by using a generic <a href=\"http:\/\/www.boost.org\/doc\/libs\/1_35_0\/libs\/python\/doc\/v2\/object.html\" rel=\"nofollow\">boost::python::object<\/a> argument to your C++ API. You can also register converters to automatically convert python types to C++ types and vice versa.<\/p>\n\n<p>If you plan use boost.python, the <a href=\"http:\/\/www.boost.org\/doc\/libs\/1_35_0\/libs\/python\/doc\/tutorial\/doc\/html\/index.html\" rel=\"nofollow\">tutorial<\/a> is a good place to start.<\/p>\n\n<p>I have implemented something somewhat similar to what you need. I have a C++ function that \naccepts a python function and an image as arguments, and applies the python function to each pixel in the image.<\/p>\n\n<pre><code>Image* unary(boost::python::object op, Image&amp; im)\n{\n    Image* out = new Image(im.width(), im.height(), im.channels());\n    for(unsigned int i=0; i&lt;im.size(); i++)\n    {\n        (*out)[i] == extract&lt;float&gt;(op(im[i]));\n    \n    return out;\n\n<\/code><\/pre>\n\n<p>In this case, Image is a C++ object exposed to python (an image with float pixels), and op is a python defined function  (or really any python object with a &#95;&#95;call&#95;&#95; attribute). You can then use this function as follows (assuming unary is located in the called image that also contains Image and a load function):<\/p>\n\n<pre><code>import image\nim = image.load('somefile.tiff')\ndouble_im = image.unary(lambda x: 2.0*x, im)\n<\/code><\/pre>\n\n<p>As for using arrays with boost, I personally haven't done this, but I know the functionality to expose arrays to python using boost is available - <a href=\"http:\/\/www.boost.org\/doc\/libs\/1_35_0\/libs\/python\/doc\/v2\/faq.html#question2\" rel=\"nofollow\">this<\/a> might be helpful.<\/p>\n",
                "<p>Finally a question that I can really put a value answer to :). <\/p>\n\n<p>I have investigated f2py, boost.python, swig, cython and pyrex for my work (PhD in optical measurement techniques). I used swig extensively, boost.python some and pyrex and cython a lot. I also used ctypes. This is my breakdown:<\/p>\n\n<p><strong>Disclaimer<\/strong>: This is my personal experience. I am not involved with any of these projects. <\/p>\n\n<p><strong>swig:<\/strong>\ndoes not play well with c++. It should, but name mangling problems in the linking step was a major headache for me on linux &amp; Mac OS X. If you have C code and want it interfaced to python, it is a good solution. I wrapped the GTS for my needs and needed to write basically a C shared library which I could connect to. I would not recommend it.<\/p>\n\n<p><strong>Ctypes:<\/strong>\nI wrote a libdc1394 (IEEE Camera library) wrapper using ctypes and it was a very straigtforward experience. You can find the code on <a href=\"https:\/\/launchpad.net\/pydc1394\">https:\/\/launchpad.net\/pydc1394<\/a>. It is a lot of work to convert headers to python code, but then everything works reliably. This is a good way if you want to interface an external library. Ctypes is also in the stdlib of python, so everyone can use your code right away. This is also a good way to play around with a new lib in python quickly. I can recommend it to interface to external libs. <\/p>\n\n<p><strong>Boost.Python<\/strong>: Very enjoyable. If you already have C++ code of your own that you want to use in python, go for this. It is very easy to translate c++ class structures into python class structures this way. I recommend it if you have c++ code that you need in python. <\/p>\n\n<p><strong>Pyrex\/Cython:<\/strong> Use Cython, not Pyrex. Period. Cython is more advanced and more enjoyable to use. Nowadays, I do everything with cython that i used to do with SWIG or Ctypes. It is also the best way if you have python code that runs too slow. The process is absolutely fantastic: you convert your python modules into cython modules, build them and keep profiling and optimizing like it still was python (no change of tools needed). You can then apply as much (or as little) C code mixed with your python code. This is by far faster then having to rewrite whole parts of your application in C; you only rewrite the inner loop. <\/p>\n\n<p><strong>Timings<\/strong>: ctypes has the highest call overhead (~700ns), followed by boost.python (322ns), then directly by swig (290ns). Cython has the lowest call overhead (124ns) and the best feedback where it spends time on (cProfile support!). The numbers are from my box calling a trivial function that returns an integer from an interactive shell; module import overhead is therefore not timed, only function call overhead is. It is therefore easiest and most productive to get python code fast by profiling and using cython.<\/p>\n\n<p><strong>Summary<\/strong>: For your problem, use Cython ;). I hope this rundown will be useful for some people. I'll gladly answer any remaining question.<\/p>\n\n<p><hr \/><\/p>\n\n<p><strong>Edit<\/strong>: I forget to mention: for numerical purposes (that is, connection to NumPy) use Cython; they have support for it (because they basically develop cython for this purpose). So this should be another +1 for your decision. <\/p>\n"
            ]
        },
        {
            "tag": "questao_16861",
            "padroes": [
                "What's the best way to sanitise user input for a Python-based web application? Is there a single function to remove HTML characters and any other necessary characters combinations to prevent an XSS or SQL injection attack?\n"
            ],
            "respostas": [
                "<p>If you are using a framework like <a href=\"http:\/\/www.djangoproject.com\/\" rel=\"nofollow\">django<\/a>, the framework can easily do this for you using standard filters.  In fact, I'm pretty sure django automatically does it unless you tell it not to.<\/p>\n\n<p>Otherwise, I would recommend using some sort of regex validation before accepting inputs from forms.  I don't think there's a silver bullet for your problem, but using the re module, you should be able to construct what you need.<\/p>\n",
                "<p>To sanitize a string input which you want to store to the database (for example a customer name) you need either to escape it or plainly remove any quotes (', \") from it. This effectively prevents classical SQL injection which can happen if you are assembling an SQL query from strings passed by the user.<\/p>\n\n<p>For example (if it is acceptable to remove quotes completely):<\/p>\n\n<pre><code>datasetName = datasetName.replace(\"'\",\"\").replace('\"',\"\")\n<\/code><\/pre>\n",
                "<p>I don't do web development much any longer, but when I did, I did something like so:<\/p>\n\n<p>When no parsing is supposed to happen, I usually just escape the data to not interfere with the database when I store it, and escape everything I read up from the database to not interfere with html when I display it (cgi.escape() in python).<\/p>\n\n<p>Chances are, if someone tried to input html characters or stuff, they actually wanted that to be displayed as text anyway. If they didn't, well tough :)<\/p>\n\n<p>In short always escape what can affect the current target for the data.<\/p>\n\n<p>When I did need some parsing (markup or whatever) I usually tried to keep that language in a non-intersecting set with html so I could still just store it suitably escaped (after validating for syntax errors) and parse it to html when displaying without having to worry about the data the user put in there interfering with your html.<\/p>\n\n<p>See also <a href=\"http:\/\/wiki.python.org\/moin\/EscapingHtml\" rel=\"nofollow\">Escaping HTML<\/a><\/p>\n",
                "<p>Jeff Atwood himself described how StackOverflow.com sanitizes user input (in non-language-specific terms) on the Stack Overflow blog: <a href=\"http:\/\/blog.stackoverflow.com\/2008\/06\/safe-html-and-xss\/\" rel=\"nofollow\">http:\/\/blog.stackoverflow.com\/2008\/06\/safe-html-and-xss\/<\/a><\/p>\n\n<p>However, as Justin points out, if you use Django templates or something similar then they probably sanitize your HTML output anyway.<\/p>\n\n<p>SQL injection also shouldn't be a concern.  All of Python's database libraries (MySQLdb, cx_Oracle, etc) always sanitize the parameters you pass.  These libraries are used by all of Python's object-relational mappers (such as Django models), so you don't need to worry about sanitation there either.<\/p>\n",
                "<p>The best way to prevent XSS is not to try and filter everything, but rather to simply do HTML Entity encoding.  For example, automatically turn &lt; into &amp;lt;.  This is the ideal solution assuming you don't need to accept any html input (outside of forum\/comment areas where it is used as markup, it should be pretty rare to need to accept HTML); there are so many permutations via alternate encodings that anything but an ultra-restrictive whitelist (a-z,A-Z,0-9 for example) is going to let something through.<\/p>\n\n<p>SQL Injection, contrary to other opinion, is still possible, if you are just building out a query string.  For example, if you are just concatenating an incoming parameter onto a query string, you will have SQL Injection.  The best way to protect against this is also not filtering, but rather to religiously use parameterized queries and NEVER concatenate user input.<\/p>\n\n<p>This is not to say that filtering isn't still a best practice, but in terms of SQL Injection and XSS, you will be far more protected if you religiously use Parameterize Queries and HTML Entity Encoding.<\/p>\n",
                "<p><strong>Edit<\/strong>: <a href=\"https:\/\/github.com\/jsocol\/bleach\">bleach<\/a> is a wrapper around html5lib which makes it even easier to use as a whitelist-based sanitiser.<\/p>\n\n<p><a href=\"http:\/\/code.google.com\/p\/html5lib\/\"><code>html5lib<\/code><\/a> comes with a whitelist-based HTML sanitiser - it's easy to subclass it to restrict the tags and attributes users are allowed to use on your site, and it even attempts to sanitise CSS if you're allowing use of the <code>style<\/code> attribute.<\/p>\n\n<p>Here's now I'm using it in my Stack Overflow clone's <code>sanitize_html<\/code> utility function:<\/p>\n\n<p><a href=\"http:\/\/code.google.com\/p\/soclone\/source\/browse\/trunk\/soclone\/utils\/html.py\">http:\/\/code.google.com\/p\/soclone\/source\/browse\/trunk\/soclone\/utils\/html.py<\/a><\/p>\n\n<p>I've thrown all the attacks listed in <a href=\"http:\/\/ha.ckers.org\/xss.html\">ha.ckers.org's XSS Cheatsheet<\/a> (which are handily <a href=\"http:\/\/ha.ckers.org\/xssAttacks.xml\">available in XML format<\/a> at it after performing Markdown to HTML conversion using <a href=\"http:\/\/code.google.com\/p\/python-markdown2\/\">python-markdown2<\/a> and it seems to have held up ok.<\/p>\n\n<p>The WMD editor component which Stackoverflow currently uses is a problem, though - I actually had to disable JavaScript in order to test the XSS Cheatsheet attacks, as pasting them all into WMD ended up giving me alert boxes and blanking out the page.<\/p>\n",
                "<p>Here is a snippet that will remove all tags not on the white list, and all tag attributes not on the attribues whitelist (so you can't use <code>onclick<\/code>).<\/p>\n\n<p>It is a modified version of <a href=\"http:\/\/www.djangosnippets.org\/snippets\/205\/\">http:\/\/www.djangosnippets.org\/snippets\/205\/<\/a>, with the regex on the attribute values to prevent people from using <code>href=\"javascript:...\"<\/code>, and other cases described at <a href=\"http:\/\/ha.ckers.org\/xss.html\">http:\/\/ha.ckers.org\/xss.html<\/a>.<br>\n(e.g. <code>&lt;a href=\"ja&amp;#x09;vascript:alert('hi')\"&gt;<\/code> or <code>&lt;a href=\"ja  vascript:alert('hi')\"&gt;<\/code>, etc.)<\/p>\n\n<p>As you can see, it uses the (awesome) <a href=\"http:\/\/www.crummy.com\/software\/BeautifulSoup\/\">BeautifulSoup<\/a> library.<\/p>\n\n<pre><code>import re\nfrom urlparse import urljoin\nfrom BeautifulSoup import BeautifulSoup, Comment\n\ndef sanitizeHtml(value, base_url=None):\n    rjs = r'[\\s]*(&amp;#x.{1,7)?'.join(list('javascript:'))\n    rvb = r'[\\s]*(&amp;#x.{1,7)?'.join(list('vbscript:'))\n    re_scripts = re.compile('(%s)|(%s)' % (rjs, rvb), re.IGNORECASE)\n    validTags = 'p i strong b u a h1 h2 h3 pre br img'.split()\n    validAttrs = 'href src width height'.split()\n    urlAttrs = 'href src'.split() # Attributes which should have a URL\n    soup = BeautifulSoup(value)\n    for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n        # Get rid of comments\n        comment.extract()\n    for tag in soup.findAll(True):\n        if tag.name not in validTags:\n            tag.hidden = True\n        attrs = tag.attrs\n        tag.attrs = []\n        for attr, val in attrs:\n            if attr in validAttrs:\n                val = re_scripts.sub('', val) # Remove scripts (vbs &amp; js)\n                if attr in urlAttrs:\n                    val = urljoin(base_url, val) # Calculate the absolute url\n                tag.attrs.append((attr, val))\n\n    return soup.renderContents().decode('utf8')\n<\/code><\/pre>\n\n<p>As the other posters have said, pretty much all Python db libraries take care of SQL injection, so this should pretty much cover you.<\/p>\n"
            ]
        },
        {
            "tag": "questao_17250",
            "padroes": [
                "I'm creating an ZIP file with ZipFile in Python 2.5, it works ok so far:\n\nimport zipfile, os\n\nlocfile = \"test.txt\"\nloczip = os.path.splitext (locfile)[0] + \".zip\"\nzip = zipfile.ZipFile (loczip, \"w\")\nzip.write (locfile)\nzip.close()\n\n\nbut I couldn't find how to encrypt the files in the ZIP file.\nI could use system and call PKZIP -s, but I suppose there must be a more \"Pythonic\" way.  I'm looking for an open source solution.\n"
            ],
            "respostas": [
                "<p>You can use the <a href=\"http:\/\/www.chilkatsoft.com\/python.asp\" rel=\"nofollow\">Chilkat<\/a> library.  It's commercial, but has a free evaluation and seems pretty nice.<\/p>\n\n<p>Here's an example I got from <a href=\"http:\/\/www.example-code.com\/python\/zip.asp\" rel=\"nofollow\">here<\/a>:<\/p>\n\n<pre><code>import chilkat\n\n# Demonstrates how to create a WinZip-compatible 128-bit AES strong encrypted zip\nzip = chilkat.CkZip()\nzip.UnlockComponent(\"anything for 30-day trial\")\n\nzip.NewZip(\"strongEncrypted.zip\")\n\n# Set the Encryption property = 4, which indicates WinZip compatible AES encryption.\nzip.put_Encryption(4)\n# The key length can be 128, 192, or 256.\nzip.put_EncryptKeyLength(128)\nzip.SetPassword(\"secret\")\n\nzip.AppendFiles(\"exampleData\/*\",True)\nzip.WriteZip()\n<\/code><\/pre>\n",
                "<p>The duplicate question <a href=\"http:\/\/stackoverflow.com\/a\/2366917\/874188\">http:\/\/stackoverflow.com\/a\/2366917\/874188<\/a> recommends using <code>7z<\/code> instead of <code>zip<\/code>.  My experience bears this out.<\/p>\n\n<p>Copy\/pasting the answer by @JFSebastian here too for completeness:<\/p>\n\n<p>To create encrypted zip archive (named <code>'myarchive.zip'<\/code>) using open-source <a href=\"http:\/\/www.7-zip.org\/\" rel=\"nofollow\"><code>7-Zip<\/code><\/a> utility:<\/p>\n\n<pre><code>rc = subprocess.call(['7z', 'a', '-pP4$$W0rd', '-y', 'myarchive.zip'] + \n                     ['first_file.txt', 'second.file'])\n<\/code><\/pre>\n\n<p>To install 7-Zip, type:<\/p>\n\n<pre><code>$ sudo apt-get install p7zip-full\n<\/code><\/pre>\n\n<p>To unzip by hand (to demonstrate compatibility with zip utitity), type:<\/p>\n\n<pre><code>$ unzip myarchive.zip\n<\/code><\/pre>\n\n<p>And enter <code>P4$$W0rd<\/code> at the prompt.<\/p>\n\n<p>Or the same in Python 2.6+:<\/p>\n\n<pre><code>&gt;&gt;&gt; zipfile.ZipFile('myarchive.zip').extractall(pwd='P4$$W0rd')\n<\/code><\/pre>\n",
                "<p>I created a simple library to create a password encrypted zip file in python. - <a href=\"https:\/\/github.com\/smihica\/pyminizip\"><strong>here<\/strong><\/a><\/p>\n\n<pre><code>import pyminizip\n\ncompression_level = 5 # 1-9\npyminizip.compress(\"src.txt\", \"dst.zip\", \"password\", compression_level)\n<\/code><\/pre>\n\n<p><strong>The library requires zlib.<\/strong><\/p>\n\n<p>I have checked that the file can be extracted in WINDOWS\/MAC.<\/p>\n"
            ]
        },
        {
            "tag": "questao_17893",
            "padroes": [
                "My current setup.py script works okay, but it installs tvnamer.py (the tool) as \"tvnamer.py\" into site-packages or somewhere similar..\n\nCan I make setup.py install tvnamer.py as tvnamer, and\/or is there a better way of installing command-line applications?\n"
            ],
            "respostas": [
                "<p>Try the <code>entry_points.console_scripts<\/code> parameter in the setup() call. As described in the <a href=\"http:\/\/peak.telecommunity.com\/DevCenter\/setuptools#automatic-script-creation\">setuptools docs<\/a>, this should do what I think you want.<\/p>\n\n<p>To reproduce here:<\/p>\n\n<pre><code>from setuptools import setup\n\nsetup(\n    # other arguments here...\n    entry_points = {\n        'console_scripts': [\n            'foo = package.module:func',\n            'bar = othermodule:somefunc',\n        ],\n    \n)\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_19151",
            "padroes": [
                "How would one create an iterative function (or iterator object) in python?\n"
            ],
            "respostas": [
                "<p>This is an iterable function without <code>yield<\/code>. It make use of the <code>iter<\/code> function and a closure which keeps it's state in a mutable (<code>list<\/code>) in the enclosing scope for python 2.  <\/p>\n\n<pre><code>def count(low, high):\n    counter = [0]\n    def tmp():\n        val = low + counter[0]\n        if val &lt; high:\n            counter[0] += 1\n            return val\n        return None\n    return iter(tmp, None)\n<\/code><\/pre>\n\n<p>For Python 3, closure state is kept in an immutable in the enclosing scope and <code>nonlocal<\/code> is used in local scope to update the state variable.  <\/p>\n\n<pre><code>def count(low, high):\n    counter = 0\n    def tmp():\n        nonlocal counter\n        val = low + counter\n        if val &lt; high:\n            counter += 1\n            return val\n        return None\n    return iter(tmp, None)  \n<\/code><\/pre>\n\n<p>Test;<\/p>\n\n<pre><code>for i in count(1,10):\n    print(i)\n1\n2\n3\n4\n5\n6\n7\n8\n9\n<\/code><\/pre>\n",
                "<p>This question is about iterable objects, not about iterators. In Python, sequences are iterable too so one way to make an iterable class is to  make it behave like a sequence, i.e. give it <code>__getitem__<\/code> and <code>__len__<\/code> methods. I have tested this on Python 2 and 3.<\/p>\n\n<pre><code>class CustomRange:\n\n    def __init__(self, low, high):\n        self.low = low\n        self.high = high\n\n    def __getitem__(self, item):\n        if item &gt;= len(self):\n            raise IndexError(\"CustomRange index out of range\")\n        return self.low + item\n\n    def __len__(self):\n        return self.high - self.low\n\n\ncr = CustomRange(0, 10)\nfor i in cr:\n    print(i)\n<\/code><\/pre>\n",
                "<p>I see some of you doing <code>return self<\/code> in <code>__iter__<\/code>. I just wanted to note that <code>__iter__<\/code> itself can be a generator (thus removing the need for <code>__next__<\/code> and raising <code>StopIteration<\/code> exceptions)<\/p>\n\n<pre><code>class range:\n  def __init__(self,a,b):\n    self.a = a\n    self.b = b\n  def __iter__(self):\n    i = self.a\n    while i &lt; self.b:\n      yield i\n      i+=1\n<\/code><\/pre>\n\n<p>Of course here one might as well directly make a generator, but for more complex classes it can be useful.<\/p>\n",
                "<p>First of all the <a href=\"https:\/\/docs.python.org\/3\/library\/itertools.html\">itertools module<\/a> is incredibly useful for all sorts of cases in which an iterator would be useful, but here is all you need to create an iterator in python:<\/p>\n\n<blockquote>\n  <p>yield<\/p>\n<\/blockquote>\n\n<p>Isn't that cool?  Yield can be used to replace a normal <strong>return<\/strong> in a function.  It returns the object just the same, but instead of destroying state and exiting, it saves state for when you want to execute the next iteration.  Here is an example of it in action pulled directly from the <a href=\"http:\/\/docs.python.org\/lib\/itertools-functions.html\">itertools function list<\/a>:<\/p>\n\n<pre><code> def count(n=0):\n     while True:\n         yield n\n         n += 1\n<\/code><\/pre>\n\n<p>As stated in the functions description (it's the <strong>count()<\/strong> function from the itertools module...) , it produces an iterator that returns consecutive integers starting with n.<\/p>\n\n<p><a href=\"https:\/\/docs.python.org\/2\/reference\/expressions.html#generator-expressions\">Generator expressions<\/a> are a whole other can of worms (awesome worms!).  They may be used in place of a <a href=\"http:\/\/www.secnetix.de\/olli\/Python\/list_comprehensions.hawk\">List Comprehension<\/a> to save memory (list comprehensions create a list in memory that is destroyed after use if not assigned to a variable, but generator expressions can create a Generator Object... which is a fancy way of saying Iterator). Here is an example of a generator expression definition:<\/p>\n\n<pre><code>gen = (n for n in xrange(0,11))\n<\/code><\/pre>\n\n<p>This is very similar to our iterator definition above except the full range is predetermined to be between 0 and 10.<\/p>\n\n<p>I just found <strong>xrange()<\/strong> (suprised I hadn't seen it before...) and added it to the above example.  <strong>xrange()<\/strong> is an iterable version of <strong>range()<\/strong> which has the advantage of not prebuilding the list.  It would be  very useful if you had a giant corpus of data to iterate over and only had so much memory to do it in.<\/p>\n",
                "<p>There are four ways to build an iterative function:<\/p>\n\n<ul>\n<li>create a generator (uses the <a href=\"http:\/\/docs.python.org\/py3k\/reference\/expressions.html#yield-expressions\">yield keyword<\/a>)<\/li>\n<li>use a generator expression (<a href=\"http:\/\/docs.python.org\/py3k\/reference\/expressions.html#generator-expressions\">genexp<\/a>)<\/li>\n<li>create an iterator (defines <a href=\"http:\/\/docs.python.org\/py3k\/library\/stdtypes.html?highlight=__iter__#iterator-types\"><code>__iter__<\/code> and <code>__next__<\/code><\/a> (or <code>next<\/code> in Python 2.x))<\/li>\n<li>create a function that Python can iterate over on its own (<a href=\"http:\/\/docs.python.org\/py3k\/reference\/datamodel.html?highlight=__getitem__#object.__getitem__\">defines <code>__getitem__<\/code><\/a>)<\/li>\n<\/ul>\n\n<p>Examples:<\/p>\n\n<pre><code># generator\ndef uc_gen(text):\n    for char in text:\n        yield char.upper()\n\n# generator expression\ndef uc_genexp(text):\n    return (char.upper() for char in text)\n\n# iterator protocol\nclass uc_iter():\n    def __init__(self, text):\n        self.text = text\n        self.index = 0\n    def __iter__(self):\n        return self\n    def __next__(self):\n        try:\n            result = self.text[self.index].upper()\n        except IndexError:\n            raise StopIteration\n        self.index += 1\n        return result\n\n# getitem method\nclass uc_getitem():\n    def __init__(self, text):\n        self.text = text\n    def __getitem__(self, index):\n        result = self.text[index].upper()\n        return result\n<\/code><\/pre>\n\n<p>To see all four methods in action:<\/p>\n\n<pre><code>for iterator in uc_gen, uc_genexp, uc_iter, uc_getitem:\n    for ch in iterator('abcde'):\n        print ch,\n    print\n<\/code><\/pre>\n\n<p>Which results in:<\/p>\n\n<pre><code>A B C D E\nA B C D E\nA B C D E\nA B C D E\n<\/code><\/pre>\n\n<p><strong>Note<\/strong>:<\/p>\n\n<p>The two generator types (<code>uc_gen<\/code> and <code>uc_genexp<\/code>) cannot be <code>reversed()<\/code>; the plain iterator (<code>uc_iter<\/code>) would need the <code>__reversed__<\/code> magic method (which must return a new iterator that goes backwards); and the getitem iteratable (<code>uc_getitem<\/code>) must have the <code>__len__<\/code> magic method:<\/p>\n\n<pre><code>    # for uc_iter\n    def __reversed__(self):\n        return reversed(self.text)\n\n    # for uc_getitem\n    def __len__(self)\n        return len(self.text)\n<\/code><\/pre>\n\n<hr>\n\n<p>To answer Colonel Panic's secondary question about an infinite lazily evaluated iterator, here are those examples, using each of the four methods above:<\/p>\n\n<pre><code># generator\ndef even_gen():\n    result = 0\n    while True:\n        yield result\n        result += 2\n\n\n# generator expression\ndef even_genexp():\n    return (num for num in even_gen())  # or even_iter or even_getitem\n                                        # not much value under these circumstances\n\n# iterator protocol\nclass even_iter():\n    def __init__(self):\n        self.value = 0\n    def __iter__(self):\n        return self\n    def __next__(self):\n        next_value = self.value\n        self.value += 2\n        return next_value\n\n# getitem method\nclass even_getitem():\n    def __getitem__(self, index):\n        return index * 2\n\nimport random\nfor iterator in even_gen, even_genexp, even_iter, even_getitem:\n    limit = random.randint(15, 30)\n    count = 0\n    for even in iterator():\n        print even,\n        count += 1\n        if count &gt;= limit:\n            break\n    print\n<\/code><\/pre>\n\n<p>Which results in (at least for my sample run):<\/p>\n\n<pre><code>0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54\n0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38\n0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30\n0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32\n<\/code><\/pre>\n",
                "<p>Iterator objects in python conform to the iterator protocol, which basically means they provide two methods: <code>__iter__()<\/code>  and  <code>next()<\/code>.  The <code>__iter__<\/code> returns the iterator object and is implicitly called at the start of loops.  The <code>next()<\/code> method returns the next value and is implicitly called at each loop increment.  <code>next()<\/code> raises a StopIteration exception when there are no more value to return, which is implicitly captured by looping constructs to stop iterating.<\/p>\n\n<p>Here's a simple example of a counter:<\/p>\n\n<pre><code>class Counter:\n    def __init__(self, low, high):\n        self.current = low\n        self.high = high\n\n    def __iter__(self):\n        return self\n\n    def next(self): # Python 3: def __next__(self)\n        if self.current &gt; self.high:\n            raise StopIteration\n        else:\n            self.current += 1\n            return self.current - 1\n\n\nfor c in Counter(3, 8):\n    print c\n<\/code><\/pre>\n\n<p>This will print:<\/p>\n\n<pre><code>3\n4\n5\n6\n7\n8\n<\/code><\/pre>\n\n<p>This is easier to write using a generator, as covered in a previous answer:<\/p>\n\n<pre><code>def counter(low, high):\n    current = low\n    while current &lt;= high:\n        yield current\n        current += 1\n\nfor c in counter(3, 8):\n    print c\n<\/code><\/pre>\n\n<p>The printed output will be the same.  Under the hood, the generator object supports the iterator protocol and does something roughly similar to the class Counter.<\/p>\n\n<p>David Mertz's article, <a href=\"https:\/\/www.ibm.com\/developerworks\/library\/l-pycon\/\">Iterators and Simple Generators<\/a>, is a pretty good introduction. <\/p>\n"
            ]
        },
        {
            "tag": "questao_19339",
            "padroes": [
                "I have a list of 2-item tuples and I'd like to convert them to 2 lists where the first contains the first item in each tuple and the second list holds the second item.\n\nFor example:\n\noriginal = [('a', 1), ('b', 2), ('c', 3), ('d', 4)]\n# and I want to become...\nresult = (['a', 'b', 'c', 'd'], [1, 2, 3, 4])\n\n\nIs there a builtin function that does that?\n"
            ],
            "respostas": [
                "<p>It's only another way to do it but it helped me a lot so I write it here:<\/p>\n\n<p>Having this data structure:<\/p>\n\n<pre><code>X=[1,2,3,4]\nY=['a','b','c','d']\nXY=zip(X,Y)\n<\/code><\/pre>\n\n<p>Resulting in:<\/p>\n\n<pre><code>In: XY\nOut: [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]\n<\/code><\/pre>\n\n<p>The more pythonic way to unzip it and go back to the original is this one in my opinion:<\/p>\n\n<pre><code>x,y=zip(*XY)\n<\/code><\/pre>\n\n<p>But this return a tuple so if you need an array you can use:<\/p>\n\n<pre><code>xy=(list(x),list(y))\n<\/code><\/pre>\n",
                "<pre><code>&gt;&gt;&gt; original = [('a', 1), ('b', 2), ('c', 3), ('d', 4)]\n&gt;&gt;&gt; tuple([list(tup) for tup in zip(*original)])\n(['a', 'b', 'c', 'd'], [1, 2, 3, 4])\n<\/code><\/pre>\n\n<p>Gives a tuple of lists as in the question.<\/p>\n\n<pre><code>list1, list2 = [list(tup) for tup in zip(*original)]\n<\/code><\/pre>\n\n<p>Unpacks the two lists.<\/p>\n",
                "<p>I like to use <code>zip(*iterable)<\/code> (which is the piece of code you're looking for) in my programs as so:<\/p>\n\n<pre><code>def unzip(iterable):\n    return zip(*iterable)\n<\/code><\/pre>\n\n<p>I find <code>unzip<\/code> more readable.<\/p>\n",
                "<p>If you have lists that are not the same length, you may not want to use zip as per Patricks answer. This works:<\/p>\n\n<pre><code>&gt;&gt;&gt; zip(*[('a', 1), ('b', 2), ('c', 3), ('d', 4)])\n[('a', 'b', 'c', 'd'), (1, 2, 3, 4)]\n<\/code><\/pre>\n\n<p>But with different length lists, zip truncates each item to the length of the shortest list:<\/p>\n\n<pre><code>&gt;&gt;&gt; zip(*[('a', 1), ('b', 2), ('c', 3), ('d', 4), ('e', )])\n[('a', 'b', 'c', 'd', 'e')]\n<\/code><\/pre>\n\n<p>You can use map with no function to fill empty results with None:<\/p>\n\n<pre><code>&gt;&gt;&gt; map(None, *[('a', 1), ('b', 2), ('c', 3), ('d', 4), ('e', )])\n[('a', 'b', 'c', 'd', 'e'), (1, 2, 3, 4, None)]\n<\/code><\/pre>\n\n<p>zip() is marginally faster though.<\/p>\n",
                "<p>You could also do<\/p>\n\n<pre><code>result = ([ a for a,b in original ], [ b for a,b in original ])\n<\/code><\/pre>\n\n<p>It <em>should<\/em> scale better. Especially if Python makes good on not expanding the list comprehensions unless needed.<\/p>\n\n<p>(Incidentally, it makes a 2-tuple (pair) of lists, rather than a list of tuples, like <code>zip<\/code> does.)<\/p>\n\n<p>If generators instead of actual lists are ok, this would do that:<\/p>\n\n<pre><code>result = (( a for a,b in original ), ( b for a,b in original ))\n<\/code><\/pre>\n\n<p>The generators don't munch through the list until you ask for each element, but on the other hand, they do keep references to the original list.<\/p>\n",
                "<p><a href=\"http:\/\/docs.python.org\/library\/functions.html#zip\"><code>zip<\/code><\/a> is its own inverse! Provided you use the special * operator.<\/p>\n\n<pre><code>&gt;&gt;&gt; zip(*[('a', 1), ('b', 2), ('c', 3), ('d', 4)])\n[('a', 'b', 'c', 'd'), (1, 2, 3, 4)]\n<\/code><\/pre>\n\n<p>The way this works is by calling <code>zip<\/code> with the arguments:<\/p>\n\n<pre><code>zip(('a', 1), ('b', 2), ('c', 3), ('d', 4))\n<\/code><\/pre>\n\n<p>ÃÃÂª except the arguments are passed to <code>zip<\/code> directly (after being converted to a tuple), so there's no need to worry about the number of arguments getting too big.<\/p>\n"
            ]
        },
        {
            "tag": "questao_19030",
            "padroes": [
                "I have a bunch of files (TV episodes, although that is fairly arbitrary) that I want to check match a specific naming\/organisation scheme..\n\nCurrently: I have three arrays of regex, one for valid filenames, one for files missing an episode name, and one for valid paths.\n\nThen, I loop though each valid-filename regex, if it matches, append it to a \"valid\" dict, if not, do the same with the missing-ep-name regexs, if it matches this I append it to an \"invalid\" dict with an error code (2:'missing epsiode name'), if it matches neither, it gets added to invalid with the 'malformed name' error code.\n\nThe current code can be found here\n\nI want to add a rule that checks for the presence of a folder.jpg file in each directory, but to add this would make the code substantially more messy in it's current state.. \n\nHow could I write this system in a more expandable way?\n\nThe rules it needs to check would be..\n\n\n- File is in the format Show Name - [01x23] - Episode Name.avi or Show Name - [01xSpecial02] - Special Name.avi or Show Name - [01xExtra01] - Extra Name.avi- If filename is in the format Show Name - [01x23].avi display it a 'missing episode name' section of the output- The path should be in the format Show Name\/season 2\/the_file.avi (where season 2 should be the correct season number in the filename)- each Show Name\/season 1\/ folder should contain \"folder.jpg\"\n\n.any ideas? While I'm trying to check TV episodes, this concept\/code should be able to apply to many things..\n\nThe only thought I had was a list of dicts in the format:\n\nchecker = [\n{\n    'name':'valid files',\n    'type':'file',\n    'function':check_valid(), # runs check_valid() on all files\n    'status':0 # if it returns True, this is the status the file gets\n\n\n"
            ],
            "respostas": [
                "<p>maybe you should take the approach of defaulting to: \"the filename is correct\" and work from there to disprove that statement:<\/p>\n\n<p>with the fact that you only allow filenames with: 'show name', 'season number x episode number' and 'episode name', you know for certain that these items should be separated by a \"-\" (dash) so you have to have 2 of those for a filename to be correct.<br>\nif that checks out, you can use your code to check that the show name matches the show name as seen in the parent's parent folder (case insensitive i assume), the season number matches the parents folder numeric value (with or without an extra 0 prepended).<\/p>\n\n<p>if however you don't see the correct amount of dashes you instantly know that there is something wrong and stop before the rest of the tests etc.<\/p>\n\n<p>and separately you can check if the file <code>folder.jpg<\/code> exists and take the necessary actions. <strong>or<\/strong> do that first and filter that file from the rest of the files in that folder.<\/p>\n",
                "<blockquote>\n  <p>I want to add a rule that checks for\n  the presence of a folder.jpg file in\n  each directory, but to add this would\n  make the code substantially more messy\n  in it's current state..<\/p>\n<\/blockquote>\n\n<p>This doesn't look bad.  In fact your current code does it very nicely, and Sven mentioned a good way to do it as well:<\/p>\n\n<ol>\n<li>Get a list of all the files<\/li>\n<li>Check for \"required\" files<\/li>\n<\/ol>\n\n<p>You would just have have add to your dictionary a list of required files:<\/p>\n\n<pre><code>checker = {\n  ...\n  'required': ['file', 'list', 'for_required']\n\n<\/code><\/pre>\n\n<p>As far as there being a better\/extensible way to do this?  I am not exactly sure.  I could only really think of a way to possibly drop the \"multiple\" regular expressions and build off of Sven's idea for using a delimiter.  So my strategy would be defining a dictionary as follows (and I'm sorry I don't know Python syntax and I'm a tad to lazy to look it up but it should make sense.  The \/regex\/ is shorthand for a regex):<\/p>\n\n<pre><code>check_dict = {\n  'delim'    : \/\\-\/,\n  'parts'    : [ 'Show Name', 'Episode Name', 'Episode Number' ],\n  'patterns' : [\/valid name\/, \/valid episode name\/, \/valid number\/ ],\n  'required' : ['list', 'of', 'files'],\n  'ignored'  : ['.*', 'hidden.txt'],\n  'start_dir': '\/path\/to\/dir\/to\/test\/'\n\n<\/code><\/pre>\n\n<ol>\n<li>Split the filename based on the delimiter.<\/li>\n<li>Check each of the parts.<\/li>\n<\/ol>\n\n<p>Because its an ordered list you can determine what parts are missing and if a section doesn't match any pattern it is malformed.  Here the <code>parts<\/code> and <code>patterns<\/code> have a 1 to 1 ratio.  Two arrays instead of a dictionary enforces the order.<\/p>\n\n<p>Ignored and required files can be listed.  The <code>.<\/code> and <code>..<\/code> files should probably be ignored automatically.  The user should be allowed to input \"globs\" which can be shell expanded.  I'm thinking here of <code>svn:ignore<\/code> properties, but globbing is natural for listing files.<\/p>\n\n<p>Here <code>start_dir<\/code> would be default to the current directory but if you wanted a single file to run automated testing of a bunch of directories this would be useful.<\/p>\n\n<p>The real loose end here is the path template and along the same lines what path is required for \"valid files\".  I really couldn't come up with a solid idea without writing one large regular expression and taking groups from it... to build a template.  It felt a lot like writing a TextMate language grammar.  But that starts to stray on the ease of use.  The real problem was that the path template was not composed of <code>parts<\/code>, which makes sense but adds complexity.<\/p>\n\n<p>Is this strategy in tune with what you were thinking of?<\/p>\n"
            ]
        },
        {
            "tag": "questao_19654",
            "padroes": [
                "The company I used to work with has two developers working fulltime, and a handful of freelancers. They're in the process of hiring a new lead developer to try to bring order and management to the development.\n\nBut, currently, one of the developers has seen the light of Django (the company has only developed in PHP to date) while the other developer is concerned that introducing a new language (Python) is a bad idea right now.\n\nHow should they approach introducing this new technology? Obviously with only one of the developers actually knowing Python, there will be no redundancy when that dev is away or leaves the company.\n\nShould they bother to introduce Python, or should they look for PHP-only solutions until such a time when the team actually have more than one Pythonion? Without a team leader, the decisions are having to fall to them.\n"
            ],
            "respostas": [
                "<p>Well, python is a high level language.. its not hard to learn and if the guys already have programming knowledge it should be much easier to learn.. i like django.. i think it should be a nice try to use django .. <\/p>\n",
                "<p>I don't think it's a matter of a programming language as such. <\/p>\n\n<p>What is the proficiency level of PHP in the team you're talking about? Are they doing spaghetti code or using some structured framework like Zend? If this is the first case then I absolutely understand the guy's interest in Python and Django. It this is the latter, it's just a hype.<\/p>\n",
                "<p>I love Python and Django, and use both to develop the our core webapps.<\/p>\n\n<p>That said, it's hard to make a business case for switching at this point. Specifically:<\/p>\n\n<ul>\n<li>Any new platform is risky compared to staying with the tried and true<\/li>\n<li>You'll have the developer fragmentation you mentioned<\/li>\n<li>It's far easier to find PHP programmers than python programmers<\/li>\n<\/ul>\n\n<p>Moreover, as other posters have mention, if the issue is more with spaghetti code than PHP itself, there are plenty of nice PHP frameworks that could be used to refactor the code.<\/p>\n\n<p>That said, if this developer is excited about python, stopping them outright is probably demoralizing. My suggestion would be to encourage them to develop in python, but not the mission critical parts of the app. Instead they could write some utility scripts, some small internal application that needs doing, etc.<\/p>\n\n<p>In conclusion: I don't recommend switching from PHP, but I do recommend accommodating the developer's interest in some way at work.<\/p>\n",
                "<p>It's really all about schedules.  To me the break should be with a specific project.  If you decide your direction is Django then start new projects with that.  Before you start a new project with a new language\/framework, either make sure that you have scheduled time to get up to speed in this new direction, or get up to speed before using on new projects.<\/p>\n\n<p>I would avoid going with a tool of the month.  Make sure you want it to be your direction and commit some time\/resources to learning enough to make a good decision.<\/p>\n",
                "<p>I think the language itself is not an issue here, as python is really nice high level language with good and easy to find, thorough documentation.<\/p>\n\n<p>From what I've seen, the Django framework is also a great tooklit for web development, giving much the same developer performance boost Rails is touted to give.<\/p>\n\n<p>The real issue is at the maintenance and management level.<\/p>\n\n<p>How will this move fragment the maintenance between PHP and Python code. Is there a need to migrate existing code from one platform to another? What problems will adopting Python and Django solve that you have in your current development workflow and frameworks, etc.<\/p>\n",
                "<p>@darkdog:<\/p>\n\n<p>Using a new language in production code is about more than easy syntax and high-level capability. You want to be familiar with core APIs and feel like you can fix something through logic instead of having to comb through the documentation.<\/p>\n\n<p>I'm not saying transitioning to Python would be a bad idea for this company, but I'm with John--keep things simple during the transition. The new lead will appreciate having a say in such decisions.<\/p>\n\n<p>If you'd really, really, really like to introduce Python, consider writing some extensions or utilities in straight-up Python or in the framework. You won't be upsetting your core initiatives, so it will be a low\/no-risk opportunity to prove the merits of a switch.<\/p>\n",
                "<p>If the mandate of the new lead is to put the house in order, the current situation should likely be simplified as much as possible prior.  If I had to bring things to order, I wouldn't want to have to manage an ongoing language conversion project on top of everything else, or at least I'd like some choice when initiating the project.  When making your recommendation, did you think about the additional managerial complexity that coming into the middle of a conversion would entail?<\/p>\n",
                "<p>I recently introduced Python to my company, which does consulting work for the Post Office.  I did this by waiting until there was a project for which I would be the only programmer, then getting permission to do this new project in Python.  I then did another small project in Python with similarly impressive results.  In addition, I used Python for all of my small throwaway assignments (\"can you parse the stats in these files into a CSV file organized by date and site?\", etc) and had a quick turnaround time on all of them.<\/p>\n\n<p>I also evangelized Python a bit; I went out of my way to NOT be obnoxious about it, but I'd occasionally describe why I liked it so much, talked about the personal projects I use it for in my free time and why it's awesome for me, etc.<\/p>\n\n<p>Eventually we started another project and I convinced everyone to use Python for it.  I took care to point everyone to a lot of documentation, including the specific webpages relating to what they were working on, and every time they had a question, I'd explain how to do things properly by explaining the Pythonic approach to things, etc.<\/p>\n\n<p>This has worked really well.  However, this might be somewhat different than what you're describing.  In my case I started with moderately small projects and Python is only being used for new projects.  Also, none of my co-workers were really Perl or PHP gurus; they all knew those languages and had been using them for awhile, but it didn't take much effort for them to become more productive in Python than they'd been before.<\/p>\n\n<p>So if you're talking about new projects with people who currently use PHP but aren't super-experts and don't love that language, then I think switching to Python is a no-brainer.  However, if you're talking about working with a large existing PHP code base with a lot of very experienced PHP programmers who are happy with their current setup, then switching languages is probably not a good idea.  You're probably somewhere in between, so you'll have to weigh the tradeoffs; hopefully my answer will help you do that.<\/p>\n"
            ]
        },
        {
            "tag": "questao_20063",
            "padroes": [
                "What's the easiest, tersest, and most flexible method or library for parsing Python command line arguments?\n"
            ],
            "respostas": [
                "<p>Here's a method, not a library, which seems to work for me.<\/p>\n\n<p>The goals here are to be terse, each argument parsed by a single line, the args line up for readability, the code is simple and doesn't depend on any special modules (only os + sys), warns about missing or unknown arguments gracefully, use a simple for\/range() loop, and works across python 2.x and 3.x<\/p>\n\n<p>Shown are two toggle flags (-d, -v), and two values controlled by arguments (-i xxx and -o xxx).<\/p>\n\n<pre><code>import os,sys\n\ndef HelpAndExit():\n    print(\"&lt;&lt;your help output goes here&gt;&gt;\")\n    sys.exit(1)\n\ndef Fatal(msg):\n    sys.stderr.write(\"%s: %s\\n\" % (os.path.basename(sys.argv[0]), msg))\n    sys.exit(1)\n\ndef NextArg(i):\n    '''Return the next command line argument (if there is one)'''\n    if ((i+1) &gt;= len(sys.argv)):\n        Fatal(\"'%s' expected an argument\" % sys.argv[i])\n    return(1, sys.argv[i+1])\n\n### MAIN\nif __name__=='__main__':\n\n    verbose = 0\n    debug   = 0\n    infile  = \"infile\"\n    outfile = \"outfile\"\n\n    # Parse command line\n    skip = 0\n    for i in range(1, len(sys.argv)):\n        if not skip:\n            if   sys.argv[i][:2] == \"-d\": debug ^= 1\n            elif sys.argv[i][:2] == \"-v\": verbose ^= 1\n            elif sys.argv[i][:2] == \"-i\": (skip,infile)  = NextArg(i)\n            elif sys.argv[i][:2] == \"-o\": (skip,outfile) = NextArg(i)\n            elif sys.argv[i][:2] == \"-h\": HelpAndExit()\n            elif sys.argv[i][:1] == \"-\":  Fatal(\"'%s' unknown argument\" % sys.argv[i])\n            else:                         Fatal(\"'%s' unexpected\" % sys.argv[i])\n        else: skip = 0\n\n    print(\"%d,%d,%s,%s\" % (debug,verbose,infile,outfile))\n<\/code><\/pre>\n\n<p>The goal of NextArg() is to return the next argument while checking for missing data, and 'skip' skips the loop when NextArg() is used, keeping the flag parsing down to one liners.<\/p>\n",
                "<p><a href=\"https:\/\/github.com\/muromec\/consoleargs\" rel=\"nofollow\">consoleargs<\/a> deserves to be mentioned here. It is very easy to use. Check it out:<\/p>\n\n<pre><code>from consoleargs import command\n\n@command\ndef main(url, name=None):\n  \"\"\"\n  :param url: Remote URL \n  :param name: File name\n  \"\"\"\n  print \"\"\"Downloading url '%r' into file '%r'\"\"\" % (url, name)\n\nif __name__ == '__main__':\n  main()\n<\/code><\/pre>\n\n<p>Now in console:<\/p>\n\n<pre><code>% python demo.py --help\nUsage: demo.py URL [OPTIONS]\n\nURL:    Remote URL \n\nOptions:\n    --name -n   File name\n\n% python demo.py http:\/\/www.google.com\/\nDownloading url ''http:\/\/www.google.com\/'' into file 'None'\n\n% python demo.py http:\/\/www.google.com\/ --name=index.html\nDownloading url ''http:\/\/www.google.com\/'' into file ''index.html''\n<\/code><\/pre>\n",
                "<p>I think the best way for larger projects is optparse, but if you are looking for an easy way, maybe <a href=\"http:\/\/werkzeug.pocoo.org\/documentation\/script\" rel=\"nofollow\">http:\/\/werkzeug.pocoo.org\/documentation\/script<\/a> is something for you.<\/p>\n\n<pre><code>from werkzeug import script\n\n# actions go here\ndef action_foo(name=\"\"):\n    \"\"\"action foo does foo\"\"\"\n    pass\n\ndef action_bar(id=0, title=\"default title\"):\n    \"\"\"action bar does bar\"\"\"\n    pass\n\nif __name__ == '__main__':\n    script.run()\n<\/code><\/pre>\n\n<p>So basically every function action_* is exposed to the command line and a nice\nhelp message is generated for free. <\/p>\n\n<pre><code>python foo.py \nusage: foo.py &lt;action&gt; [&lt;options&gt;]\n       foo.py --help\n\nactions:\n  bar:\n    action bar does bar\n\n    --id                          integer   0\n    --title                       string    default title\n\n  foo:\n    action foo does foo\n\n    --name                        string\n<\/code><\/pre>\n",
                "<p>I prefer optparse to getopt. It's very declarative: you tell it the names of the options and the effects they should have (e.g., setting a boolean field), and it hands you back a dictionary populated according to your specifications.<\/p>\n\n<p><a href=\"http:\/\/docs.python.org\/lib\/module-optparse.html\" rel=\"nofollow\">http:\/\/docs.python.org\/lib\/module-optparse.html<\/a><\/p>\n",
                "<p>Just in case you might need to, this may help if you need to <strong>grab<\/strong> unicode arguments on Win32 (2K, XP etc):<\/p>\n\n<pre><code>\nfrom ctypes import *\n\ndef wmain(argc, argv):\n    print argc\n    for i in argv:\n        print i\n    return 0\n\ndef startup():\n    size = c_int()\n    ptr = windll.shell32.CommandLineToArgvW(windll.kernel32.GetCommandLineW(), byref(size))\n    ref = c_wchar_p * size.value\n    raw = ref.from_address(ptr)\n    args = [arg for arg in raw]\n    windll.kernel32.LocalFree(ptr)\n    exit(wmain(len(args), args))\nstartup()\n<\/code><\/pre>\n",
                "<p>I prefer <a href=\"http:\/\/click.pocoo.org\/\" rel=\"nofollow\">Click<\/a>. It abstracts managing options and allows \"(...) creating beautiful command line interfaces in a composable way with as little code as necessary\".<\/p>\n\n<p>Here's example usage:<\/p>\n\n<pre><code>import click\n\n@click.command()\n@click.option('--count', default=1, help='Number of greetings.')\n@click.option('--name', prompt='Your name',\n              help='The person to greet.')\ndef hello(count, name):\n    \"\"\"Simple program that greets NAME for a total of COUNT times.\"\"\"\n    for x in range(count):\n        click.echo('Hello %s!' % name)\n\nif __name__ == '__main__':\n    hello()\n<\/code><\/pre>\n\n<p>It also automatically generates nicely formatted help pages:<\/p>\n\n<pre><code>$ python hello.py --help\nUsage: hello.py [OPTIONS]\n\n  Simple program that greets NAME for a total of COUNT times.\n\nOptions:\n  --count INTEGER  Number of greetings.\n  --name TEXT      The person to greet.\n  --help           Show this message and exit.\n<\/code><\/pre>\n",
                "<p>Use <code>optparse<\/code> which comes with the standard library. For example:<\/p>\n\n<pre><code>#!\/usr\/bin\/env python\nimport optparse\n\ndef main():\n  p = optparse.OptionParser()\n  p.add_option('--person', '-p', default=\"world\")\n  options, arguments = p.parse_args()\n  print 'Hello %s' % options.person\n\nif __name__ == '__main__':\n  main()\n<\/code><\/pre>\n\n<p>Source: <a href=\"http:\/\/www.ibm.com\/developerworks\/aix\/library\/au-pythocli\/\" rel=\"nofollow\">Using Python to create UNIX command line tools<\/a><\/p>\n\n<p>However as of Python 2.7 optparse is deprecated, see: <a href=\"http:\/\/stackoverflow.com\/q\/3217673\/55075\">Why use argparse rather than optparse?<\/a><\/p>\n",
                "<p>Pretty much everybody is using <a href=\"http:\/\/python.active-venture.com\/lib\/module-getopt.html\" rel=\"nofollow\">getopt<\/a><\/p>\n\n<p>Here is the example code for the doc :<\/p>\n\n<pre><code>import getopt, sys\n\ndef main():\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], \"ho:v\", [\"help\", \"output=\"])\n    except getopt.GetoptError:\n        # print help information and exit:\n        usage()\n        sys.exit(2)\n    output = None\n    verbose = False\n    for o, a in opts:\n        if o == \"-v\":\n            verbose = True\n        if o in (\"-h\", \"--help\"):\n            usage()\n            sys.exit()\n        if o in (\"-o\", \"--output\"):\n            output = a\n<\/code><\/pre>\n\n<p>So in a word, here is how it works.<\/p>\n\n<p>You've got two types of options. Those who are receiving arguments, and those who are\njust like switches.<\/p>\n\n<p><code>sys.argv<\/code> is pretty much your <code>char** argv<\/code> in C. Like in C you skip the first element which is the name of your program and parse only the arguments : <code>sys.argv[1:]<\/code><\/p>\n\n<p><code>Getopt.getopt<\/code> will parse it according to the rule you give in argument.<\/p>\n\n<p><code>\"ho:v\"<\/code> here describes the short arguments : <code>-ONELETTER<\/code>. The <code>:<\/code> means that <code>-o<\/code> accepts one argument.<\/p>\n\n<p>Finally <code>[\"help\", \"output=\"]<\/code> describes long arguments ( <code>--MORETHANONELETTER<\/code> ).\nThe <code>=<\/code> after output once again means that output accepts one arguments.<\/p>\n\n<p>The result is a list of couple (option,argument)<\/p>\n\n<p>If an option doesn't accept any argument (like <code>--help<\/code> here) the <code>arg<\/code> part is an empty string.\nYou then usually want to loop on this list and test the option name as in the example.<\/p>\n\n<p>I hope this helped you.<\/p>\n",
                "<p>Other answers do mention that <code>argparse<\/code> is the way to go for new Python, but do not give usage examples. For completeness, here is a short summary of how to use argparse:<\/p>\n\n<p><strong>1) Initialize<\/strong><\/p>\n\n<pre><code>import argparse\n\n# Instantiate the parser\nparser = argparse.ArgumentParser(description='Optional app description')\n<\/code><\/pre>\n\n<p><strong>2) Add Arguments<\/strong><\/p>\n\n<pre><code># Required positional argument\nparser.add_argument('pos_arg', type=int,\n                    help='A required integer positional argument')\n\n# Optional positional argument\nparser.add_argument('opt_pos_arg', type=int, nargs='?',\n                    help='An optional integer positional argument')\n\n# Optional argument\nparser.add_argument('--opt_arg', type=int,\n                    help='An optional integer argument')\n\n# Switch\nparser.add_argument('--switch', action='store_true',\n                    help='A boolean switch')\n<\/code><\/pre>\n\n<p><strong>3) Parse<\/strong><\/p>\n\n<pre><code>args = parser.parse_args()\n<\/code><\/pre>\n\n<p><strong>4) Access<\/strong><\/p>\n\n<pre><code>print(\"Argument values:\")\nprint(args.pos_arg)\nprint(args.opt_pos_arg)\nprint(args.opt_arg)\nprint(args.switch)\n<\/code><\/pre>\n\n<p><strong>5) Check Values<\/strong><\/p>\n\n<pre><code>if args.pos_arg &gt; 10:\n    parser.error(\"pos_arg cannot be larger than 10\")\n<\/code><\/pre>\n\n<h2>Usage<\/h2>\n\n<p><strong>Correct use:<\/strong><\/p>\n\n<pre><code>$ .\/app 1 2 --opt_arg 3 --switch\n\nArgument values:\n1\n2\n3\nTrue\n<\/code><\/pre>\n\n<p><strong>Incorrect arguments:<\/strong><\/p>\n\n<pre><code>$ .\/app foo 2 --opt_arg 3 --switch\nusage: convert [-h] [--opt_arg OPT_ARG] [--switch] pos_arg [opt_pos_arg]\napp: error: argument pos_arg: invalid int value: 'foo'\n\n$ .\/app 11 2 --opt_arg 3\nArgument values:\n11\n2\n3\nFalse\nusage: app [-h] [--opt_arg OPT_ARG] [--switch] pos_arg [opt_pos_arg]\nconvert: error: pos_arg cannot be larger than 10\n<\/code><\/pre>\n\n<p><strong>Full help:<\/strong><\/p>\n\n<pre><code>$ .\/app -h\n\nusage: app [-h] [--opt_arg OPT_ARG] [--switch] pos_arg [opt_pos_arg]\n\nOptional app description\n\npositional arguments:\n  pos_arg            A required integer positional argument\n  opt_pos_arg        An optional integer positional argument\n\noptional arguments:\n  -h, --help         show this help message and exit\n  --opt_arg OPT_ARG  An optional integer argument\n  --switch           A boolean switch\n<\/code><\/pre>\n",
                "<p>The new hip way is <code>argparse<\/code> for <a href=\"http:\/\/argparse.googlecode.com\/svn\/trunk\/doc\/argparse-vs-optparse.html\">these<\/a> reasons.  argparse > optparse > getopt<\/p>\n\n<p><strong>update:<\/strong> As of py2.7 <a href=\"http:\/\/docs.python.org\/library\/argparse.html\">argparse<\/a> is part of the standard library and <a href=\"http:\/\/docs.python.org\/library\/optparse.html\">optparse<\/a> is deprecated.<\/p>\n",
                "<p>Since 2012 Python has a very easy, powerful and really <em>cool<\/em> module for argument parsing called <a href=\"https:\/\/github.com\/docopt\/docopt\" rel=\"nofollow\">docopt<\/a>. It works with Python 2.6 to 3.5 and needs no installation (just copy it). Here is an example taken from it's documentation: <\/p>\n\n<pre><code>\"\"\"Naval Fate.\n\nUsage:\n  naval_fate.py ship new &lt;name&gt;...\n  naval_fate.py ship &lt;name&gt; move &lt;x&gt; &lt;y&gt; [--speed=&lt;kn&gt;]\n  naval_fate.py ship shoot &lt;x&gt; &lt;y&gt;\n  naval_fate.py mine (set|remove) &lt;x&gt; &lt;y&gt; [--moored | --drifting]\n  naval_fate.py (-h | --help)\n  naval_fate.py --version\n\nOptions:\n  -h --help     Show this screen.\n  --version     Show version.\n  --speed=&lt;kn&gt;  Speed in knots [default: 10].\n  --moored      Moored (anchored) mine.\n  --drifting    Drifting mine.\n\n\"\"\"\nfrom docopt import docopt\n\n\nif __name__ == '__main__':\n    arguments = docopt(__doc__, version='Naval Fate 2.0')\n    print(arguments)\n<\/code><\/pre>\n\n<p>So this is it: one line of code plus your doc string which <em>is<\/em> essential. I told you it's cool, didn't I ;-)<\/p>\n",
                "<p><strong>This answer suggests <code>optparse<\/code> which is appropriate for older Python versions. For Python 2.7 and above, <code>argparse<\/code> replaces <code>optparse<\/code>. See <a href=\"http:\/\/stackoverflow.com\/questions\/3217673\/why-use-argparse-rather-than-optparse\">this answer<\/a> for more information.<\/strong><\/p>\n\n<p>As other people pointed out, you are better off going with optparse over getopt.  getopt is pretty much a one-to-one mapping of the standard getopt(3) C library functions, and not very easy to use.<\/p>\n\n<p>optparse, while being a bit more verbose, is much better structured and simpler to extend later on.<\/p>\n\n<p>Here's a typical line to add an option to your parser:<\/p>\n\n<pre><code>parser.add_option('-q', '--query',\n            action=\"store\", dest=\"query\",\n            help=\"query string\", default=\"spam\")\n<\/code><\/pre>\n\n<p>It pretty much speaks for itself; at processing time, it will accept -q or --query as options, store the argument in an attribute called query and has a default value if you don't specify it.  It is also self-documenting in that you declare the help argument (which will be used when run with -h\/--help) right there with the option.<\/p>\n\n<p>Usually you parse your arguments with:<\/p>\n\n<pre><code>options, args = parser.parse_args()\n<\/code><\/pre>\n\n<p>This will, by default, parse the standard arguments passed to the script (sys.argv[1:])<\/p>\n\n<p>options.query will then be set to the value you passed to the script.<\/p>\n\n<p>You create a parser simply by doing<\/p>\n\n<pre><code>parser = optparse.OptionParser()\n<\/code><\/pre>\n\n<p>These are all the basics you need.  Here's a complete Python script that shows this:<\/p>\n\n<pre><code>import optparse\n\nparser = optparse.OptionParser()\n\nparser.add_option('-q', '--query',\n    action=\"store\", dest=\"query\",\n    help=\"query string\", default=\"spam\")\n\noptions, args = parser.parse_args()\n\nprint 'Query string:', options.query\n<\/code><\/pre>\n\n<p>5 lines of python that show you the basics.<\/p>\n\n<p>Save it in sample.py, and run it once with<\/p>\n\n<pre><code>python sample.py\n<\/code><\/pre>\n\n<p>and once with<\/p>\n\n<pre><code>python sample.py --query myquery\n<\/code><\/pre>\n\n<p>Beyond that, you will find that optparse is very easy to extend.\nIn one of my projects, I created a Command class which allows you to nest subcommands in a command tree easily.  It uses optparse heavily to chain commands together.  It's not something I can easily explain in a few lines, but feel free to <a href=\"https:\/\/thomas.apestaart.org\/moap\/trac\/browser\/trunk\/moap\/extern\/command\/command.py\">browse around in my repository<\/a> for the main class, as well as <a href=\"https:\/\/thomas.apestaart.org\/moap\/trac\/browser\/trunk\/moap\/command\/doap.py\">a class that uses it and the option parser<\/a><\/p>\n"
            ]
        },
        {
            "tag": "questao_20794",
            "padroes": [
                "If I call os.stat() on a broken symlink, python throws an OSError exception. This makes it useful for finding them. However, there are a few other reasons that os.stat() might throw a similar exception. Is there a more precise way of detecting broken symlinks with Python under Linux?\n"
            ],
            "respostas": [
                "<p>I'm not a python guy but it looks like os.readlink()?  The logic I would use in perl is to use readlink() to find the target and the use stat() to test to see if the target exists.<\/p>\n\n<p>Edit: I banged out some perl that demos readlink.  I believe perl's stat and readlink and python's os.stat() and os.readlink()are both wrappers for the system calls, so this should translate reasonable well as proof of concept code:<\/p>\n\n<pre><code>wembley 0 \/home\/jj33\/swap &gt; cat p\nmy $f = shift;\n\nwhile (my $l = readlink($f)) {\n  print \"$f -&gt; $l\\n\";\n  $f = $l;\n\n\nif (!-e $f) {\n  print \"$f doesn't exist\\n\";\n\nwembley 0 \/home\/jj33\/swap &gt; ls -l | grep ^l\nlrwxrwxrwx    1 jj33  users          17 Aug 21 14:30 link -&gt; non-existant-file\nlrwxrwxrwx    1 root     users          31 Oct 10  2007 mm -&gt; ..\/systems\/mm\/20071009-rewrite\/\/\nlrwxrwxrwx    1 jj33  users           2 Aug 21 14:34 mmm -&gt; mm\/\nwembley 0 \/home\/jj33\/swap &gt; perl p mm\nmm -&gt; ..\/systems\/mm\/20071009-rewrite\/\nwembley 0 \/home\/jj33\/swap &gt; perl p mmm\nmmm -&gt; mm\nmm -&gt; ..\/systems\/mm\/20071009-rewrite\/\nwembley 0 \/home\/jj33\/swap &gt; perl p link\nlink -&gt; non-existant-file\nnon-existant-file doesn't exist\nwembley 0 \/home\/jj33\/swap &gt;\n<\/code><\/pre>\n",
                "<p><a href=\"http:\/\/docs.python.org\/lib\/module-os.path.html\" rel=\"nofollow\">os.path<\/a><\/p>\n\n<p>You may try using realpath() to get what the symlink points to, then trying to determine if it's a valid file using is file.<\/p>\n\n<p>(I'm not able to try that out at the moment, so you'll have to play around with it and see what you get)<\/p>\n",
                "<p>Can I mention testing for hardlinks without python? \/bin\/test has the FILE1 -ef FILE2 condition that is true when files share an inode.<\/p>\n\n<p>Therefore, something like <code>find . -type f -exec test \\{ -ef \/path\/to\/file \\; -print<\/code> works for hard link testing to a specific file.<\/p>\n\n<p>Which brings me to reading <code>man test<\/code> and the mentions of <code>-L<\/code> and <code>-h<\/code> which both work on one file and return true if that file is a symbolic link, however that doesn't tell you if the target is missing.<\/p>\n\n<p>I did find that <code>head -0 FILE1<\/code> would return an exit code of <code>0<\/code> if the file can be opened and a <code>1<\/code> if it cannot, which in the case of a symbolic link to a regular file works as a test for whether it's target can be read.<\/p>\n",
                "<p>This is not atomic but it works.<\/p>\n\n<p><code>os.path.islink(filename) and not os.path.exists(filename)<\/code><\/p>\n\n<p>Indeed by <a href=\"https:\/\/docs.python.org\/2\/library\/os.path.html\" rel=\"nofollow\">RTFM<\/a>\n (reading the fantastic manual) we see<\/p>\n\n<blockquote>\n  <p>os.path.exists(path)<\/p>\n  \n  <p>Return True if path refers to an existing path. Returns False for  broken symbolic links.<\/p>\n<\/blockquote>\n\n<p>It also says:<\/p>\n\n<blockquote>\n  <p>On some platforms, this function may return False if permission is not granted to execute os.stat() on the requested file, even if the path physically exists.<\/p>\n<\/blockquote>\n\n<p>So if you are worried about permissions, you should add other clauses.<\/p>\n",
                "<p><a href=\"https:\/\/docs.python.org\/2\/library\/os.html#os.lstat\" rel=\"nofollow\">os.lstat()<\/a> may be helpful. If lstat() succeeds and stat() fails, then it's probably a broken link.<\/p>\n",
                "<p>A common Python saying is that it's easier to ask forgiveness than permission.  While I'm not a fan of this statement in real life, it does apply in a lot of cases.  Usually you want to avoid code that chains two system calls on the same file, because you never know what will happen to the file in between your two calls in your code.<\/p>\n\n<p><strong>A typical mistake is to write something like<\/strong>:<\/p>\n\n<pre><code>if os.path.exists(path):\n    os.unlink(path)\n<\/code><\/pre>\n\n<p>The second call (os.unlink) may fail if something else deleted it after your if test, raise an Exception, and stop the rest of your function from executing.  (You might think this doesn't happen in real life, but we just fished another bug like that out of our codebase last week - and it was the kind of bug that left a few programmers scratching their head and claiming 'Heisenbug' for the last few months)<\/p>\n\n<p>So, in your particular case, I would probably do:<\/p>\n\n<pre><code>try:\n    os.stat(path)\nexcept OSError, e:\n    if e.errno == errno.ENOENT:\n        print 'path %s does not exist or is a broken symlink' % path\n    else:\n        raise e\n<\/code><\/pre>\n\n<p>The annoyance here is that stat returns the same error code for a symlink that just isn't there and a broken symlink.<\/p>\n\n<p>So, I guess you have no choice than to break the atomicity, and do something like<\/p>\n\n<pre><code>if not os.path.exists(os.readlink(path)):\n    print 'path %s is a broken symlink' % path\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_20927",
            "padroes": [
                "I've got two models: Message and Attachment. Each attachment is attached to a specific message, using a ForeignKey on the Attachment model. Both models have an auto_now DateTimeField called updated. I'm trying to make it so that when any attachment is saved, it also sets the updated field on the associated message to now. Here's my code:\n\ndef save(self):\n    super(Attachment, self).save()\n    self.message.updated = self.updated\n\n\nWill this work, and if you can explain it to me, why? If not, how would I accomplish this?\n"
            ],
            "respostas": [
                "<p>Proper version to work is: (attention to last line <code>self.message.save()<\/code>)<\/p>\n\n<pre><code>class Message(models.Model):\n    updated = models.DateTimeField(auto_now = True)\n    ...\n\nclass Attachment(models.Model):\n    updated = models.DateTimeField(auto_now = True)\n    message = models.ForeignKey(Message)\n\n    def save(self):\n        super(Attachment, self).save()\n        self.message.save()\n<\/code><\/pre>\n",
                "<p>DateTime fields with auto_now are automatically updated upon calling <code>save()<\/code>, so you do not need to update them manually. Django will do this work for you.<\/p>\n",
                "<p>You would also need to then save the message.  Then it that should work.<\/p>\n"
            ]
        },
        {
            "tag": "questao_21454",
            "padroes": [
                "How do I go about specifying and using an ENUM in a Django model?\n"
            ],
            "respostas": [
                "<p>A the top of your models.py file, add this line after you do your imports:<\/p>\n\n<pre><code>    enum = lambda *l: [(s,_(s)) for s in l]\n<\/code><\/pre>\n",
                "<p>There're currently two github projects based on adding these, though I've not looked into exactly how they're implemented:<\/p>\n\n<ol>\n<li><a href=\"https:\/\/github.com\/5monkeys\/django-enumfield\" rel=\"nofollow\">Django-EnumField<\/a>:<br>\nProvides an enumeration Django model field (using IntegerField) with reusable enums and transition validation. <\/li>\n<li><a href=\"https:\/\/github.com\/hzdg\/django-enumfields\" rel=\"nofollow\">Django-EnumFields<\/a>:<br>\nThis package lets you use real Python (PEP435-style) enums with Django.<\/li>\n<\/ol>\n\n<p>I don't think either use DB enum types, but they are <a href=\"https:\/\/github.com\/5monkeys\/django-enumfield\/issues\/18\" rel=\"nofollow\">in the works<\/a> for first one.<\/p>\n",
                "<p><a href=\"http:\/\/www.b-list.org\/weblog\/2007\/nov\/02\/handle-choices-right-way\/\">http:\/\/www.b-list.org\/weblog\/2007\/nov\/02\/handle-choices-right-way\/<\/a><\/p>\n\n<blockquote>\n<pre><code>class Entry(models.Model):\n    LIVE_STATUS = 1\n    DRAFT_STATUS = 2\n    HIDDEN_STATUS = 3\n    STATUS_CHOICES = (\n        (LIVE_STATUS, 'Live'),\n        (DRAFT_STATUS, 'Draft'),\n        (HIDDEN_STATUS, 'Hidden'),\n    )\n    # ...some other fields here...\n    status = models.IntegerField(choices=STATUS_CHOICES, default=LIVE_STATUS)\n\nlive_entries = Entry.objects.filter(status=Entry.LIVE_STATUS)\ndraft_entries = Entry.objects.filter(status=Entry.DRAFT_STATUS)\n\nif entry_object.status == Entry.LIVE_STATUS:\n<\/code><\/pre>\n<\/blockquote>\n\n<p>This is another nice and easy way of implementing enums although it doesn't really save enums in the database.<\/p>\n\n<p>However it does allow you to reference the 'label' whenever querying or specifying defaults as opposed to the top-rated answer where you have to use the 'value' (which may be a number).<\/p>\n",
                "<p>Setting <code>choices<\/code> on the field will allow some validation on the Django end, but it <em>won't<\/em> define any form of an enumerated type on the database end.<\/p>\n\n<p>As others have mentioned, the solution is to specify <a href=\"https:\/\/docs.djangoproject.com\/en\/dev\/howto\/custom-model-fields\/#django.db.models.Field.db_type\"><code>db_type<\/code><\/a> on a custom field.<\/p>\n\n<p>If you're using a SQL backend (e.g. MySQL), you can do this like so:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from django.db import models\n\n\nclass EnumField(models.Field):\n    def __init__(self, *args, **kwargs):\n        super(EnumField, self).__init__(*args, **kwargs)\n        assert self.choices, \"Need choices for enumeration\"\n\n    def db_type(self, connection):\n        if not all(isinstance(col, basestring) for col, _ in self.choices):\n            raise ValueError(\"MySQL ENUM values should be strings\")\n        return \"ENUM({)\".format(','.join(\"'{'\".format(col) \n                                          for col, _ in self.choices))\n\n\nclass IceCreamFlavor(EnumField, models.CharField):\n    def __init__(self, *args, **kwargs):\n        flavors = [('chocolate', 'Chocolate'),\n                   ('vanilla', 'Vanilla'),\n                  ]\n        super(IceCreamFlavor, self).__init__(*args, choices=flavors, **kwargs)\n\n\nclass IceCream(models.Model):\n    price = models.DecimalField(max_digits=4, decimal_places=2)\n    flavor = IceCreamFlavor(max_length=20)\n<\/code><\/pre>\n\n<p>Run <code>syncdb<\/code>, and inspect your table to see that the <code>ENUM<\/code> was created properly.<\/p>\n\n<pre class=\"lang-sql prettyprint-override\"><code>mysql&gt; SHOW COLUMNS IN icecream;\n+--------+-----------------------------+------+-----+---------+----------------+\n| Field  | Type                        | Null | Key | Default | Extra          |\n+--------+-----------------------------+------+-----+---------+----------------+\n| id     | int(11)                     | NO   | PRI | NULL    | auto_increment |\n| price  | decimal(4,2)                | NO   |     | NULL    |                |\n| flavor | enum('chocolate','vanilla') | NO   |     | NULL    |                |\n+--------+-----------------------------+------+-----+---------+----------------+\n<\/code><\/pre>\n",
                "<p>If you really want to use your databases ENUM type:<\/p>\n\n<ol>\n<li>Use Django 1.x<\/li>\n<li>Recognize your application will only work on some databases.<\/li>\n<li>Puzzle through this documentation page:<a href=\"http:\/\/docs.djangoproject.com\/en\/dev\/howto\/custom-model-fields\/#howto-custom-model-fields\">http:\/\/docs.djangoproject.com\/en\/dev\/howto\/custom-model-fields\/#howto-custom-model-fields<\/a><\/li>\n<\/ol>\n\n<p>Good luck!<\/p>\n",
                "<p>Using the <code>choices<\/code> parameter won't use the ENUM db type; it will just create a VARCHAR or INTEGER, depending on whether you use <code>choices<\/code> with a CharField or IntegerField.  Generally, this is just fine.  If it's important to you that the ENUM type is used at the database level, you have three options:<\/p>\n\n<ol>\n<li>Use \".\/manage.py sql appname\" to see the SQL Django generates, manually modify it to use the ENUM type, and run it yourself.  If you create the table manually first, \".\/manage.py syncdb\" won't mess with it.<\/li>\n<li>If you don't want to do this manually every time you generate your DB, put some custom SQL in appname\/sql\/modelname.sql to perform the appropriate ALTER TABLE command.<\/li>\n<li>Create a <a href=\"http:\/\/docs.djangoproject.com\/en\/dev\/howto\/custom-model-fields\/#howto-custom-model-fields\" rel=\"nofollow\">custom field type<\/a> and define the db_type method appropriately.<\/li>\n<\/ol>\n\n<p>With any of these options, it would be your responsibility to deal with the implications for cross-database portability.  In option 2, you could use <a href=\"http:\/\/www.djangoproject.com\/documentation\/model-api\/#database-backend-specific-sql-data\" rel=\"nofollow\">database-backend-specific custom SQL<\/a> to ensure your ALTER TABLE is only run on MySQL.  In option 3, your db_type method would need to check the database engine and set the db column type to a type that actually exists in that database.<\/p>\n\n<p><strong>UPDATE<\/strong>: Since the migrations framework was added in Django 1.7, options 1 and 2 above are entirely obsolete. Option 3 was always the best option anyway. The new version of options 1\/2 would involve a complex custom migration using <code>SeparateDatabaseAndState<\/code> -- but really you want option 3.<\/p>\n",
                "<pre><code>from django.db import models\n\nclass EnumField(models.Field):\n    \"\"\"\n    A field class that maps to MySQL's ENUM type.\n\n    Usage:\n\n    class Card(models.Model):\n        suit = EnumField(values=('Clubs', 'Diamonds', 'Spades', 'Hearts'))\n\n    c = Card()\n    c.suit = 'Clubs'\n    c.save()\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        self.values = kwargs.pop('values')\n        kwargs['choices'] = [(v, v) for v in self.values]\n        kwargs['default'] = self.values[0]\n        super(EnumField, self).__init__(*args, **kwargs)\n\n    def db_type(self):\n        return \"enum({0)\".format( ','.join(\"'%s'\" % v for v in self.values) )\n<\/code><\/pre>\n",
                "<p>From the <a href=\"https:\/\/docs.djangoproject.com\/en\/dev\/ref\/models\/fields\/#django.db.models.Field.choices\" rel=\"nofollow\">Django documentation<\/a>:<\/p>\n\n<pre><code>MAYBECHOICE = (\n    ('y', 'Yes'),\n    ('n', 'No'),\n    ('u', 'Unknown'),\n)\n<\/code><\/pre>\n\n<p>And you define a charfield in your model :<\/p>\n\n<pre><code>married = models.CharField(max_length=1, choices=MAYBECHOICE)\n<\/code><\/pre>\n\n<p>You can do the same with integer fields if you don't like to have letters\nin your db.<\/p>\n\n<p>In that case, rewrite your choices:<\/p>\n\n<pre><code>MAYBECHOICE = (\n    (0, 'Yes'),\n    (1, 'No'),\n    (2, 'Unknown'),\n)\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_21934",
            "padroes": [
                "Python uses the reference count method to handle object life time. So an object that has no more use will be immediately destroyed.\n\nBut, in Java, the GC(garbage collector) destroys objects which are no longer used at a specific time.\n\nWhy does Java choose this strategy and what is the benefit from this?\n\nIs this better than the Python approach?\n"
            ],
            "respostas": [
                "<p>Late in the game, but I think one significant rationale for RC in python is its simplicity. See this <a href=\"http:\/\/mail.python.org\/pipermail\/python-list\/2005-October\/921938.html\" rel=\"nofollow\">email by Alex Martelli<\/a>, for example.<\/p>\n\n<p>(I could not find a link outside google cache, the email date from 13th october 2005 on python list).<\/p>\n",
                "<p>One big disadvantage of Java's tracing GC is that from time to time it will  \"stop the world\" and freeze the application for a relatively long time to do a full GC. If the heap is big and the the object tree complex, it will freeze for a few seconds. Also each full GC visits the whole object tree over and over again, something that is probably quite inefficient. Another drawback of the way Java does GC is that you have to tell the jvm what heap size you want (if the default is not good enough); the JVM derives from that value several thresholds that will trigger the GC process when there is too much garbage stacking up in the heap.<\/p>\n\n<p>I presume that this is actually the main cause of the jerky feeling of Android (based on Java), even on the most expensive cellphones, in comparison with the smoothness of iOS (based on ObjectiveC, and using RC). <\/p>\n\n<p>I'd love to see a jvm option to enable RC memory management, and maybe keeping GC only to run as a last resort when there is no more memory left. <\/p>\n",
                "<p>The latest Sun Java VM actually have multiple GC algorithms which you can tweak.  The Java VM specifications intentionally omitted specifying actual GC behaviour to allow different (and multiple) GC algorithms for different VMs.<\/p>\n\n<p>For example, for all the people who dislike the \"stop-the-world\" approach of the default Sun Java VM GC behaviour, there are VM such as <a href=\"http:\/\/www-01.ibm.com\/software\/webservers\/realtime\/\" rel=\"nofollow\">IBM's WebSphere Real Time<\/a> which allows real-time application to run on Java.<\/p>\n\n<p>Since the Java VM spec is publicly available, there is (theoretically) nothing stopping anyone from implementing a Java VM that uses CPython's GC algorithm.<\/p>\n",
                "<p>Reference counting is particularly difficult to do efficiently in a multi-threaded environment. I don't know how you'd even start to do it without getting into hardware assisted transactions or similar (currently) unusual atomic instructions.<\/p>\n\n<p>Reference counting is easy to implement. JVMs have had a lot of money sunk into competing implementations, so it shouldn't be surprising that they implement very good solutions to very difficult problems. However, it's becoming increasingly easy to target your favourite language at the JVM.<\/p>\n",
                "<p>Garbage collection is faster (more time efficient) than reference counting, if you have enough memory. For example, a copying gc traverses the \"live\" objects and copies them to a new space, and can reclaim all the \"dead\" objects in one step by marking a whole memory region. This is very efficient, <em>if<\/em> you have enough memory. Generational collections use the knowledge that \"most objects die young\"; often only a few percent of objects have to be copied.<\/p>\n\n<p>[This is also the reason why gc can be faster than malloc\/free]<\/p>\n\n<p>Reference counting is much more space efficient than garbage collection, since it reclaims memory the very moment it gets unreachable. This is nice when you want to attach finalizers to objects (e.g. to close a file once the File object gets unreachable). A reference counting system can work even when only a few percent of the memory is free. But the management cost of having to increment and decrement counters upon each pointer assignment cost a lot of time, and some kind of garbage collection is still needed to reclaim cycles.<\/p>\n\n<p>So the trade-off is clear: if you have to work in a memory-constrained environment, or if you need precise finalizers, use reference counting. If you have enough memory and need the speed, use garbage collection.<\/p>\n",
                "<p>I think the article \"<a href=\"http:\/\/www.ibm.com\/developerworks\/java\/library\/j-jtp10283\/\">Java theory and practice: A brief history of garbage collection<\/a>\" from IBM should help explain some of the questions you have.<\/p>\n",
                "<p>Darren Thomas gives a good answer.  However, one big difference between the Java and Python approaches is that with reference counting in the common case (no circular references) objects are cleaned up immediately rather than at some indeterminate later date.<\/p>\n\n<p>For example, I can write sloppy, non-portable code in CPython such as<\/p>\n\n<pre><code>def parse_some_attrs(fname):\n    return open(fname).read().split(\"~~~\")[2:4]\n<\/code><\/pre>\n\n<p>and the file descriptor for that file I opened will be cleaned up immediately because as soon as the reference to the open file goes away, the file is garbage collected and the file descriptor is freed.  Of course, if I run Jython or IronPython or possibly PyPy, then the garbage collector won't necessarily run until much later; possibly I'll run out of file descriptors first and my program will crash.<\/p>\n\n<p>So you SHOULD be writing code that looks like<\/p>\n\n<pre><code>def parse_some_attrs(fname):\n    with open(fname) as f:\n        return f.read().split(\"~~~\")[2:4]\n<\/code><\/pre>\n\n<p>but sometimes people like to rely on reference counting to always free up their resources because it can sometimes make your code a little shorter.<\/p>\n\n<p>I'd say that the best garbage collector is the one with the best performance, which currently seems to be the Java-style generational garbage collectors that can run in a separate thread and has all these crazy optimizations, etc.  The differences to how you write your code should be negligible and ideally non-existent.<\/p>\n",
                "<p>Actually reference counting and the strategies used by the Sun JVM are all different types of garbage collection algorithms.<\/p>\n\n<p>There are two broad approaches for tracking down dead objects: tracing and reference counting. In tracing the GC starts from the \"roots\" - things like stack references, and traces all reachable (live) objects. Anything that can't be reached is considered dead. In reference counting each time a reference is modified the object's involved have their count updated. Any object whose reference count gets set to zero is considered dead.<\/p>\n\n<p>With basically all GC implementations there are trade offs but tracing is usually good for high through put (i.e. fast) operation but has longer pause times (larger gaps where the UI or program may freeze up). Reference counting can operate in smaller chunks but will be slower overall. It may mean less freezes but poorer performance overall.<\/p>\n\n<p>Additionally a reference counting GC requires a cycle detector to clean up any objects in a cycle that won't be caught by their reference count alone. Perl 5 didn't have a cycle detector in its GC implementation and could leak memory that was cyclic.<\/p>\n\n<p>Research has also been done to get the best of both worlds (low pause times, high throughput):\n<a href=\"http:\/\/cs.anu.edu.au\/~Steve.Blackburn\/pubs\/papers\/urc-oopsla-2003.pdf\">http:\/\/cs.anu.edu.au\/~Steve.Blackburn\/pubs\/papers\/urc-oopsla-2003.pdf<\/a><\/p>\n",
                "<p>There are drawbacks of using reference counting. One of the most mentioned is circular references: Suppose A references B, B references C and C references B. If A were to drop its reference to B, both B and C will still have a reference count of 1 and won't be deleted with traditional reference counting. CPython (reference counting is not part of python itself, but part of the C implementation thereof) catches circular references with a separate garbage collection routine that it runs periodically...<\/p>\n\n<p>Another drawback: Reference counting can make execution slower. Each time an object is referenced and dereferenced, the interpreter\/VM must check to see if the count has gone down to 0 (and then deallocate if it did). Garbage Collection does not need to do this.<\/p>\n\n<p>Also, Garbage Collection can be done in a separate thread (though it can be a bit tricky). On machines with lots of RAM and for processes that use memory only slowly, you might not want to be doing GC at all! Reference counting would be a bit of a drawback there in terms of performance...<\/p>\n"
            ]
        },
        {
            "tag": "questao_21961",
            "padroes": [
                ">>> import time\n>>> time.strptime(\"01-31-2009\", \"%m-%d-%Y\")\n(2009, 1, 31, 0, 0, 0, 5, 31, -1)\n>>> time.mktime((2009, 1, 31, 0, 0, 0, 5, 31, -1))\n1233378000.0\n>>> 60*60*24 # seconds in a day\n86400\n>>> 1233378000.0 \/ 86400\n14275.208333333334\n\n\ntime.mktime should return the number of seconds since the epoch. Since I'm giving it a time at midnight and the epoch is at midnight, shouldn't the result be evenly divisible by the number of seconds in a day?\n"
            ],
            "respostas": [
                "<p>Interesting. I don't know, but I did try this:<\/p>\n\n<pre><code>&gt;&gt;&gt; now = time.mktime((2008, 8, 22, 11 ,17, -1, -1, -1, -1))\n&gt;&gt;&gt; tomorrow = time.mktime((2008, 8, 23, 11 ,17, -1, -1, -1, -1))\n&gt;&gt;&gt; tomorrow - now\n86400.0\n<\/code><\/pre>\n\n<p>which is what you expected. My guess? Maybe some time correction was done since the epoch. This could be only a few seconds, something like a leap year. I think I heard something like this before, but can't remember exactly how and when it is done...<\/p>\n",
                "<pre><code>mktime(...)\n    mktime(tuple) -&gt; floating point number\n\n    Convert a time tuple in local time to seconds since the Epoch.\n<\/code><\/pre>\n\n<p>local time... fancy that.<\/p>\n\n<p>The time tuple:<\/p>\n\n<pre><code>The other representation is a tuple of 9 integers giving local time.\nThe tuple items are:\n  year (four digits, e.g. 1998)\n  month (1-12)\n  day (1-31)\n  hours (0-23)\n  minutes (0-59)\n  seconds (0-59)\n  weekday (0-6, Monday is 0)\n  Julian day (day in the year, 1-366)\n  DST (Daylight Savings Time) flag (-1, 0 or 1)\nIf the DST flag is 0, the time is given in the regular time zone;\nif it is 1, the time is given in the DST time zone;\nif it is -1, mktime() should guess based on the date and time.\n<\/code><\/pre>\n\n<p>Incidentally, we seem to be 6 hours apart:<\/p>\n\n<pre><code>&gt;&gt;&gt; time.mktime((2009, 1, 31, 0, 0, 0, 5, 31, -1))\n1233356400.0\n&gt;&gt;&gt; (1233378000.0 - 1233356400)\/(60*60)\n6.0\n<\/code><\/pre>\n",
                "<p>Phil's answer really solved it, but I'll elaborate a little more. Since the epoch is in UTC, if I want to compare other times to the epoch, I need to interpret them as UTC as well.<\/p>\n\n<pre><code>&gt;&gt;&gt; calendar.timegm((2009, 1, 31, 0, 0, 0, 5, 31, -1))\n1233360000\n&gt;&gt;&gt; 1233360000 \/ (60*60*24)\n14275\n<\/code><\/pre>\n\n<p>By converting the time tuple to a timestamp treating is as UTC time, I get a number which <em>is<\/em> evenly divisible by the number of seconds in a day.<\/p>\n\n<p>I can use this to convert a date to a days-from-the-epoch representation which is what I'm ultimately after.<\/p>\n",
                "<p>Short answer: Because of timezones.<\/p>\n\n<p>The Epoch is in UTC.<\/p>\n\n<p>For example, I'm on IST (Irish Stsandard Time) or GMT+1. time.mktime() is relative to my timezone, so on my system this refers to<\/p>\n\n<pre><code>&gt;&gt;&gt; time.mktime((2009, 1, 31, 0, 0, 0, 5, 31, -1))\n1233360000.0\n<\/code><\/pre>\n\n<p>Because you got the result 1233378000, that would suggest that you're 5 hours behind me<\/p>\n\n<pre><code>&gt;&gt;&gt; (1233378000 - 1233360000) \/ (60*60)    \n5\n<\/code><\/pre>\n\n<p>Have a look at the time.gmtime() function which works off UTC.<\/p>\n"
            ]
        },
        {
            "tag": "questao_22149",
            "padroes": [
                "I stumbled over this passage in the Django tutorial:\n\n\n  Django models have a default str() method that calls unicode() and converts the result to a UTF-8 bytestring. This means that unicode(p) will return a Unicode string, and str(p) will return a normal string, with characters encoded as UTF-8.\n\n\nNow, I'm confused because afaik Unicode is not any particular representation, so what is a \"Unicode string\" in Python? Does that mean UCS-2? Googling turned up this \"Python Unicode Tutorial\" which boldly states\n\n\n  Unicode is a two-byte encoding which covers all of the world's common writing systems.\n\n\nwhich is plain wrong, or is it? I have been confused many times by character set and encoding issues, but here I'm quite sure that the documentation I'm reading is confused. Does anybody know what's going on in Python when it gives me a \"Unicode string\"?\n"
            ],
            "respostas": [
                "<blockquote>\n  <p>so what is a \"Unicode string\" in\n  Python?<\/p>\n<\/blockquote>\n\n<p>Python 'knows' that your string is Unicode. Hence if you do regex on it, it will know which is character and which is not etc, which is really helpful. If you did a strlen it will also give the correct result. As an example if you did string count on Hello, you will get 5 (even if it's Unicode). But if you did a string count of a foreign word and that string was not a Unicode string than you will have much larger result. Pythong uses the information form the Unicode Character Database to identify each character in the Unicode String. Hope that helps. <\/p>\n",
                "<p>From <a href=\"http:\/\/en.wikipedia.org\/wiki\/UTF-8\" rel=\"nofollow\">Wikipedia on UTF-8<\/a>: <\/p>\n\n<blockquote>\nUTF-8 (8-bit UCS\/Unicode Transformation Format) is a <strong>variable-length character encoding for Unicode. It is able to represent any character in the Unicode standard<\/strong>, yet the initial encoding of byte codes and character assignments for UTF-8 is backwards compatible with ASCII. For these reasons, it is steadily becoming the preferred encoding for e-mail, web pages[1], and other places where characters are stored or streamed.\n<\/blockquote>\n\n<p>So, it's anywhere between one and four bytes depending on which character you wish to represent within the realm of Unicode.<\/p>\n\n<p><a href=\"http:\/\/en.wikipedia.org\/wiki\/Unicode\" rel=\"nofollow\">From Wikipedia on Unicode:<\/a><\/p>\n\n<blockquote>\nIn computing, Unicode is an industry standard allowing computers to consistently represent and manipulate text expressed in <strong>most of the world's writing systems<\/strong>. \n<\/blockquote>\n\n<p>So it's able to represent most (but not all) of the world's writing systems. <\/p>\n\n<p>I hope this helps :)<\/p>\n",
                "<p>Python stores Unicode as UTF-16. str() will return the UTF-8 representation of the UTF-16 string.<\/p>\n",
                "<p>Meanwhile, I did a refined research to verify what the internal representation in Python is, and also what its limits are. \"<a href=\"http:\/\/www.cmlenz.net\/archives\/2008\/07\/the-truth-about-unicode-in-python\">The Truth About Unicode In Python<\/a>\" is a very good article which cites directly from the Python developers. Apparently, internal representation is either UCS-2 or UCS-4 depending on a compile-time switch. So Jon, it's not UTF-16, but your answer put me on the right track anyway, thanks.<\/p>\n",
                "<blockquote>\n  <p>what is a \"Unicode string\" in Python? Does that mean UCS-2?<\/p>\n<\/blockquote>\n\n<p>Unicode strings in Python are stored internally either as UCS-2 (fixed-length 16-bit representation, almost the same as UTF-16) or UCS-4\/UTF-32 (fixed-length 32-bit representation). It's a compile-time option; on Windows it's always UTF-16 whilst many Linux distributions set UTF-32 (ÃÃÃ¿wide modeÃÃÃ) for their versions of Python.<\/p>\n\n<p>You are generally not supposed to care: you will see Unicode code-points as single elements in your strings and you won't know whether they're stored as two or four bytes. If you're in a UTF-16 build and you need to handle characters outside the Basic Multilingual Plane you'll be Doing It Wrong, but that's still very rare, and users who really need the extra characters should be compiling wide builds.<\/p>\n\n<blockquote>\n  <p>plain wrong, or is it?<\/p>\n<\/blockquote>\n\n<p>Yes, it's quite wrong. To be fair I think that tutorial is rather old; it probably pre-dates wide Unicode strings, if not Unicode 3.1 (the version that introduced characters outside the Basic Multilingual Plane).<\/p>\n\n<p>There is an additional source of confusion stemming from Windows's habit of using the term ÃÃÂ£UnicodeÃÃÃ to mean, specifically, the UTF-16LE encoding that NT uses internally. People from Microsoftland may often copy this somewhat misleading habit.<\/p>\n"
            ]
        },
        {
            "tag": "questao_22617",
            "padroes": [
                "I need to find out how to format numbers as strings. My code is here:\n\nreturn str(hours)+\":\"+str(minutes)+\":\"+str(seconds)+\" \"+ampm\n\n\nHours and minutes are integers, and seconds is a float.  the str() function will convert all of these numbers to the tenths (0.1) place.  So instead of my string outputting \"5:30:59.07 pm\", it would display something like \"5.0:30.0:59.1 pm\".\n\nBottom line, what library \/ function do I need to do this for me?\n"
            ],
            "respostas": [
                "<p><em>str()<\/em> in python on an integer will <strong>not<\/strong> print any decimal places.<\/p>\n\n<p>If you have a float that you want to ignore the decimal part, then you can use str(int(floatValue)).<\/p>\n\n<p>Perhaps the following code will demonstrate:<\/p>\n\n<pre><code>&gt;&gt;&gt; str(5)\n'5'\n&gt;&gt;&gt; int(8.7)\n8\n<\/code><\/pre>\n",
                "<p>If you have a value that includes a decimal, but the decimal value is negligible (ie: 100.0) and try to int that, you will get an error.  It seems silly, but calling float first fixes this.<\/p>\n\n<p>str(int(float([variable])))<\/p>\n",
                "<p>You can use following to achieve desired functionality<\/p>\n\n<pre><code>\"%d:%d:d\" % (hours, minutes, seconds)\n<\/code><\/pre>\n",
                "<p>You can use C style string formatting:<\/p>\n\n<pre><code>\"%d:%d:d\" % (hours, minutes, seconds)\n<\/code><\/pre>\n\n<p>See here, especially: <a href=\"https:\/\/web.archive.org\/web\/20120415173443\/http:\/\/diveintopython3.ep.io\/strings.html\" rel=\"nofollow\">https:\/\/web.archive.org\/web\/20120415173443\/http:\/\/diveintopython3.ep.io\/strings.html<\/a><\/p>\n",
                "<p>Starting in Python 2.6, there is an alternative: the <code>str.format()<\/code> method. Here are some examples using the existing string format operator (<code>%<\/code>):<\/p>\n\n<pre><code>&gt;&gt;&gt; \"Name: %s, age: %d\" % ('John', 35) \n'Name: John, age: 35' \n&gt;&gt;&gt; i = 45 \n&gt;&gt;&gt; 'dec: %d\/oct: %#o\/hex: %#X' % (i, i, i) \n'dec: 45\/oct: 055\/hex: 0X2D' \n&gt;&gt;&gt; \"MM\/DD\/YY = %02d\/%02d\/%02d\" % (12, 7, 41) \n'MM\/DD\/YY = 12\/07\/41' \n&gt;&gt;&gt; 'Total with tax: $%.2f' % (13.00 * 1.0825) \n'Total with tax: $14.07' \n&gt;&gt;&gt; d = {'web': 'user', 'page': 42 \n&gt;&gt;&gt; 'http:\/\/xxx.yyy.zzz\/%(web)s\/%(page)d.html' % d \n'http:\/\/xxx.yyy.zzz\/user\/42.html' \n<\/code><\/pre>\n\n<p>Here are the equivalent snippets but using <code>str.format()<\/code>:<\/p>\n\n<pre><code>&gt;&gt;&gt; \"Name: {0, age: {1\".format('John', 35) \n'Name: John, age: 35' \n&gt;&gt;&gt; i = 45 \n&gt;&gt;&gt; 'dec: {0\/oct: {0:#o\/hex: {0:#X'.format(i) \n'dec: 45\/oct: 0o55\/hex: 0X2D' \n&gt;&gt;&gt; \"MM\/DD\/YY = {0:02d\/{1:02d\/{2:02d\".format(12, 7, 41) \n'MM\/DD\/YY = 12\/07\/41' \n&gt;&gt;&gt; 'Total with tax: ${0:.2f'.format(13.00 * 1.0825) \n'Total with tax: $14.07' \n&gt;&gt;&gt; d = {'web': 'user', 'page': 42 \n&gt;&gt;&gt; 'http:\/\/xxx.yyy.zzz\/{web\/{page.html'.format(**d) \n'http:\/\/xxx.yyy.zzz\/user\/42.html'\n<\/code><\/pre>\n\n<p>Like Python 2.6+, all Python 3 releases (so far) understand how to do both. I shamelessly ripped this stuff straight out of <a href=\"http:\/\/amzn.com\/0132269937\">my hardcore Python intro book<\/a> and the slides for the Intro+Intermediate <a href=\"http:\/\/cyberwebconsulting.com\">Python courses I offer<\/a> from time-to-time. <code>:-)<\/code><\/p>\n",
                "<p>Formatting in Python is done via the <a href=\"http:\/\/docs.python.org\/2\/library\/stdtypes.html#string-formatting\">string formatting (<code>%<\/code>) operator<\/a>:<\/p>\n\n<pre><code>\"%02d:%02d:%02d\" % (hours, minutes, seconds)\n<\/code><\/pre>\n\n<p>\/Edit: There's also <a href=\"https:\/\/docs.python.org\/2\/library\/time.html#time.strftime\">strftime<\/a>.<\/p>\n"
            ]
        },
        {
            "tag": "questao_22676",
            "padroes": [
                "I have a small utility that I use to download a MP3 from a website on a schedule and then builds\/updates a podcast XML file which I've obviously added to iTunes.\n\nThe text processing that creates\/updates the XML file is written in Python. I use wget inside a Windows .bat file to download the actual MP3 however. I would prefer to have the entire utility written in Python though.\n\nI struggled though to find a way to actually down load the file in Python, thus why I resorted to wget.\n\nSo, how do I download the file using Python?\n"
            ],
            "respostas": [
                "<p>Source code can be:<\/p>\n\n<pre><code>import urllib\nsock = urllib.urlopen(\"http:\/\/diveintopython.org\/\")\nhtmlSource = sock.read()                            \nsock.close()                                        \nprint htmlSource  \n<\/code><\/pre>\n",
                "<p>If you have wget installed, you can use parallel_sync.<\/p>\n\n<p>pip install parallel_sync<\/p>\n\n<pre><code>from parallel_sync import wget\nurls = ['http:\/\/something.png', 'http:\/\/somthing.tar.gz', 'http:\/\/somthing.zip']\nwget.download('\/tmp', urls)\n# or a single file:\nwget.download('\/tmp', urls[0], filenames='x.zip', extract=True)\n<\/code><\/pre>\n\n<p>Doc:\n<a href=\"https:\/\/pythonhosted.org\/parallel_sync\/pages\/examples.html\" rel=\"nofollow\">https:\/\/pythonhosted.org\/parallel_sync\/pages\/examples.html<\/a><\/p>\n\n<p>This is pretty powerful. It can download files in parallel, retry upon failure , and it can even download files on a remote machine.<\/p>\n",
                "<p>Following are the most commonly used calls for downloading files in python:<\/p>\n\n<ol>\n<li><p><code>urllib.urlretrieve ('url_to_file', file_name)<\/code><\/p><\/li>\n<li><p><code>urllib2.urlopen('url_to_file')<\/code><\/p><\/li>\n<li><p><code>requests.get(url)<\/code><\/p><\/li>\n<li><p><code>wget.download('url', file_name)<\/code><\/p><\/li>\n<\/ol>\n\n<p>Note: <code>urlopen<\/code> and <code>urlretrieve<\/code> are found to perform relatively bad with downloading large files (size > 500 MB). <code>requests.get<\/code> stores the file in-memory until download is complete.  <\/p>\n",
                "<p>This may be a little late, But I saw pabloG's code and couldn't help adding a os.system('cls') to make it look AWESOME! Check it out : <\/p>\n\n<pre><code>    import urllib2,os\n\n    url = \"http:\/\/download.thinkbroadband.com\/10MB.zip\"\n\n    file_name = url.split('\/')[-1]\n    u = urllib2.urlopen(url)\n    f = open(file_name, 'wb')\n    meta = u.info()\n    file_size = int(meta.getheaders(\"Content-Length\")[0])\n    print \"Downloading: %s Bytes: %s\" % (file_name, file_size)\n    os.system('cls')\n    file_size_dl = 0\n    block_sz = 8192\n    while True:\n        buffer = u.read(block_sz)\n        if not buffer:\n            break\n\n        file_size_dl += len(buffer)\n        f.write(buffer)\n        status = r\"%10d  [%3.2f%%]\" % (file_size_dl, file_size_dl * 100. \/ file_size)\n        status = status + chr(8)*(len(status)+1)\n        print status,\n\n    f.close()\n<\/code><\/pre>\n",
                "<p>You can get the progress feedback with urlretrieve as well:<\/p>\n\n<pre><code>def report(blocknr, blocksize, size):\n    current = blocknr*blocksize\n    sys.stdout.write(\"\\r{0:.2f%\".format(100.0*current\/size))\n\ndef downloadFile(url):\n    print \"\\n\",url\n    fname = url.split('\/')[-1]\n    print fname\n    urllib.urlretrieve(url, fname, report)\n<\/code><\/pre>\n",
                "<p>use wget module:<\/p>\n\n<pre><code>import wget\nwget.download('url')\n<\/code><\/pre>\n",
                "<p>I agree with Corey, urllib2 is more complete than <a href=\"http:\/\/docs.python.org\/lib\/module-urllib.html\">urllib<\/a> and should likely be the module used if you want to do more complex things, but to make the answers more complete, urllib is a simpler module if you want just the basics:<\/p>\n\n<pre><code>import urllib\nresponse = urllib.urlopen('http:\/\/www.example.com\/sound.mp3')\nmp3 = response.read()\n<\/code><\/pre>\n\n<p>Will work fine. Or, if you don't want to deal with the \"response\" object you can call <strong>read()<\/strong> directly:<\/p>\n\n<pre><code>import urllib\nmp3 = urllib.urlopen('http:\/\/www.example.com\/sound.mp3').read()\n<\/code><\/pre>\n",
                "<p>Wrote <a href=\"https:\/\/pypi.python.org\/pypi\/wget\">wget<\/a> library in pure Python just for this purpose. It is pumped up <code>urlretrieve<\/code> with <a href=\"https:\/\/bitbucket.org\/techtonik\/python-wget\/src\/6859e7b4aba37cef57616111be890fb59631bc4c\/wget.py?at=default#cl-330\">these features<\/a> as of version 2.0.<\/p>\n",
                "<p>An improved version of the PabloG code for Python 2\/3:<\/p>\n\n<pre><code>from __future__ import ( division, absolute_import, print_function, unicode_literals )\n\nimport sys, os, tempfile, logging\n\nif sys.version_info &gt;= (3,):\n    import urllib.request as urllib2\n    import urllib.parse as urlparse\nelse:\n    import urllib2\n    import urlparse\n\ndef download_file(url, desc=None):\n    u = urllib2.urlopen(url)\n\n    scheme, netloc, path, query, fragment = urlparse.urlsplit(url)\n    filename = os.path.basename(path)\n    if not filename:\n        filename = 'downloaded.file'\n    if desc:\n        filename = os.path.join(desc, filename)\n\n    with open(filename, 'wb') as f:\n        meta = u.info()\n        meta_func = meta.getheaders if hasattr(meta, 'getheaders') else meta.get_all\n        meta_length = meta_func(\"Content-Length\")\n        file_size = None\n        if meta_length:\n            file_size = int(meta_length[0])\n        print(\"Downloading: {0 Bytes: {1\".format(url, file_size))\n\n        file_size_dl = 0\n        block_sz = 8192\n        while True:\n            buffer = u.read(block_sz)\n            if not buffer:\n                break\n\n            file_size_dl += len(buffer)\n            f.write(buffer)\n\n            status = \"{0:16\".format(file_size_dl)\n            if file_size:\n                status += \"   [{0:6.2f%]\".format(file_size_dl * 100 \/ file_size)\n            status += chr(13)\n            print(status, end=\"\")\n        print()\n\n    return filename\n\nurl = \"http:\/\/download.thinkbroadband.com\/10MB.zip\"\nfilename = download_file(url)\nprint(filename)\n<\/code><\/pre>\n",
                "<p>Here's how to do it in Python 3 using the standard library:<\/p>\n\n<ul>\n<li><p><a href=\"https:\/\/docs.python.org\/3.0\/library\/urllib.request.html#urllib.request.urlopen\"><code>urllib.request.urlopen<\/code><\/a><\/p>\n\n<pre><code>import urllib.request\nresponse = urllib.request.urlopen('http:\/\/www.example.com\/')\nhtml = response.read()\n<\/code><\/pre><\/li>\n<li><p><a href=\"https:\/\/docs.python.org\/3.0\/library\/urllib.request.html#urllib.request.urlretrieve\"><code>urllib.request.urlretrieve<\/code><\/a><\/p>\n\n<pre><code>import urllib.request\nurllib.request.urlretrieve('http:\/\/www.example.com\/songs\/mp3.mp3', 'mp3.mp3')\n<\/code><\/pre><\/li>\n<\/ul>\n",
                "<pre class=\"lang-py prettyprint-override\"><code>import urllib2\nmp3file = urllib2.urlopen(\"http:\/\/www.example.com\/songs\/mp3.mp3\")\nwith open('test.mp3','wb') as output:\n  output.write(mp3file.read())\n<\/code><\/pre>\n\n<p>The <code>wb<\/code> in <code>open('test.mp3','wb')<\/code> opens a file (and erases any existing file) in binary mode so you can save data with it instead of just text.<\/p>\n",
                "<p>In 2012, use the <a href=\"http:\/\/docs.python-requests.org\/en\/latest\/index.html\">python requests library<\/a><\/p>\n\n<pre><code>&gt;&gt;&gt; import requests\n&gt;&gt;&gt; \n&gt;&gt;&gt; url = \"http:\/\/download.thinkbroadband.com\/10MB.zip\"\n&gt;&gt;&gt; r = requests.get(url)\n&gt;&gt;&gt; print len(r.content)\n10485760\n<\/code><\/pre>\n\n<p>You can run <code>pip install requests<\/code> to get it.<\/p>\n\n<p>Requests has many advantages over the alternatives because the API is much simpler. This is especially true if you have to do authentication. urllib and urllib2 are pretty unintuitive and painful in this case.<\/p>\n\n<hr>\n\n<p>2015-12-30<\/p>\n\n<p>People have expressed admiration for the progress bar. It's cool, sure. There are several off-the-shelf solutions now, including <code>tqdm<\/code>:<\/p>\n\n<pre><code>from tqdm import tqdm\nimport requests\n\nurl = \"http:\/\/download.thinkbroadband.com\/10MB.zip\"\nresponse = requests.get(url, stream=True)\n\nwith open(\"10MB\", \"wb\") as handle:\n    for data in tqdm(response.iter_content()):\n        handle.write(data)\n<\/code><\/pre>\n\n<p>This is essentially the implementation @kvance described 30 months ago.<\/p>\n",
                "<p>In Python 2, use urllib2 which comes with the standard library.<\/p>\n\n<pre><code>import urllib2\nresponse = urllib2.urlopen('http:\/\/www.example.com\/')\nhtml = response.read()\n<\/code><\/pre>\n\n<p>This is the most basic way to use the library, minus any error handling.  You can also do more complex stuff such as changing headers.  The documentation can be found <a href=\"http:\/\/docs.python.org\/2\/library\/urllib2.html\">here.<\/a><\/p>\n",
                "<p>One more, using <a href=\"http:\/\/docs.python.org\/2\/library\/urllib.html#urllib.urlretrieve\"><code>urlretrieve<\/code><\/a>:<\/p>\n\n<pre><code>import urllib\nurllib.urlretrieve (\"http:\/\/www.example.com\/songs\/mp3.mp3\", \"mp3.mp3\")\n<\/code><\/pre>\n\n<p>(for Python 3+ use 'import urllib.request' and urllib.request.urlretrieve)<\/p>\n\n<p>Yet another one, with a \"progressbar\"<\/p>\n\n<pre><code>import urllib2\n\nurl = \"http:\/\/download.thinkbroadband.com\/10MB.zip\"\n\nfile_name = url.split('\/')[-1]\nu = urllib2.urlopen(url)\nf = open(file_name, 'wb')\nmeta = u.info()\nfile_size = int(meta.getheaders(\"Content-Length\")[0])\nprint \"Downloading: %s Bytes: %s\" % (file_name, file_size)\n\nfile_size_dl = 0\nblock_sz = 8192\nwhile True:\n    buffer = u.read(block_sz)\n    if not buffer:\n        break\n\n    file_size_dl += len(buffer)\n    f.write(buffer)\n    status = r\"%10d  [%3.2f%%]\" % (file_size_dl, file_size_dl * 100. \/ file_size)\n    status = status + chr(8)*(len(status)+1)\n    print status,\n\nf.close()\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_22059",
            "padroes": [
                "I was wondering how as semantic service like Open Calais figures out the names of companies, or people, tech concepts, keywords, etc. from a piece of text. Is it because they have a large database that they match the text against? \n\nHow would a service like Zemanta know what images to suggest to a piece of text for instance? \n"
            ],
            "respostas": [
                "<p>Open Calais probably use language parsing technology and language statics to guess which words or phrases are Names, Places, Companies, etc. Then, it is just another step to do some kind of search for those entities and return meta data.<\/p>\n\n<p>Zementa probably does something similar, but matches the phrases against meta-data attached to images in order to acquire related results.<\/p>\n\n<p>It certainly isn't easy.<\/p>\n",
                "<p>I'm not familiar with the specific services listed, but the field of natural language processing has developed a number of techniques that enable this sort of information extraction from general text.  As Sean stated, once you have candidate terms, it's not to difficult to search for those terms with some of the other entities in context and then use the results of that search to determine how confident you are that the term extracted is an actual entity of interest.<\/p>\n\n<p><a href=\"http:\/\/opennlp.sourceforge.net\/\">OpenNLP<\/a> is a great project if you'd like to play around with natural language processing.  The capabilities you've named would probably be best accomplished with Named Entity Recognizers (NER) (algorithms that locate proper nouns, generally, and sometimes dates as well) and\/or Word Sense Disambiguation (WSD) (eg: the word 'bank' has different meanings depending on it's context, and that can be very important when extracting information from text.  Given the sentences: \"the plane banked left\", \"the snow bank was high\", and \"they robbed the bank\" you can see how dissambiguation can play an important part in language understanding)<\/p>\n\n<p>Techniques generally build on each other, and NER is one of the more complex tasks, so to do NER successfully, you will generally need accurate tokenizers (natural language tokenizers, mind you -- statistical approaches tend to fare the best), string stemmers (algorithms that conflate similar words to common roots: so words like informant and informer are treated equally), sentence detection ('Mr. Jones was tall.' is only one sentence, so you can't just check for punctuation), part-of-speech taggers (POS taggers), and WSD.<\/p>\n\n<p>There is a python port of (parts of) OpenNLP called NLTK (<a href=\"http:\/\/nltk.sourceforge.net\">http:\/\/nltk.sourceforge.net<\/a>) but I don't have much experience with it yet.  Most of my work has been with the Java and C# ports, which work well.  <\/p>\n\n<p>All of these algorithms are language-specific, of course, and they can take significant time to run (although, it is generally faster than reading the material you are processing).  Since the state-of-the-art is largely based on statistical techniques, there is also a considerable error rate to take into account.  Furthermore, because the error rate impacts all the stages, and something like NER requires numerous stages of processing, (tokenize -> sentence detect -> POS tag -> WSD -> NER) the error rates compound.<\/p>\n",
                "<p>Michal Finkelstein from OpenCalais here.<\/p>\n\n<p>First, thanks for your interest. I'll reply here but I also encourage you to read more on OpenCalais forums; there's a lot of information there including - but not limited to:\n<a href=\"http:\/\/opencalais.com\/tagging-information\">http:\/\/opencalais.com\/tagging-information<\/a>\n<a href=\"http:\/\/opencalais.com\/how-does-calais-learn\">http:\/\/opencalais.com\/how-does-calais-learn<\/a>\nAlso feel free to follow us on Twitter (@OpenCalais) or to email us at team@opencalais.com<\/p>\n\n<p>Now to the answer:<\/p>\n\n<p>OpenCalais is based on a decade of research and development in the fields of Natural Language Processing and Text Analytics.<\/p>\n\n<p>We support the full \"NLP Stack\" (as we like to call it):\nFrom text tokenization, morphological analysis and POS tagging, to shallow parsing and identifying nominal and verbal phrases.<\/p>\n\n<p>Semantics come into play when we look for Entities (a.k.a. Entity Extraction, Named Entity Recognition). For that purpose we have a sophisticated rule-based system that combines discovery rules as well as lexicons\/dictionaries. This combination allows us to identify names of companies\/persons\/films, etc., even if they don't exist in any available list.<\/p>\n\n<p>For the most prominent entities (such as people, companies) we also perform anaphora resolution, cross-reference and name canonization\/normalization at the article level, so we'll know that 'John Smith' and 'Mr. Smith', for example, are likely referring to the same person.\nSo the short answer to your question is - no, it's not just about matching against large databases.<\/p>\n\n<p>Events\/Facts are really interesting because they take our discovery rules one level deeper; we find relations between entities and label them with the appropriate type, for example M&amp;As (relations between two or more companies), Employment Changes (relations between companies and people), and so on. Needless to say, Event\/Fact extraction is not possible for systems that are based solely on lexicons.\nFor the most part, our system is tuned to be precision-oriented, but we always try to keep a reasonable balance between accuracy and entirety.<\/p>\n\n<p>By the way there are some cool new metadata capabilities coming out later this month so stay tuned.<\/p>\n\n<p>Regards,<\/p>\n\n<p>Michal<\/p>\n"
            ]
        },
        {
            "tag": "questao_23397",
            "padroes": [
                "How do I implement some logic that will allow me to reproduce on Windows the functionality that I have on Linux with the fork() system call, using Python?\n\nI'm specifically trying to execute a method on the SAPI Com component, while continuing the other logic in the main thread without blocking or waiting.\n"
            ],
            "respostas": [
                "<p>Possibly a version of spawn() for python? <a href=\"http:\/\/en.wikipedia.org\/wiki\/Spawn_(operating_system)\" rel=\"nofollow\">http:\/\/en.wikipedia.org\/wiki\/Spawn_(operating_system)<\/a><\/p>\n",
                "<p>You might also like using the processing module (<a href=\"http:\/\/pypi.python.org\/pypi\/processing\" rel=\"nofollow\">http:\/\/pypi.python.org\/pypi\/processing<\/a>). It has lot's of functionality for writing parallel systems with the same API as the threading module...<\/p>\n",
                "<p>The Threading example from Eli will run the thread, but not do any of the work after that line.  <\/p>\n\n<p>I'm going to look into the processing module and the subprocess module.  I think the com method I'm running needs to be in another process, not just in another thread.<\/p>\n",
                "<p>In addition to the process management code in the os module that Greg pointed out, you should also take a look at the threading module: <a href=\"https:\/\/docs.python.org\/library\/threading.html\" rel=\"nofollow\">https:\/\/docs.python.org\/library\/threading.html<\/a><\/p>\n\n<pre><code>from threading import Thread\n\ndef separate_computations(x, y):\n    print sum(x for i in range(y))  # really expensive multiplication\n\nThread(target=separate_compuations, args=[57, 83]).start()\nprint \"I'm continuing while that other function runs in another thread!\"\n<\/code><\/pre>\n",
                "<p>Have a look at the process management functions in the <a href=\"http:\/\/python.org\/doc\/2.5\/lib\/os-process.html\" rel=\"nofollow\">os module<\/a>. There are function for starting new processes in many different ways, both synchronously and asynchronously.<\/p>\n\n<p>I should note also that Windows doesn't provide functionality that is exactly like fork() on other systems. To do multiprocessing on Windows, you will need to use the <a href=\"http:\/\/python.org\/doc\/2.5\/lib\/module-threading.html\" rel=\"nofollow\">threading<\/a> module.<\/p>\n",
                "<p><code>fork()<\/code> <em>has<\/em> in fact been duplicated in Windows, under <a href=\"https:\/\/en.wikipedia.org\/wiki\/Cygwin\" rel=\"nofollow\">Cygwin<\/a>, but it's pretty hairy.<\/p>\n\n<blockquote>\n  <p>The fork call in Cygwin is particularly interesting because it does not map well on top of the Win32 API. This makes it very difficult to implement correctly.<\/p>\n<\/blockquote>\n\n<p>See the <a href=\"http:\/\/cygwin.com\/cygwin-ug-net\/highlights.html#ov-hi-process\" rel=\"nofollow\">The Cygwin User's Guide<\/a> for a description of this hack.<\/p>\n",
                "<p>Use the python <a href=\"http:\/\/docs.python.org\/library\/multiprocessing.html\">multiprocessing module<\/a> which will work everywhere.<\/p>\n\n<p>Here is a <a href=\"http:\/\/www.ibm.com\/developerworks\/aix\/library\/au-multiprocessing\/\">IBM developerWords article<\/a> that shows how to convert from os.fork() to the multiprocessing module.<\/p>\n"
            ]
        },
        {
            "tag": "questao_23907",
            "padroes": [
                "Basically I want to get the number of lines-of-code in the repository after each commit.\n\nThe only (really crappy) ways I have found is to use git filter-branch to run \"wc -l *\", and a script that run git reset --hard on each commit, then ran wc -l\n\nTo make it a bit clearer, when the tool is run, it would output the lines of code of the very first commit, then the second and so on.. This is what I want the tool to output (as an example):\n\nme@something:~\/$ gitsloc --branch master\n10\n48\n153\n450\n1734\n1542\n\n\nI've played around with the ruby 'git' library, but the closest I found was using the .lines() method on a diff, which seems like it should give the added lines (but does not.. it returns 0 when you delete lines for example)\n\nrequire 'rubygems'\nrequire 'git'\n\ntotal = 0\ng = Git.open(working_dir = '\/Users\/dbr\/Desktop\/code_projects\/tvdb_api')\n\n\nlast = nil\ng.log.each do |cur|\n  diff = g.diff(last, cur)\n  total = total + diff.lines\n  puts total\n  last = cur\nend\n\n"
            ],
            "respostas": [
                "<p>The first thing that jumps to mind is the possibility of your git history having a nonlinear history. You might have difficulty determining a sensible sequence of commits.<\/p>\n\n<p>Having said that, it seems like you could keep a log of commit ids and the corresponding lines of code in that commit. In a post-commit hook, starting from the HEAD revision, work backwards (branching to multiple parents if necessary) until all paths reach a commit that you've already seen before. That should give you the total lines of code for each commit id.<\/p>\n\n<p>Does that help any? I have a feeling that I've misunderstood something about your question.<\/p>\n",
                "<p><a href=\"http:\/\/github.com\/ITikhonov\/git-loc\">http:\/\/github.com\/ITikhonov\/git-loc<\/a> worked right out of the box for me.<\/p>\n",
                "<p>You may get both added and removed lines with git log, like:<\/p>\n\n<pre><code>git log --shortstat --reverse --pretty=oneline\n<\/code><\/pre>\n\n<p>From this, you can write a similar script to the one you did using this info. In python:<\/p>\n\n<pre><code>#!\/usr\/bin\/python\n\n\"\"\"\nDisplay the per-commit size of the current git branch.\n\"\"\"\n\nimport subprocess\nimport re\nimport sys\n\ndef main(argv):\n  git = subprocess.Popen([\"git\", \"log\", \"--shortstat\", \"--reverse\",\n                        \"--pretty=oneline\"], stdout=subprocess.PIPE)\n  out, err = git.communicate()\n  total_files, total_insertions, total_deletions = 0, 0, 0\n  for line in out.split('\\n'):\n    if not line: continue\n    if line[0] != ' ': \n      # This is a description line\n      hash, desc = line.split(\" \", 1)\n    else:\n      # This is a stat line\n      data = re.findall(\n        ' (\\d+) files changed, (\\d+) insertions\\(\\+\\), (\\d+) deletions\\(-\\)', \n        line)\n      files, insertions, deletions = ( int(x) for x in data[0] )\n      total_files += files\n      total_insertions += insertions\n      total_deletions += deletions\n      print \"%s: %d files, %d lines\" % (hash, total_files,\n                                        total_insertions - total_deletions)\n\n\nif __name__ == '__main__':\n  sys.exit(main(sys.argv))\n<\/code><\/pre>\n",
                "<p>You might also consider <a href=\"http:\/\/gitstats.sourceforge.net\/\">gitstats<\/a>, which generates this graph as an html file.  <\/p>\n"
            ]
        },
        {
            "tag": "questao_24193",
            "padroes": [
                "I had an idea, if I add a python .py file to my C# project, and tag the file with a custom generator that would execute the python file, and treat the output as the result of the code generation, ie. put it into a C# file, that would allow me to do quite a lot of code generation as part of the build process.\n\nDoes anyone know if such a custom generator for Visual Studio 2008 exists?\n"
            ],
            "respostas": [
                "<p>I don't understand what you are trying to do here. Are you trying to execute a Python script that generates a C# file and then compile that with the project? Or are you trying to compile a Python script to C#?<\/p>\n",
                "<p>OK, I see. Well, as far as I know there isn't any code generator for Python. There is a good introduction on how to roll your own <a href=\"http:\/\/www.drewnoakes.com\/snippets\/WritingACustomCodeGeneratorToolForVisualStudio\/\" rel=\"nofollow\">here<\/a>.<\/p>\n\n<p>Actually, that's quite an under-used part of the environment, I suppose it's so because it needs you to use the IDE to compile the project, as it'd seem only the IDE knows about these \"generators\", but MSBuild ignores them.<\/p>\n",
                "<p>I dug through my old bookmarks (I love Del.icio.us!) and found this article: <a href=\"http:\/\/blogs.acceleration.net\/ryan\/articles\/577.aspx\" rel=\"nofollow\">Code Generation with Python, Cog, and Nant<\/a>. Keep in mind that anything you can do in NAnt can probably be done in MSBuild as well. This should be enough to get you started.<\/p>\n",
                "<p>I recall that in previous versions of VS, there was a way to add custom build steps to the build process. I used that a lot to do exactly the kind of automated code generation you describe.<\/p>\n\n<p>I imagine the custom build step feature is still there in 2008.<\/p>\n",
                "<p>I think <a href=\"http:\/\/nedbatchelder.com\/code\/cog\/\" rel=\"nofollow\">Cog<\/a> does what you want.<\/p>\n"
            ]
        },
        {
            "tag": "questao_24931",
            "padroes": [
                "\n- Is it possible to capture Python interpreter's output from a Python script?- Is it possible to capture Windows CMD's output from a Python script?\n\nIf so, which librar(y|ies) should I look into?\n"
            ],
            "respostas": [
                "<p>In which context are you asking?<\/p>\n\n<p>Are you trying to capture the output from a program you start on the command line?<\/p>\n\n<p>if so, then this is how to execute it:<\/p>\n\n<pre><code>somescript.py | your-capture-program-here\n<\/code><\/pre>\n\n<p>and to read the output, just read from standard input.<\/p>\n\n<p>If, on the other hand, you're executing that script or cmd.exe or similar from within your program, and want to wait until the script\/program has finished, and capture all its output, then you need to look at the library calls you use to start that external program, most likely there is a way to ask it to give you some way to read the output and wait for completion.<\/p>\n",
                "<p>You want <a href=\"http:\/\/docs.python.org\/lib\/module-subprocess.html\" rel=\"nofollow\">subprocess<\/a>. Look specifically at Popen in 17.1.1 and communicate in 17.1.2.<\/p>\n",
                "<p>Actually, you definitely can, and it's beautiful, ugly, and crazy at the same time!<\/p>\n\n<p>You can replace sys.stdout and sys.stderr with StringIO objects that collect the output.<\/p>\n\n<p>Here's an example, save it as evil.py:<\/p>\n\n<pre><code>import sys\nimport StringIO\n\ns = StringIO.StringIO()\n\nsys.stdout = s\n\nprint \"hey, this isn't going to stdout at all!\"\nprint \"where is it ?\"\n\nsys.stderr.write('It actually went to a StringIO object, I will show you now:\\n')\nsys.stderr.write(s.getvalue())\n<\/code><\/pre>\n\n<p>When you run this program, you will see that:<\/p>\n\n<ul>\n<li>nothing went to stdout (where print usually prints to)<\/li>\n<li>the first string that gets written to stderr is the one starting with 'It'<\/li>\n<li>the next two lines are the ones that were collected in the StringIO object<\/li>\n<\/ul>\n\n<p>Replacing sys.stdout\/err like this is an application of what's called monkeypatching.  Opinions may vary whether or not this is 'supported', and it is definitely an ugly hack, but it has saved my bacon when trying to wrap around external stuff once or twice.<\/p>\n\n<p>Tested on Linux, not on Windows, but it should work just as well.  Let me know if it works on Windows!<\/p>\n",
                "<p>I think I can point you to a good answer for the first part of your question. <\/p>\n\n<blockquote>\n  <p><em>1.&nbsp;&nbsp;Is it possible to capture Python interpreter's output from a Python\n  script?<\/em><\/p>\n<\/blockquote>\n\n<p>The answer is \"<em>yes<\/em>\", and personally I like the following lifted from the examples in the <em><a href=\"http:\/\/www.python.org\/dev\/peps\/pep-0343\/\" rel=\"nofollow\">PEP 343 -- The \"with\" Statement<\/a><\/em> document.<\/p>\n\n<pre><code>from contextlib import contextmanager\nimport sys\n\n@contextmanager\ndef stdout_redirected(new_stdout):\n    saved_stdout = sys.stdout\n    sys.stdout = new_stdout\n    try:\n        yield None\n    finally:\n        sys.stdout.close()\n        sys.stdout = saved_stdout\n<\/code><\/pre>\n\n<p>And used like this:<\/p>\n\n<pre><code>with stdout_redirected(open(\"filename.txt\", \"w\")):\n    print \"Hello world\"\n<\/code><\/pre>\n\n<p>A nice aspect of it is that it can be applied selectively around just a portion of a script's execution, rather than its entire extent, and stays in effect even when unhandled exceptions are raised within its context. If you re-open the file in append-mode after its first use, you can accumulate the results into a single file:<\/p>\n\n<pre><code>with stdout_redirected(open(\"filename.txt\", \"w\")):\n    print \"Hello world\"\n\nprint \"screen only output again\"\n\nwith stdout_redirected(open(\"filename.txt\", \"a\")):\n    print \"Hello world2\"\n<\/code><\/pre>\n\n<p>Of course, the above be also be extended to also redirect <code>sys.stderr<\/code> to the same or another file. Also see this <a href=\"http:\/\/stackoverflow.com\/a\/16571630\/355230\">answer<\/a> to a related question.<\/p>\n",
                "<p>If you are talking about the python interpreter or CMD.exe that is the 'parent' of your script then no, it isn't possible. In every POSIX-like system (now you're running Windows, it seems, and that might have some quirk I don't know about, YMMV) each process has three streams, standard input, standard output and standard error. Bu default (when running in a console) these are directed to the console, but redirection is possible using the pipe notation:<\/p>\n\n<pre><code>python script_a.py | python script_b.py\n<\/code><\/pre>\n\n<p>This ties the standard output stream of script a to the standard input stream of script B. Standard error still goes to the console in this example. See the article on <a href=\"http:\/\/en.wikipedia.org\/wiki\/Standard_streams\" rel=\"nofollow\">standard streams<\/a> on Wikipedia.<\/p>\n\n<p>If you're talking about a child process, you can launch it from python like so (stdin is also an option if you want two way communication):<\/p>\n\n<pre><code>import subprocess\n# Of course you can open things other than python here :)\nprocess = subprocess.Popen([\"python\", \"main.py\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\nx = process.stderr.readline()\ny = process.stdout.readline()\nprocess.wait()\n<\/code><\/pre>\n\n<p>See the Python <a href=\"http:\/\/docs.python.org\/lib\/module-subprocess.html\" rel=\"nofollow\">subprocess<\/a> module for information on managing the process. For communication, the process.stdin and process.stdout pipes are considered standard <a href=\"http:\/\/docs.python.org\/lib\/bltin-file-objects.html\" rel=\"nofollow\">file objects<\/a>.<\/p>\n\n<p>For use with pipes, reading from standard input as <a href=\"http:\/\/stackoverflow.com\/questions\/24931\/how-to-capture-python-interpreters-andor-cmdexes-output-from-a-python-script#24939\" rel=\"nofollow\">lassevk<\/a> suggested you'd do something like this:<\/p>\n\n<pre><code>import sys\nx = sys.stderr.readline()\ny = sys.stdin.readline()\n<\/code><\/pre>\n\n<p>sys.stdin and sys.stdout are standard file objects as noted above, defined in the <a href=\"http:\/\/docs.python.org\/lib\/module-sys.html\" rel=\"nofollow\">sys<\/a> module. You might also want to take a look at the <a href=\"http:\/\/docs.python.org\/lib\/module-pipes.html\" rel=\"nofollow\">pipes<\/a> module.<\/p>\n\n<p>Reading data with readline() as in my example is a pretty na+Â»ve way of getting data though. If the output is not line-oriented or indeterministic you probably want to look into <a href=\"http:\/\/docs.python.org\/lib\/poll-objects.html\" rel=\"nofollow\">polling<\/a> which unfortunately does not work in windows, but I'm sure there's some alternative out there.<\/p>\n"
            ]
        },
        {
            "tag": "questao_25116",
            "padroes": [
                "In Python you can use StringIO for a file-like buffer for character data. Memory-mapped file basically does similar thing for binary data, but it requires a file that is used as the basis. Does Python have a file object that is intended for binary data and is memory only, equivalent to Java's ByteArrayOutputStream?\n\nThe use-case I have is I want to create a ZIP file in memory, and ZipFile requires a file-like object.\n"
            ],
            "respostas": [
                "<p>Look at the struct package: <a href=\"https:\/\/docs.python.org\/library\/struct.html\" rel=\"nofollow\">https:\/\/docs.python.org\/library\/struct.html<\/a>, it allows you to interpret strings as packed binary data.<\/p>\n\n<p>Not sure if this will completely answer your question but you can use struct.unpack() to convert binary data to python objects.<\/p>\n\n<pre>\n<code>\nimport struct\nf = open(filename, \"rb\")\ns = f.read(8)\nx, y = struct.unpack(\">hl\", s)\n<\/code>\n<\/pre>\n\n<p>int this example, the \">\" tells to read big-endian the \"h\" reads a 2-byte short, and the \"l\" is for a 4-byte long. you can obviously change these to whatever you need to read out of the binary data...<\/p>\n",
                "<p>As long as you don't try to put any unicode data into your <code>StringIO<\/code> and you are careful NOT to use <code>cStringIO<\/code> you should be fine.<\/p>\n\n<p>According to the <a href=\"https:\/\/docs.python.org\/library\/stringio.html\" rel=\"nofollow\">StringIO<\/a> documentation, as long as you keep to either unicode or 8-bits everything works as expected. Presumably, <code>StringIO<\/code> does something special when someone does a <code>f.write(u\"asdf\")<\/code> (which ZipFile does not do, to my knowledge). Anyway;<\/p>\n\n<pre><code>import zipfile\nimport StringIO\n\ns = StringIO.StringIO()\nz = zipfile.ZipFile(s, \"w\")\nz.write(\"test.txt\")\nz.close()\nf = file(\"x.zip\", \"w\")\nf.write(s.getvalue())\ns.close()\nf.close()\n<\/code><\/pre>\n\n<p>works just as expected, and there's no difference between the file in the resulting archive and the original file.<\/p>\n\n<p>If you know of a particular case where this approach does not work, I'd be most interested to hear about it :)<\/p>\n",
                "<p>You are probably looking for <a href=\"http:\/\/docs.python.org\/release\/3.1.3\/library\/io.html#binary-i-o\">io.BytesIO<\/a> class. It works exactly like StringIO except that it supports binary data:<\/p>\n\n<pre><code>from io import BytesIO\nbio = BytesIO(b\"some initial binary data: \\x00\\x01\")\n<\/code><\/pre>\n\n<p>StringIO will throw TypeError:<\/p>\n\n<pre><code>from io import StringIO\nsio = StringIO(b\"some initial binary data: \\x00\\x01\")\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_25661",
            "padroes": [
                "What is the best way to use PyGame (SDL) within a PyGTK application?\n\nI'm searching for a method that allows me to have a drawing area in the GTK window and at the same time being able to manage both GTK and SDL events.\n"
            ],
            "respostas": [
                "<p>I tried doing this myself a while ago, and I never got it to work perfectly. Actually I never got it to work at all under Windows, as it kept crashing the entire OS and I ran out of patience. I continued to use it though as it was only important it ran on Linux, and was only a small project. I'd strongly recommend you investigate alternatives. It always felt like a nasty hack, and made me feel dirty.<\/p>\n",
                "<p>There's a simple solution that might work for you.  <\/p>\n\n<p>Write the PyGTK stuff and PyGame stuff as separate applications.  Then from the PyGTK application call the PyGame application, using os.system to call the PyGame application.  If you need to share data between the two then either use a database, pipes or IPC.<\/p>\n",
                "<p>The Sugar project has several Activities built with PyGTK and PyGame.<\/p>\n\n<p>They wrote a support lib to achieve this, called <a href=\"http:\/\/wiki.sugarlabs.org\/go\/Development_Team\/Sugargame\" rel=\"nofollow\">Sugargame<\/a>. You should be able to modify it for regular PyGTK apps instead of Sugar.<\/p>\n\n<p>Here's a <a href=\"http:\/\/georgejhunt.com\/olpc\/pydebug\/ActivityBook\/ActivitiesGuideSugar__ActivitiesUsingPyGame.html\" rel=\"nofollow\">chapter in Sugar's development book<\/a> about how to use it.<\/p>\n\n<p>The lib allows for communicating events between GTK and PyGame.<\/p>\n\n<p>Enjoy!<\/p>\n",
                "<p>PyGame works much better when it can manage its own window, or even better, use the whole screen. GTK has flexible enough widgets to allow creation of a drawing area. <\/p>\n\n<p><a href=\"http:\/\/faq.pygtk.org\/index.py?req=show&amp;file=faq23.042.htp\" rel=\"nofollow\">This page<\/a> may help, though, if you want to try it.<\/p>\n",
                "<p><a href=\"http:\/\/faq.pygtk.org\/index.py?file=faq23.042.htp&amp;req=show\" rel=\"nofollow\">http:\/\/faq.pygtk.org\/index.py?file=faq23.042.htp&amp;req=show<\/a> mentions it all:<\/p>\n\n<p>You need to create a drawing area and set the environment variable SDL_WINDOWID after it's realized:<\/p>\n\n<pre>\n import os\n\n import gobject\n import gtk\n import pygame\n\n WINX = 400\n WINY = 200\n\n window = gtk.Window()\n window.connect('delete-event', gtk.main_quit)\n window.set_resizable(False)\n area = gtk.DrawingArea()\n area.set_app_paintable(True)\n area.set_size_request(WINX, WINY)\n window.add(area)\n area.realize()\n\n # Force SDL to write on our drawing area\n os.putenv('SDL_WINDOWID', str(area.window.xid))\n\n # We need to flush the XLib event loop otherwise we can't\n # access the XWindow which set_mode() requires\n gtk.gdk.flush()\n\n pygame.init()\n pygame.display.set_mode((WINX, WINY), 0, 0)\n screen = pygame.display.get_surface()\n\n image_surface = pygame.image.load('foo.png')\n screen.blit(image_surface, (0, 0))\n\n gobject.idle_add(pygame.display.update)\n\n window.show_all()\n\n while gtk.event_pending():\n     # pygame\/SDL event processing goes here\n     gtk.main_iteration(False)\n<\/pre>\n",
                "<p>You may be interested in <a href=\"http:\/\/www.daa.com.au\/pipermail\/pygtk\/2006-September\/012888.html\" rel=\"nofollow\">this message thread<\/a>.  Looks like they recommend against it.<\/p>\n",
                "<p>I've never attempted it myself, but hearing plenty about other people who've tried, it's not a road you want to go down.<\/p>\n\n<p>There is the alternative of putting the gui in pygame itself. There are plenty of gui toolkits built specifically for pygame that you could use. Most of them are rather unfinished, but there are 2 big, actively maintained ones: <a href=\"http:\/\/www.pygame.org\/project\/108\/\" rel=\"nofollow\">PGU<\/a> and <a href=\"http:\/\/www.pygame.org\/project\/125\/\" rel=\"nofollow\">OcempGUI<\/a>. The full list on the pygame site is <a href=\"http:\/\/www.pygame.org\/tags\/gui\" rel=\"nofollow\">here<\/a>.<\/p>\n"
            ]
        },
        {
            "tag": "questao_25807",
            "padroes": [
                "If I have Python code\n\nclass A():\n    pass\nclass B():\n    pass\nclass C(A, B):\n    pass\n\n\nand I have class C, is there a way to iterate through it's super classed (A and B)? Something like pseudocode:\n\n>>> magicGetSuperClasses(C)\n(, )\n\n\nOne solution seems to be inspect module and getclasstree function.\n\ndef magicGetSuperClasses(cls):\n    return [o[0] for o in inspect.getclasstree([cls]) if type(o[0]) == type]\n\n\nbut is this a \"Pythonian\" way to achieve the goal?\n"
            ],
            "respostas": [
                "<p>if you need to know to order in which super() would call the classes you can use <code>C.__mro__<\/code> and don't need <code>inspect<\/code> therefore.<\/p>\n",
                "<p>The inspect module was a good start, use the <a href=\"http:\/\/docs.python.org\/library\/inspect.html#inspect.getmro\" rel=\"nofollow\">getmro<\/a> function:<\/p>\n\n<blockquote>\n  <p>Return a tuple of class clsÃÃÃs base classes, including cls, in method resolution order. No class appears more than once in this tuple. ...<\/p>\n<\/blockquote>\n\n<pre><code>&gt;&gt;&gt; class A: pass\n&gt;&gt;&gt; class B: pass\n&gt;&gt;&gt; class C(A, B): pass\n&gt;&gt;&gt; import inspect\n&gt;&gt;&gt; inspect.getmro(C)[1:]\n(&lt;class __main__.A at 0x8c59f2c&gt;, &lt;class __main__.B at 0x8c59f5c&gt;)\n<\/code><\/pre>\n\n<p>The first element of the returned tuple is <code>C<\/code>, you can just disregard it.<\/p>\n",
                "<p>@John: Your snippet doesn't work -- you are returning the <em>class<\/em> of the base classes (which are also known as metaclasses). You really just want <code>cls.__bases__<\/code>:<\/p>\n\n<pre><code>class A: pass\nclass B: pass\nclass C(A, B): pass\n\nc = C() # Instance\n\nassert C.__bases__ == (A, B) # Works\nassert c.__class__.__bases__ == (A, B) # Works\n\ndef magicGetSuperClasses(clz):\n  return tuple([base.__class__ for base in clz.__bases__])\n\nassert magicGetSuperClasses(C) == (A, B) # Fails\n<\/code><\/pre>\n\n<p>Also, if you're using Python 2.4+ you can use <a href=\"http:\/\/www.python.org\/dev\/peps\/pep-0289\/\">generator expressions<\/a> instead of creating a list (via []), then turning it into a tuple (via <code>tuple<\/code>). For example:<\/p>\n\n<pre><code>def get_base_metaclasses(cls):\n    \"\"\"Returns the metaclass of all the base classes of cls.\"\"\"\n    return tuple(base.__class__ for base in clz.__bases__)\n<\/code><\/pre>\n\n<p>That's a somewhat confusing example, but genexps are generally easy and cool. :)<\/p>\n",
                "<p><code>C.__bases__<\/code> is an array of the super classes, so you could implement your hypothetical function like so:<\/p>\n\n<pre><code>def magicGetSuperClasses(cls):\n  return cls.__bases__\n<\/code><\/pre>\n\n<p>But I imagine it would be easier to just reference <code>cls.__bases__<\/code> directly in most cases.<\/p>\n"
            ]
        },
        {
            "tag": "questao_26595",
            "padroes": [
                "Is there any difference between:\n\nif foo is None: pass\n\n\nand\n\nif foo == None: pass\n\n\nThe convention that I've seen in most Python code (and the code I myself write) is the former, but I recently came across code which uses the latter.  None is an instance (and the only instance, IIRC) of NoneType, so it shouldn't matter, right?  Are there any circumstances in which it might?\n"
            ],
            "respostas": [
                "<p>Some more details:<\/p>\n\n<ol>\n<li><p>The <code>is<\/code> clause actually checks if the two <code>object<\/code>s are at the same\nmemory location or not. i.e whether they both point to the same\nmemory location and have the same <code>id<\/code>. <\/p><\/li>\n<li><p>As a  consequence of 1, <code>is<\/code> ensures whether, or not, the two lexically represented <code>object<\/code>s have identical attributes (attributes-of-attributes...) or not<\/p><\/li>\n<li><p>Instantiation of primitive types like <code>bool<\/code>, <code>int<\/code>, <code>string<\/code>(with some exception), <code>NoneType<\/code> having a same value will always be in the same memory location.<\/p><\/li>\n<\/ol>\n\n<p>E.g.<\/p>\n\n<pre><code>&gt;&gt;&gt; int(1) is int(1)\nTrue\n&gt;&gt;&gt; str(\"abcd\") is str(\"abcd\")\nTrue\n&gt;&gt;&gt; bool(1) is bool(2)\nTrue\n&gt;&gt;&gt; bool(0) is bool(0)\nTrue\n&gt;&gt;&gt; bool(0)\nFalse\n&gt;&gt;&gt; bool(1)\nTrue\n<\/code><\/pre>\n\n<p>And since <code>NoneType<\/code> can only have one instance of itself in the python's \"look-up\" table therefore the former and the latter are more of a programming style of the developer who wrote the code(maybe for consistency) rather then having any subtle logical reason to choose one over the other.<\/p>\n",
                "<p>John Machin's conclusion that <code>None<\/code> is a singleton is a conclusion bolstered by this code.<\/p>\n\n<pre><code>&gt;&gt;&gt; x = None\n&gt;&gt;&gt; y = None\n&gt;&gt;&gt; x == y\nTrue\n&gt;&gt;&gt; x is y\nTrue\n&gt;&gt;&gt; \n<\/code><\/pre>\n\n<p>Since <code>None<\/code> is a singleton, <code>x == None<\/code> and <code>x is None<\/code> would have the same result.  However, in my aesthetical opinion, <code>x == None<\/code> is best.<\/p>\n",
                "<p><code>is<\/code> tests for identity, <strong>not<\/strong> equality. For your statement <code>foo is none<\/code>, Python simply compares the memory address of objects. It means you are asking the question \"Do I have two names for the same object?\"<\/p>\n\n<p><code>==<\/code> on the other hand tests for equality as determined by the <code>__eq__()<\/code> method. It doesn't cares about identity.<\/p>\n\n<pre><code>In [102]: x, y, z = 2, 2, 2.0\n\nIn [103]: id(x), id(y), id(z)\nOut[103]: (38641984, 38641984, 48420880)\n\nIn [104]: x is y\nOut[104]: True\n\nIn [105]: x == y\nOut[105]: True\n\nIn [106]: x is z\nOut[106]: False\n\nIn [107]: x == z\nOut[107]: True\n<\/code><\/pre>\n\n<p><code>None<\/code> is a singleton operator. So <code>None is None<\/code> is always true.<\/p>\n\n<pre><code>In [101]: None is None\nOut[101]: True\n<\/code><\/pre>\n",
                "<p>For None there shouldn't be a difference between equality (==) and identity (is). The NoneType probably returns identity for equality. Since None is the only instance you can make of NoneType (I think this is true), the two operations are the same. In the case of other types this is not always the case. For example:<\/p>\n\n<pre><code>list1 = [1, 2, 3]\nlist2 = [1, 2, 3]\nif list1==list2: print \"Equal\"\nif list1 is list2: print \"Same\"\n<\/code><\/pre>\n\n<p>This would print \"Equal\" since lists have a comparison operation that is not the default returning of identity.<\/p>\n",
                "<p>@<a href=\"http:\/\/stackoverflow.com\/questions\/26595\/is-there-any-difference-between-foo-is-none-and-foo-none#26698\" rel=\"nofollow\">Jason<\/a>:<\/p>\n\n<blockquote>\n  <p>I recommend using something more along the lines of<\/p>\n\n<pre><code>if foo:\n    #foo isn't None\nelse:\n    #foo is None\n<\/code><\/pre>\n<\/blockquote>\n\n<p>I don't like using \"if foo:\" unless foo truly represents a boolean value (i.e. 0 or 1). If foo is a string or an object or something else, \"if foo:\" may work, but it looks like a lazy shortcut to me. If you're checking to see if x is None, say \"if x is None:\".<\/p>\n",
                "<p>There is no difference because objects which are identical will of course be equal. However, <a href=\"http:\/\/www.python.org\/dev\/peps\/pep-0008\/\" rel=\"nofollow\" title=\"PEP 8\">PEP 8<\/a> clearly states you should use <code>is<\/code>:<\/p>\n\n<blockquote>\n  <p>Comparisons to singletons like None should always be done with is or is not, never the equality operators.<\/p>\n<\/blockquote>\n",
                "<p>The reason <code>foo is None<\/code> is the preferred way is that you might be handling an object that defines its own <code>__eq__<\/code>, and that defines the object to be equal to None. So, always use <code>foo is None<\/code> if you need to see if it is infact <code>None<\/code>.<\/p>\n",
                "<p><code>(ob1 is ob2)<\/code> equal to <code>(id(ob1) == id(ob2))<\/code><\/p>\n",
                "<p>A word of caution: <\/p>\n\n<pre><code>if foo:\n  # do something\n<\/code><\/pre>\n\n<p>Is <strong>not<\/strong> exactly the same as:<\/p>\n\n<pre><code>if x is not None:\n  # do something\n<\/code><\/pre>\n\n<p>The former is a boolean value test and can evaluate to false in different contexts. There are a number of things that represent false in a boolean value tests for example empty containers, boolean values. None also evaluates to false in this situation but other things do too.<\/p>\n",
                "<p>You may want to read this <a href=\"http:\/\/mail.python.org\/pipermail\/python-list\/2001-November\/094920.html\">object identity and equivalence<\/a>.<\/p>\n\n<p>The statement 'is' is used for object identity, it checks if objects refer to the same instance (same address in memory).<\/p>\n\n<p>And the '==' statement refers to equality (same value).<\/p>\n",
                "<p><code>is<\/code> always returns <code>True<\/code> if it compares the same object instance<\/p>\n\n<p>Whereas <code>==<\/code> is ultimately determined by the <code>__eq__()<\/code> method<\/p>\n\n<p>i.e.<\/p>\n\n<pre><code>\n>>> class foo(object):\n       def __eq__(self, other):\n           return True\n\n>>> f = foo()\n>>> f == None\nTrue\n>>> f is None\nFalse\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_26706",
            "padroes": [
                "I'm a bit perplexed by drag and drop in wxPython (but perhaps this questions pertains to drag and drop in other GUI frameworks as well). The frameworks provides a couple of callbacks (OnEnter and OnDragOver) that purportedly allow me to inform the system whether the current mouse position is a valid place to drop whatever it is that is being dragged. From these methods I can return wx.DragNone, wx.DragCopy, etc. What baffles me is that from within these methods I am not allowed to call GetData, which means I am not allowed to examine the data that the user is dragging. If I cannot see the data, how am I supposed to know whether it is OK for the user to drop here?\n"
            ],
            "respostas": [
                "<p>One solution, which is a hack of limited usefulness, is when a drag is initiated, store the dragged data in a global or static reference somewhere. This way, in the OnEnter and OnDragOver handlers, it is possible to get a reference to the data being dragged. This is of course only useful for drags within the same application (the same instance of the application, actually).<\/p>\n",
                "<p>There is no way to see dragged data in <code>OnEnter<\/code> and <code>OnDragOver<\/code> methods.<\/p>\n\n<p>The only solution I found is to store the dragged item in some instance variable that is then readable inside these methods.<\/p>\n"
            ]
        },
        {
            "tag": "questao_27567",
            "padroes": [
                "I've been having a hard time trying to understand PyPy's translation.  It looks like something absolutely revolutionary from simply reading the description, however I'm hard-pressed to find good documentation on actually translating a real world piece of code to something such as LLVM.  Does such a thing exist?  The official PyPy documentation on it just skims over the functionality, rather than providing anything I can try out myself.\n"
            ],
            "respostas": [
                "<blockquote>\n  <p>It looks like something absolutely revolutionary from simply reading the description,<\/p>\n<\/blockquote>\n\n<p>As far as I know, PyPy is novel in the sense that it is the first system expressly designed for <em>implementing<\/em> languages.  Other tools exist to help with much of the very front end, such as parser generators, or for the very back end, such as code generation, but not much existed for connecting the two.<\/p>\n",
                "<p>Are you looking for Python specific translation, or just the general \"how do you compile some code to bytecode\"? If the latter is your case, check <a href=\"http:\/\/llvm.org\/docs\/tutorial\/\" rel=\"nofollow\">the LLVM tutorial<\/a>. I especially find chapter two, which teaches you to write a compiler for your own language, interesting.<\/p>\n",
                "<p>If you want some hand-on examples, <a href=\"http:\/\/codespeak.net\/pypy\/dist\/pypy\/doc\/getting-started.html\" rel=\"nofollow\">PyPy's Getting Started<\/a> document has a section titled \"Trying out the translator\".<\/p>\n",
                "<p>PyPy translator is in general, not intended for more public use. We use it for translating\nour own python interpreter (including JIT and GCs, both written in RPython, this restricted\nsubset of Python). The idea is that with good JIT and GC, you'll be able to speedups even\nwithout knowing or using PyPy's translation toolchain (and more importantly, without\nrestricting yourself to RPython).<\/p>\n\n<p>Cheers,\nfijal<\/p>\n",
                "<p>This document seems to go into quite a bit of detail (and I think a complete description is out of scope for a stackoverflow answer):<\/p>\n\n<ul>\n<li><a href=\"http:\/\/codespeak.net\/pypy\/dist\/pypy\/doc\/translation.html\" rel=\"nofollow\">http:\/\/codespeak.net\/pypy\/dist\/pypy\/doc\/translation.html<\/a><\/li>\n<\/ul>\n\n<p>The general idea of translating from one language to another isn't particularly revolutionary, but it has only recently been gaining popularity \/ applicability in \"real-world\" applications.  <a href=\"http:\/\/code.google.com\/webtoolkit\/\" rel=\"nofollow\">GWT<\/a> does this with Java (generating Javascript) and there is a library for translating Haskell into various other languages as well (called <a href=\"http:\/\/www.haskell.org\/haskellwiki\/Yhc\" rel=\"nofollow\">YHC<\/a>)<\/p>\n"
            ]
        },
        {
            "tag": "questao_28165",
            "padroes": [
                "Python has this wonderful way of handling string substitutions using dictionaries:\n\n>>> 'The %(site)s site %(adj)s because it %(adj)s' % {'site':'Stackoverflow', 'adj':'rocks'\n'The Stackoverflow site rocks because it rocks'\n\n\nI love this because you can specify a value once in the dictionary and then replace it all over the place in the string.\n\nI've tried to achieve something similar in PHP using various string replace functions but everything I've come up with feels awkward.\n\nDoes anybody have a nice clean way to do this kind of string substitution in PHP?\n\nEditHere's the code from the sprintf page that I liked best.  \n\n $v)\n    {\n        $tmp[$char . $k . $char] = $v;\n    \n    return str_replace(array_keys($tmp), array_values($tmp), $str);\n\n\necho sprintf3( 'The %site% site %adj% because it %adj%', array('site'=>'Stackoverflow', 'adj'=>'rocks'));\n?>\n\n"
            ],
            "respostas": [
                "<p>Some of the user-contributed notes and functions in <a href=\"http:\/\/us3.php.net\/sprintf\" rel=\"nofollow\">PHP's documentation for sprintf<\/a> come quite close.<\/p>\n\n<p>Note: search the page for \"sprintf2\".<\/p>\n",
                "<p>@<a href=\"http:\/\/stackoverflow.com\/questions\/28165\/does-php-have-an-equivalent-to-this-type-of-python-string-substitution#28199\" rel=\"nofollow\">Marius<\/a><\/p>\n\n<p>I don't know if it's faster, but you can do it without regexes:<\/p>\n\n<pre><code>function subst($str, $dict)\n{\n  foreach ($dict AS $key, $value)\n  {\n    $str = str_replace($key, $value, $str);\n  \n\n  return $str;\n\n<\/code><\/pre>\n",
                "<pre><code>function subst($str, $dict){\n    return preg_replace(array_map(create_function('$a', 'return \"\/%\\\\($a\\\\)s\/\";'), array_keys($dict)), array_values($dict), $str);\n \n<\/code><\/pre>\n\n<p>You call it like so:<\/p>\n\n<pre><code>echo subst('The %(site)s site %(adj)s because it %(adj)s', array('site'=&gt;'Stackoverflow', 'adj'=&gt;'rocks'));\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_28369",
            "padroes": [
                "I'm looking for a \"safe\" eval function, to implement spreadsheet-like calculations (using numpy\/scipy).\n\nThe functionality to do this (the rexec module) has been removed from Python since 2.3 due to apparently unfixable security problems. There are several third-party hacks out there that purport to do this - the most thought-out solution that I have found is \nthis Python Cookbok recipe, \"safe_eval\". \n\nAm I reasonably safe if I use this (or something similar), to protect from malicious code, or am I stuck with writing my own parser? Does anyone know of any better alternatives?\n\nEDIT: I just discovered RestrictedPython, which is part of Zope. Any opinions on this are  welcome.\n"
            ],
            "respostas": [
                "<p>Daniel,\n<a href=\"http:\/\/jinja.pocoo.org\/2\/documentation\/intro\" rel=\"nofollow\">Jinja<\/a> implements a sandboxe environment that may or may not be useful to you. From what I remember, it doesn't yet \"comprehend\" list comprehensions. <\/p>\n\n<p><a href=\"http:\/\/jinja.pocoo.org\/2\/documentation\/sandbox\" rel=\"nofollow\">Sanbox info<\/a> <\/p>\n",
                "<p>The functionality you want is in the compiler language services, see\n<a href=\"http:\/\/docs.python.org\/library\/language.html\" rel=\"nofollow\">http:\/\/docs.python.org\/library\/language.html<\/a>\nIf you define your app to accept only expressions, you can compile the input as an expression and get an exception if it is not, e.g. if there are semicolons or statement forms.<\/p>\n",
                "<p>Depends on your definition of safe I suppose. A lot of the security depends on what you pass in and what you are allowed to pass in the context. For instance, if a file is passed in, I can open arbitrary files:<\/p>\n\n<pre><code>&gt;&gt;&gt; names['f'] = open('foo', 'w+')\n&gt;&gt;&gt; safe_eval.safe_eval(\"baz = type(f)('baz', 'w+')\", names)\n&gt;&gt;&gt; names['baz']\n&lt;open file 'baz', mode 'w+' at 0x413da0&gt;\n<\/code><\/pre>\n\n<p>Furthermore, the environment is very restricted (you cannot pass in modules), thus, you can't simply pass in a module of utility functions like re or random.<\/p>\n\n<p>On the other hand, you don't need to write your own parser, you could just write your own evaluator for the python ast:<\/p>\n\n<pre><code>&gt;&gt;&gt; import compiler\n&gt;&gt;&gt; ast = compiler.parse(\"print 'Hello world!'\")\n<\/code><\/pre>\n\n<p>That way, hopefully, you could implement safe imports. The other idea is to use Jython or IronPython and take advantage of Java\/.Net sandboxing capabilities.<\/p>\n",
                "<p>If you simply need to write down and read some data structure in Python, and don't need the actual capacity of executing custom code, this one is a better fit:\n<a href=\"http:\/\/code.activestate.com\/recipes\/364469-safe-eval\/\" rel=\"nofollow\">http:\/\/code.activestate.com\/recipes\/364469-safe-eval\/<\/a><\/p>\n\n<p>It garantees that no code is executed, only static data structures are evaluated: strings, lists, tuples, dictionnaries.<\/p>\n",
                "<p>Although that code looks quite secure, I've always held the opinion that any sufficiently motivated person could break it given adequate time. I do think it will take quite a bit of determination to get through that, but I'm relatively sure it could be done.<\/p>\n",
                "<p>Writing your own parser could be fun!  It might be a better option because people are expecting to use the familiar spreadsheet syntax (Excel, etc) and not Python when they're entering formulas.  I'm not familiar with safe_eval but I would imagine that anything like this certainly has the potential for exploitation.<\/p>\n"
            ]
        },
        {
            "tag": "questao_28559",
            "padroes": [
                "What's the best Python idiom for this C construct?\n\nwhile ((x = next()) != END) {\n    ....\n\n\n\nI don't have the ability to recode next().\n\nupdate:  and the answer from seems to be:\n\nfor x in iter(next, END):\n    ....\n\n"
            ],
            "respostas": [
                "<p>What are you trying to do here?\nIf you're iterating over a list, you can use <code>for e in L<\/code> where e is the element and L is the list. If you're filtering a list, you can use list comprehensions (i.e. <code>[ e for e in L if e % 2 == 0 ]<\/code> to get all the even numbers in a list).<\/p>\n",
                "<p>If you need to do this more than once, the pythonic way would use an iterator<\/p>\n\n<pre><code>for x in iternext():\n    do_something_with_x\n<\/code><\/pre>\n\n<p>where <code>iternext<\/code> would be defined using something like\n(<a href=\"http:\/\/www.python.org\/dev\/peps\/pep-0020\/\" rel=\"nofollow\">explicit is better than implicit!<\/a>):<\/p>\n\n<pre><code>def iternext():\n    x = next()\n    while x != END:\n        yield x\n        x = next()\n<\/code><\/pre>\n",
                "<p>Can you provide more information about what you're trying to accomplish?  It's not clear to me why you can't just say<\/p>\n\n<pre><code>for x in everything():\n    ...\n<\/code><\/pre>\n\n<p>and have the everything function return everything, instead of writing a next function to just return one thing at a time.  Generators can even do this quite efficiently.<\/p>\n",
                "<p>Maybe it's not terribly idiomatic, but I'd be inclined to go with<\/p>\n\n<pre><code>x = next()\nwhile x != END:\n    do_something_with_x\n    x = next()\n<\/code><\/pre>\n\n<p>... but that's because I find that sort of thing easy to read<\/p>\n",
                "<p>Short answer: there's no way to do inline variable assignment in a while loop in Python. Meaning that I <strong>cannot<\/strong> say:<\/p>\n\n<pre><code>while x=next():\n    \/\/ do something here!\n<\/code><\/pre>\n\n<p>Since that's not possible, there are a number of \"idiomatically correct\" ways of doing this:<\/p>\n\n<pre><code>while 1:\n    x = next()\n    if x != END:\n        \/\/ Blah\n    else:\n        break\n<\/code><\/pre>\n\n<p>Obviously, this is kind of ugly. You can also use one of the \"iterator\" approaches listed above, but, again, that may not be ideal. Finally, you can use the \"pita pocket\" approach that I actually just found while googling:<\/p>\n\n<pre><code>class Pita( object ):\n    __slots__ = ('pocket',)\n    marker = object()\n    def __init__(self, v=marker):\n        if v is not self.marker:\n            self.pocket = v\n    def __call__(self, v=marker):\n        if v is not self.marker:\n            self.pocket = v\n        return self.pocket\n<\/code><\/pre>\n\n<p>Now you can do:<\/p>\n\n<pre><code>p = Pita()\nwhile p( next() ) != END:\n    \/\/ do stuff with p.pocket!\n<\/code><\/pre>\n\n<p>Thanks for this question; learning about the <code>__call__<\/code> idiom was really cool! :)<\/p>\n\n<p>EDIT: I'd like to give credit where credit is due. The 'pita pocket' idiom was found <a href=\"http:\/\/mail.python.org\/pipermail\/python-list\/2003-July\/216789.html\" rel=\"nofollow\">here<\/a><\/p>\n",
                "<p>It depends a bit what you want to do. To match your example as far as possible, I would make next a generator and iterate over it:<\/p>\n\n<pre><code>def next():\n   for num in range(10):\n      yield num\n\nfor x in next():\n   print x\n<\/code><\/pre>\n",
                "<p>@Mark Harrison's answer:<\/p>\n\n<pre><code>for x in iter(next_, END):\n    ....\n<\/code><\/pre>\n\n<p>Here's an excerpt from <a href=\"http:\/\/docs.python.org\/library\/functions.html\">Python's documentation<\/a>:<\/p>\n\n<pre><code>iter(o[, sentinel])\n<\/code><\/pre>\n\n<blockquote>\n  <p>Return an iterator object.\n  <em>...(snip)...<\/em> If the second argument, <code>sentinel<\/code>, is given, then <code>o<\/code> must be\n  a callable object. The iterator\n  created in this case will call <code>o<\/code>\n  with no arguments for each call to its\n  <code>next()<\/code> method; if the value returned\n  is equal to <code>sentinel<\/code>,\n  <code>StopIteration<\/code> will be raised,\n  otherwise the value will be returned.<\/p>\n<\/blockquote>\n"
            ]
        },
        {
            "tag": "questao_28668",
            "padroes": [
                "My job would be easier, or at least less tedious if I could come up with an automated way (preferably in a Python script) to extract useful information from a FileMaker Pro database. I am working on Linux machine and the FileMaker database is on the same LAN running on an OS X machine. I can log into the webby interface from my machine.\n\nI'm quite handy with SQL, and if somebody could point me to some FileMaker plug-in that could give me SQL access to the data within FileMaker, I would be pleased as punch. Everything I've found only goes the other way: Having FileMaker get data from SQL sources. Not useful.\n\nIt's not my first choice, but I'd use Perl instead of Python if there was a Perl-y solution at hand.\n\nNote: XML\/XSLT services (as suggested by some folks) are only available on FM Server, not FM Pro. Otherwise, that would probably be the best solution. ODBC is turning out to be extremely difficult to even get working. There is absolutely zero feedback from FM when you set it up so you have to dig through \/var\/log\/system.log and parse obscure error messages.\n\nConclusion: I got it working by running a python script locally on the machine that queries the FM database through the ODBC connections. The script is actually a TCPServer that accepts socket connections from other systems on the LAN, runs the queries, and returns the data through the socket connection. I had to do this to bypass the fact that FM Pro only accepts ODBC connections locally (FM server is required for external connections).\n"
            ],
            "respostas": [
                "<p>If your leaning is to Python, you may be interested in checking out the Python Wrapper for Filemaker.   It provides two way access to the Filemaker data via Filemaker's built-in XML services.   You can find some quite thorough information on this at:<\/p>\n\n<p><a href=\"http:\/\/code.google.com\/p\/pyfilemaker\/\" rel=\"nofollow\">http:\/\/code.google.com\/p\/pyfilemaker\/<\/a><\/p>\n",
                "<p>You'll need the FileMaker Pro installation CD to get the drivers. <a href=\"http:\/\/www.filemaker.com\/downloads\/pdf\/fm9_odbc_jdbc_guide_en.pdf\" rel=\"nofollow\">This document<\/a> details the process for FMP 9 - it is similar for versions 7.x and 8.x as well. Versions 6.x and earlier are completely different and I wouldn't bother trying (xDBC support in those previous versions is \"minimal\" at best).<\/p>\n\n<p>FMP 9 supports SQL-92 standard syntax (mostly). Note that rather than querying tables directly you query using the \"table occurrence\" name which serves as a table alias of sorts. If the data tables are stored in multiple files it is possible to create a single FMP file with table occurrences\/aliases pointing to those data tables. There's an \"undocumented feature\" where such a file must have a table defined in it as well and that table \"related\" to any other table on the relationships graph (doesn't matter which one) for ODBC access to work. Otherwise your queries will always return no results.<\/p>\n\n<p>The PDF document details all of the limitations of using the xDBC interface FMP provides. Performance of simple queries is reasonably fast, ymmv. I have found the performance of queries specifying the \"LIKE\" operator to be less than stellar.<\/p>\n\n<p>FMP also has an XML\/XSLT interface that you can use to query FMP data over an HTTP connection. It also provides a PHP class for accessing and using FMP data in web applications.<\/p>\n",
                "<p>It has been a <strong>really<\/strong> long time since I did anything with FileMaker Pro, but I know that it does have capabilities for an ODBC (and JDBC) connection to be made to it (however, I don't know how, or if, that translates to the linux\/perl\/python world though).  <\/p>\n\n<p>This article shows how to share\/expose your FileMaker data via ODBC &amp; JDBC:<br \/>\n<a href=\"http:\/\/www.filemaker.com\/help\/15-Using%20ODBC2.html\">Sharing FileMaker Pro data via ODBC or JDBC<\/a>   <\/p>\n\n<p>From there, if you're able to create an ODBC\/JDBC connection you could query out data as needed.<\/p>\n"
            ]
        },
        {
            "tag": "questao_29243",
            "padroes": [
                "Here is my sample code:\n\nfrom xml.dom.minidom import *\ndef make_xml():\n    doc = Document()\n    node = doc.createElement('foo')\n    node.innerText = 'bar'\n    doc.appendChild(node)\n    return doc\nif __name__ == '__main__':\n    make_xml().writexml(sys.stdout)\n\n\nwhen I run the above code I get this:\n\n\n\n\n\nI would like to get:\n\n\nbar\n\n\nI just guessed that there was an innerText property, it gives no compiler error, but does not seem to work... how do I go about creating a text node?\n"
            ],
            "respostas": [
                "<p>I found a <a href=\"http:\/\/www.boddie.org.uk\/python\/XML_intro.html\" rel=\"nofollow\">pretty verbose tutorial on the minidom method<\/a><\/p>\n\n<p>Here's a <a href=\"http:\/\/drfox.com\/cgi-bin\/topic_display.py?name=climbing_etree\" rel=\"nofollow\">tutorial for the etree method<\/a>. It's much nicer to read, and seems quite simple. It also goes over parsing of xml (briefly)<\/p>\n",
                "<p>Setting an attribute on an object won't give a compile-time or a run-time error, it will just do nothing useful if the object doesn't access it (i.e. \"<code>node.noSuchAttr = 'bar'<\/code>\" would also not give an error).<\/p>\n\n<p>Unless you need a specific feature of <code>minidom<\/code>, I would look at <code>ElementTree<\/code>:<\/p>\n\n<pre><code>import sys\nfrom xml.etree.cElementTree import Element, ElementTree\n\ndef make_xml():\n    node = Element('foo')\n    node.text = 'bar'\n    doc = ElementTree(node)\n    return doc\n\nif __name__ == '__main__':\n    make_xml().write(sys.stdout)\n<\/code><\/pre>\n",
                "<p>@Daniel<\/p>\n\n<p>Thanks for the reply, I also figured out how to do it with the minidom (I'm not sure of the difference between the ElementTree vs the minidom)<\/p>\n\n<pre>\n<code>\nfrom xml.dom.minidom import *\ndef make_xml():\n    doc = Document();\n    node = doc.createElement('foo')\n    node.appendChild(doc.createTextNode('bar'))\n    doc.appendChild(node)\n    return doc\nif __name__ == '__main__':\n    make_xml().writexml(sys.stdout)\n<\/code>\n<\/pre>\n\n<p>I swear I tried this before posting my question...<\/p>\n"
            ]
        },
        {
            "tag": "questao_28796",
            "padroes": [
                "I have a bunch of classes I want to rename.  Some of them have names that are small and that name is reused in other class names, where I don't want that name changed.  Most of this lives in Python code, but we also have some XML code that references class names.\n\nSimple search and replace only gets me so far.  In my case, I want to rename AdminAction to AdminActionPlug and AdminActionLogger to AdminActionLoggerPlug, so the first one's search-and-replace would also hit the second, wrongly.\n\nDoes anyone have experience with Python refactoring tools ? Bonus points if they can fix class names in the XML documents too.\n"
            ],
            "respostas": [
                "<p>Most editors support the \"whole word\" search option. It's usually a checkbox in the search dialog, and what it does is only match the search term if it has leading and trailing spaces, dots, and most other delimiters.\nIt will probably work in your case.<\/p>\n",
                "<p>You can use sed to perform this. The trick is to recall that regular expressions can recognize word boundaries. This works on all platforms provided you get the tools, which on Windows is Cygwin, Mac OS may require installing the dev tools, I'm not sure, and Linux has this out of the box. So grep, xargs, and sed should do the trick, after 12 hours of reading man pages and trial and error ;)<\/p>\n",
                "<p><a href=\"http:\/\/www.jetbrains.com\/pycharm\/features\/\" rel=\"nofollow\">PyCharm<\/a> have some refactoring features.<\/p>\n\n<blockquote>\n  <h3>PYTHON REFACTORING<\/h3>\n  \n  <p><strong>Rename<\/strong> refactoring allows to perform global code changes safely and instantly. Local changes within a file are performed in-place. Refactorings work in plain Python and Django projects.<\/p>\n  \n  <p>Use <strong>Introduce Variable\/Field\/Constant<\/strong> and <strong>Inline Local<\/strong> for improving the code structure within a method, <strong>Extract Method<\/strong> to break up longer methods, <strong>Extract Superclass<\/strong>, <strong>Push Up<\/strong>, <strong>Pull Down<\/strong> and <strong>Move<\/strong> to move the methods and classes.<\/p>\n<\/blockquote>\n",
                "<p>Your IDE can support refactorings !!\nCheck it Eric, Eclipse, WingIDE have build in tools for refactorings (Rename including). And that are very safe refactorings - if something can go wrong IDE wont do ref.<\/p>\n\n<p>Also consider adding few unit test to ensure your code did not suffer during refactorings.<\/p>\n",
                "<p>WingIDE 4.0 (WingIDE is my python IDE of choice) will support a few refactorings, but I just tried out the latest beta, beta6, and... there's still work to be done.  Retract Method works nicely, but Rename Symbol does not.<\/p>\n\n<p>Update: The 4.0 release has fixed all of the refactoring tools.  They work great now.<\/p>\n",
                "<p>I would strongly recommend <a href=\"https:\/\/www.jetbrains.com\/pycharm\/\" rel=\"nofollow\">PyCharm<\/a> - not just for refactorings. Since the first PyCharm answer was posted here a few years ago the refactoring support in PyCharm has improved significantly.<\/p>\n\n<p><a href=\"https:\/\/www.jetbrains.com\/pycharm\/webhelp\/refactoring-source-code.html\" rel=\"nofollow\">Python Refactorings available in PyCharm<\/a> (last checked 2016\/07\/27 in PyCharm 2016.2)<\/p>\n\n<ul>\n<li>Change Signature<\/li>\n<li>Convert to Python Package\/Module<\/li>\n<li>Copy<\/li>\n<li>Extract Refactorings<\/li>\n<li>Inline<\/li>\n<li>Invert Boolean<\/li>\n<li>Make Top-Level Function<\/li>\n<li>Move Refactorings<\/li>\n<li>Push Members down<\/li>\n<li>Pull Members up<\/li>\n<li>Rename Refactorings<\/li>\n<li>Safe Delete<\/li>\n<\/ul>\n\n<p>XML refactorings (I checked in context menu in an XML file):<\/p>\n\n<ul>\n<li>Rename<\/li>\n<li>Move<\/li>\n<li>Copy<\/li>\n<li>Extract Subquery as CTE<\/li>\n<li>Inline<\/li>\n<\/ul>\n\n<p>Javascript refactorings:<\/p>\n\n<ul>\n<li>Extract Parameter in JavaScript<\/li>\n<li>Change Signature in JavaScript<\/li>\n<li>Extract Variable in JavaScript<\/li>\n<\/ul>\n",
                "<p>In the meantime, I've tried it two tools that have some sort of integration with vim.<\/p>\n\n<p>The first is <a href=\"http:\/\/rope.sourceforge.net\/\">Rope<\/a>, a python refactoring library that comes with a Vim (and emacs) plug-in.  I tried it for a few renames, and that definitely worked as expected.  It allowed me to preview the refactoring as a diff, which is nice.  It is a bit text-driven, but that's alright for me, just takes longer to learn.<\/p>\n\n<p>The second is <a href=\"http:\/\/bicyclerepair.sourceforge.net\/\">Bicycle Repair Man<\/a> which I guess wins points on name.  Also plugs into vim and emacs.  Haven't played much with it yet, but I remember trying it a long time ago.<\/p>\n\n<p>Haven't played with both enough yet, or tried more types of refactoring, but I will do some more hacking with them.<\/p>\n"
            ]
        },
        {
            "tag": "questao_29562",
            "padroes": [
                "I wrote a quick program in python to add a gtk GUI to a cli program. I was wondering how I can create an installer using distutils. Since it's just a GUI frontend for a command line app it only works in *nix anyway so I'm not worried about it being cross platform.\n\nmy main goal is to create a .deb package for debian\/ubuntu users, but I don't understand make\/configure files. I've primarily been a web developer up until now.\n\nThanks for your help!\n\nedit: Does anyone know of a project that uses distutils so I could see it in action and, you know, actually try building it?\n\nHere are a few useful links\n\n\n- Ubuntu Python Packaging Guide\n\nThis Guide is very helpful. I don't know how I missed it during my initial wave of gooling. It even walks you through packaging up an existing python application- The Ubuntu MOTU Project\n\nThis is the official package maintaining project at ubuntu. Anyone can join, and there are lots of tutorials and info about creating packages, of all types, which include the above 'python packaging guide'.- \"Python distutils to deb?\" - Ars Technica Forum discussion\n\nAccording to this conversation, you can't just use distutils. It doesn't follow the debian packaging format (or something like that). I guess that's why you need dh_make as seen in the Ubuntu Packaging guide- \"A bdist_deb command for distutils\n\nThis one has some interesting discussion (it's also how I found the ubuntu guide) about concatenating a zip-file and a shell script to create some kind of universal executable (anything with python and bash that is). weird. Let me know if anyone finds more info on this practice because I've never heard of it.- Description of the deb format and how distutils fit in - python mailing list\n"
            ],
            "respostas": [
                "<p>distutils really isn't all that difficult once you get the hang of it.  It's really just a matter of putting in some meta-information (program name, author, version, etc) and then selecting what files you want to include.  For example, here's a sample distutils setup.py module from a decently complex python library:<\/p>\n\n<p><a href=\"http:\/\/code.google.com\/p\/kamaelia\/source\/browse\/trunk\/Code\/Python\/Kamaelia\/setup.py\" rel=\"nofollow\">Kamaelia setup.py<\/a><\/p>\n\n<p>Note that this doesn't deal with any data files or or whatnot, so YMMV.<\/p>\n\n<p>On another note, I agree that the distutils documentation is probably some of python's worst documentation.  It is extremely inclusive in some areas, but neglects some really important information in others.<\/p>\n",
                "<p>I found the following <a href=\"http:\/\/wiki.python.org\/moin\/Distutils\/Tutorial\" rel=\"nofollow\">tutorial<\/a> to be very helpful. It's shorter than the distutils documentation and explains how to setup a typical project step by step. <\/p>\n",
                "<p>Most Python programs will use distutils. <a href=\"http:\/\/www.djangoproject.com\" rel=\"nofollow\">Django<\/a> is a one - see <a href=\"http:\/\/code.djangoproject.com\/svn\/django\/trunk\/setup.py\" rel=\"nofollow\">http:\/\/code.djangoproject.com\/svn\/django\/trunk\/setup.py<\/a><\/p>\n\n<p>You should also read <a href=\"http:\/\/docs.python.org\/dist\/dist.html\" rel=\"nofollow\">the documentation<\/a>, as it's very comprehensive and has some good examples.<\/p>\n",
                "<p><code>apt-get install python-stdeb<\/code><\/p>\n\n<p>Python to Debian source package conversion utility<\/p>\n\n<p>This package provides some tools to produce Debian packages from Python packages via a new distutils command, sdist_dsc. Automatic defaults are provided for the Debian package, but many aspects of the resulting package can be customized via a configuration file.<\/p>\n\n<ul>\n<li>pypi-install will query the Python Package Index (PyPI) for a\npackage, download it, create a .deb from it, and then install\nthe .deb.<\/li>\n<li>py2dsc will convert a distutils-built source tarball into a Debian\nsource package.<\/li>\n<\/ul>\n",
                "<p>See the <a href=\"http:\/\/docs.python.org\/dist\/simple-example.html\" rel=\"nofollow\">distutils simple example<\/a>. That's basically what it is like, except real install scripts usually contain a bit more information. I have not seen any that are fundamentally more complicated, though. In essence, you just give it a list of what needs to be installed. Sometimes you need to give it some mapping dicts since the source and installed trees might not be the same.<\/p>\n\n<p>Here is a real-life (anonymized) example:<\/p>\n\n<pre><code>#!\/usr\/bin\/python \n\nfrom distutils.core import setup \n\nsetup (name = 'Initech Package 3', \n          description = \"Services and libraries ABC, DEF\", \n          author = \"That Guy, Initech Ltd\", \n          author_email = \"that.guy@initech.com\", \n          version = '1.0.5', \n          package_dir = {'Package3' : 'site-packages\/Package3', \n          packages = ['Package3', 'Package3.Queries'], \n          data_files = [ \n                       ('\/etc\/Package3', ['etc\/Package3\/ExternalResources.conf']) \n          ])\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_29856",
            "padroes": [
                "The default Python install on OS X 10.5 is 2.5.1 with a fat 32 bit (Intel and PPC) client. I want to setup apache and mysql to run django. In the past I have run apache and mysql to match this install in 32 bit mode (even stripping out the 64 bit stuff from apache to make it work).\n\nI want to upgrade Python to 64 bit. I am completely comfortable with compiling it from source with one caveat. How to I match the way that the default install is laid out? Especially with regards to site-packages being in \/Library\/Python\/2.5\/ and not the one in buried at the top of the framework once I compile it. \n"
            ],
            "respostas": [
                "<p>Essentially, yes. I was not sure you could do it like that (current version does not do it like that). When using the python install script, however, there is no option (that I can find) to specify where to put directories and files (eg --prefix). I was hoping to match the current layout of python related files so as to avoid 'polluting' my machine with redundant files.<\/p>\n",
                "<p>The short answer is because I can. The long answer, expanding on what the OP said, is to be more compatible with apache and mysql\/postgresql. They are all 64bit (apache is a fat binary with ppc, ppc64 x86 and x86 and x86_64, the others just straight 64bit). <strong>Mysqldb and mod_python wont compile unless they are all running the  same architecture.<\/strong> Yes I could run them all in 32bit (and have in the past) but this is much more work then compiling one program.<\/p>\n\n<p>EDIT: You pretty much convinced though to just let the installer do its thing and update the PATH to reflect this.<\/p>\n",
                "<p>Hyposaurus,<\/p>\n\n<p>It is possible to have multiple versions of Python installed simultaneously. Installing two versions in parallel solves your problem and helps avoid the problems laid out by Jason Baker above. <\/p>\n\n<p>The easiest way, and the way I recommend, is to use <a href=\"http:\/\/www.macports.org\/\" rel=\"nofollow\">MacPorts<\/a>, which will install all its software separately. By default, for example, everything is installed in \/opt\/local<\/p>\n\n<p>Another method is to simply download the source and compile with a specified prefix. Note that this method doesn't modify your PATH environment variable, so you'll need to do that yourself if you want to avoid typing the fully qualified path to the python executable each time<\/p>\n\n<pre><code>.\/configure --prefix=\/usr\/local\/python64\nmake\nsudo make install\n<\/code><\/pre>\n\n<p>Then you can simply point your Apache install at the new version using mod_python's <a href=\"http:\/\/www.modpython.org\/live\/current\/doc-html\/dir-other-pi.html\" rel=\"nofollow\">PythonInterpreter<\/a> directive<\/p>\n",
                "<p>Personally, I wouldn't worry about it until you see a problem.  Messing with the default python install on a *Nix system can cause more trouble than it's worth.  I can say from personal experience that you never truly understand what python has done for the nix world until you have a problem with it.<\/p>\n\n<p>You can also add a second python installation, but that also causes more problems than it's worth IMO.<\/p>\n\n<p>So I suppose the best question to start out with would be why exactly do you want to use the 64 bit version of python?<\/p>\n",
                "<p>Not sure I entirely understand your question, but can't you simply build and install a 64 bit version and then create symbolic links so that \/Library\/Python\/2.5 and below point to your freshly built version of python?<\/p>\n"
            ]
        },
        {
            "tag": "questao_31340",
            "padroes": [
                "I've been trying to wrap my head around how threads work in Python, and it's hard to find good information on how they operate. I may just be missing a link or something, but it seems like the official documentation isn't very thorough on the subject, and I haven't been able to find a good write-up.\n\nFrom what I can tell, only one thread can be running at once, and the active thread switches every 10 instructions or so?\n\nWhere is there a good explanation, or can you provide one? It would also be very nice to be aware of common problems that you run into while using threads with Python.\n"
            ],
            "respostas": [
                "<p>Try to remember that the GIL is set to poll around every so often in order to do show the appearance of multiple tasks. This setting can be fine tuned, but I offer the suggestion that there should be work that the threads are doing or lots of context switches are going to cause problems.<\/p>\n\n<p>I would go so far as to suggest multiple parents on processors and try to keep like jobs on the same core(s).<\/p>\n",
                "<p>One easy solution to the GIL is the <a href=\"http:\/\/docs.python.org\/2\/library\/multiprocessing.html\" rel=\"nofollow\" title=\"Python docs link\">multiprocessing<\/a> module. It can be used as a drop in replacement to the threading module but uses multiple Interpreter processes instead of threads. Because of this there is a little more overhead than plain threading for simple things but it gives you the advantage of real parallelization if you need it.\nIt also easily scales to multiple physical machines.<\/p>\n\n<p>If you need truly large scale parallelization than I would look further but if you just want to scale to all the cores of one computer or a few different ones without all the work that would go into implementing a more comprehensive framework, than this is for you.<\/p>\n",
                "<p>Use threads in python if the individual workers are doing I\/O bound operations. If you are trying to scale across multiple cores on a machine either find a good <a href=\"http:\/\/www.python.org\/dev\/peps\/pep-0371\/\">IPC<\/a> framework for python or pick a different language.<\/p>\n",
                "<p>Below is a basic threading sample. It will spawn 20 threads; each thread will output its thread number. Run it and observe the order in which they print.<\/p>\n\n<pre><code>import threading\nclass Foo (threading.Thread):\n    def __init__(self,x):\n        self.__x = x\n        threading.Thread.__init__(self)\n    def run (self):\n          print str(self.__x)\n\nfor x in xrange(20):\n    Foo(x).start()\n<\/code><\/pre>\n\n<p>As you have hinted at Python threads are implemented through time-slicing. This is how they get the \"parallel\" effect. <\/p>\n\n<p>In my example my Foo class extends thread, I then implement the <code>run<\/code> method, which is where the code that you would like to run in a thread goes. To start the thread you call <code>start()<\/code> on the thread object, which will automatically invoke the <code>run<\/code> method...<\/p>\n\n<p>Of course, this is just the very basics. You will eventually want to learn about semaphores, mutexes, and locks for thread synchronization and message passing.<\/p>\n",
                "<p>Python's a fairly easy language to thread in, but there are caveats.  The biggest thing you need to know about is the Global Interpreter Lock.  This allows only one thread to access the interpreter.  This means two things:  1)  you rarely ever find yourself using a lock statement in python and 2) if you want to take advantage of multi-processor systems, you have to use separate processes.  EDIT:  I should also point out that you can put some of the code in C\/C++ if you want to get around the GIL as well.<\/p>\n\n<p>Thus, you need to re-consider why you want to use threads.  If you want to parallelize your app to take advantage of dual-core architecture, you need to consider breaking your app up into multiple processes.<\/p>\n\n<p>If you want to improve responsiveness, you should CONSIDER using threads.  There are other alternatives though, namely <a href=\"http:\/\/en.wikipedia.org\/wiki\/Microthread\" rel=\"nofollow\">microthreading<\/a>.  There are also some frameworks that you should look into:<\/p>\n\n<ul>\n<li><a href=\"http:\/\/www.stackless.com\/\" rel=\"nofollow\">stackless python<\/a><\/li>\n<li><a href=\"http:\/\/greenlet.readthedocs.org\/en\/latest\/\" rel=\"nofollow\">greenlets<\/a><\/li>\n<li><a href=\"http:\/\/www.gevent.org\/\" rel=\"nofollow\">gevent<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/saucelabs\/monocle\" rel=\"nofollow\">monocle<\/a><\/li>\n<\/ul>\n",
                "<p>Yes, because of the Global Interpreter Lock (GIL) there can only run one thread at a time. Here are some links with some insights about this:<\/p>\n\n<ul>\n<li><a href=\"http:\/\/www.artima.com\/weblogs\/viewpost.jsp?thread=214235\">http:\/\/www.artima.com\/weblogs\/viewpost.jsp?thread=214235<\/a><\/li>\n<li><a href=\"http:\/\/smoothspan.wordpress.com\/2007\/09\/14\/guido-is-right-to-leave-the-gil-in-python-not-for-multicore-but-for-utility-computing\/\">http:\/\/smoothspan.wordpress.com\/2007\/09\/14\/guido-is-right-to-leave-the-gil-in-python-not-for-multicore-but-for-utility-computing\/<\/a><\/li>\n<\/ul>\n\n<p>From the last link an interesting quote:<\/p>\n\n<blockquote>\n  <p>Let me explain what all that means. \n  Threads run inside the same virtual\n  machine, and hence run on the same\n  physical machine.  Processes can run\n  on the same physical machine or in\n  another physical machine.  If you\n  architect your application around\n  threads, youÃÃÃve done nothing to access\n  multiple machines.  So, you can scale\n  to as many cores are on the single\n  machine (which will be quite a few\n  over time), but to really reach web\n  scales, youÃÃÃll need to solve the\n  multiple machine problem anyway.<\/p>\n<\/blockquote>\n\n<p>If you want to use multi core, <a href=\"http:\/\/www.python.org\/dev\/peps\/pep-0371\/\">pyprocessing<\/a> defines an process based API to do real parallelization. The <a href=\"http:\/\/en.wikipedia.org\/wiki\/Python_Enhancement_Proposal#Development\">PEP<\/a> also includes some interesting benchmarks.<\/p>\n"
            ]
        },
        {
            "tag": "questao_28961",
            "padroes": [
                "I have a medium sized application that runs as a .net web-service which I do not control,\nand I want to create a loose pythonic API above it to enable easy scripting.\n\nI wanted to know what is the best\/most practical solution for using web-services in python.\n\nEdit:\nI need to consume a complex soap WS\nand I have no control over it.\n"
            ],
            "respostas": [
                "<p>Most of the packages on python that a SOAP service through them can be called works on python 2.x, but had problems on Python 3.x<\/p>\n\n<p>The best fit for python 3.x that I've found is <a href=\"https:\/\/pypi.python.org\/pypi\/suds-jurko\/0.6\" rel=\"nofollow\">suds-jurko<\/a><\/p>\n",
                "<p><a href=\"http:\/\/www.jython.org\" rel=\"nofollow\">Jython<\/a> and <a href=\"http:\/\/www.codeplex.com\/IronPython\" rel=\"nofollow\">IronPython<\/a> give access to great Java &amp; .NET SOAP libraries.<\/p>\n\n<p>If you need CPython, <a href=\"http:\/\/pywebsvcs.sourceforge.net\/\" rel=\"nofollow\">ZSI<\/a> has been flaky for me, but it could be possible to use a tool like <a href=\"http:\/\/robin.python-hosting.com\/\" rel=\"nofollow\">Robin<\/a> to wrap a good C++ SOAP library such as <a href=\"http:\/\/gsoap2.sourceforge.net\/\" rel=\"nofollow\">gSOAP<\/a> or <a href=\"http:\/\/ws.apache.org\/axis\/cpp\/index.html\" rel=\"nofollow\">Apache Axis C++<\/a><\/p>\n",
                "<p>If I have to expose APIs, I prefer doing it as JSON. Python has excellent support for JSON objects (JSON Objects are infact python dictionaries)<\/p>\n"
            ]
        },
        {
            "tag": "questao_32044",
            "padroes": [
                "I have a tree structure in memory that I would like to render in HTML using a Django template. \n\nclass Node():\n  name = \"node name\"\n  children = []\n\n\nThere will be some object root that is a Node, and children is a list of Nodes. root will be passed in the content of the template.\n\nI have found this one discussion of how this might be achieved, but the poster suggests this might not be good in a production environment.\n\nDoes anybody know of a better way?\n"
            ],
            "respostas": [
                "<p>I had a similar issue, however I had first implemented the solution using JavaScript, and just afterwards considered how I would have done the same thing in django templates.<\/p>\n\n<p>I used the serializer utility to turn a list off models into json, and used the json data as a basis for my hierarchy.<\/p>\n",
                "<p>Does no one like dicts ? I might be missing something here but it would seem the most natural way to setup menus. Using keys as entries and values as links pop it in a DIV\/NAV and away you go !<\/p>\n\n<p>From your base<\/p>\n\n<pre><code># Base.html\n&lt;nav&gt;\n{% with dict=contents template=\"treedict.html\" %\n {% include template %\n{% endwith %\n&lt;nav&gt;\n<\/code><\/pre>\n\n<p>call this<\/p>\n\n<pre><code># TreeDict.html\n&lt;ul&gt;\n{% for key,val in dict.items %\n {% if val.items %\n  &lt;li&gt;{{ key &lt;\/li&gt;\n  {%with dict=val template=\"treedict.html\" %\n   {%include template%\n  {%endwith%\n {% else % \n  &lt;li&gt;&lt;a href=\"{{ val \"&gt;{{ key &lt;\/a&gt;&lt;\/li&gt;\n {% endif %\n{% endfor % \n&lt;\/ul&gt;\n<\/code><\/pre>\n\n<p>It haven't tried the default or the ordered yet perhaps you have ?<\/p>\n",
                "<p>I'm too late)\nAll of you use so much unnecessary <strong><em>with<\/em><\/strong> tags, this is how i do recuesive:<\/p>\n\n<p>in main template:<\/p>\n\n<pre><code>&lt;!-- lets say that menu_list is already defined --&gt;\n&lt;ul&gt;\n    {% include \"menu.html\" %\n&lt;\/ul&gt;\n<\/code><\/pre>\n\n<p>then in menu.html:<\/p>\n\n<pre><code>{% for menu in menu_list %\n    &lt;li&gt;\n        {{ menu.name \n        {% if menu.submenus|length %\n            &lt;ul&gt;\n                {% include \"menu.html\" with menu_list=menu.submenus %\n            &lt;\/ul&gt;\n        {% endif %\n    &lt;\/li&gt;\n{% endfor %\n<\/code><\/pre>\n",
                "<p>I had the same problem and I wrote a template tag. I know there are other tags like this out there but I needed to learn to make custom tags anyway :) I think it turned out pretty well.<\/p>\n\n<p>Read the docstring for usage instructions.<\/p>\n\n<p><a href=\"http:\/\/github.com\/skid\/django-recurse\" rel=\"nofollow\">github.com\/skid\/django-recurse<\/a><\/p>\n",
                "<p>Django has a built in template helper for this exact scenario:<\/p>\n\n<p><a href=\"https:\/\/docs.djangoproject.com\/en\/dev\/ref\/templates\/builtins\/#unordered-list\" rel=\"nofollow\">https:\/\/docs.djangoproject.com\/en\/dev\/ref\/templates\/builtins\/#unordered-list<\/a><\/p>\n",
                "<p>Yes, you can do it. It's a little trick, \npassing the filename to {% include % as a variable:<\/p>\n\n<pre><code>{% with template_name=\"file\/to_include.html\" %\n{% include template_name %\n{% endwith %\n<\/code><\/pre>\n",
                "<p>this might be way more than you need, but there is a django module called 'mptt' - this stores a hierarchical tree structure in an sql database, and includes templates for display in the view code.  you might be able to find something useful there.<\/p>\n\n<p>here's the link : <a href=\"https:\/\/github.com\/django-mptt\/django-mptt\/\" rel=\"nofollow\">django-mptt<\/a><\/p>\n",
                "<p>I think the canonical answer is: \"Don't\".<\/p>\n\n<p>What you should probably do instead is unravel the thing in your <em>view<\/em> code, so it's just a matter of iterating over (in|de)dents in the template. I think I'd do it by appending indents and dedents to a list while recursing through the tree and then sending that \"travelogue\" list to the template. (the template would then insert <code>&lt;li&gt;<\/code> and <code>&lt;\/li&gt;<\/code> from that list, creating the recursive structure with \"understanding\" it.)<\/p>\n\n<p>I'm also pretty sure recursively including template files is really a <em>wrong<\/em> way to do it...<\/p>\n",
                "<p>Using <code>with<\/code> template tag, I could do tree\/recursive list.<\/p>\n\n<p>Sample code:<\/p>\n\n<p>main template: assuming 'all_root_elems' is list of one or more root of tree<\/p>\n\n<pre><code>&lt;ul&gt;\n{%for node in all_root_elems % \n    {%include \"tree_view_template.html\" %\n{%endfor%\n&lt;\/ul&gt;\n<\/code><\/pre>\n\n<p>tree_view_template.html renders the nested <code>ul<\/code>, <code>li<\/code> and uses <code>node<\/code> template variable as below:<\/p>\n\n<pre><code>&lt;li&gt; {{node.name\n    {%if node.has_childs %\n        &lt;ul&gt;\n         {%for ch in node.all_childs %\n              {%with node=ch template_name=\"tree_view_template.html\" %\n                   {%include template_name%\n              {%endwith%\n         {%endfor%\n         &lt;\/ul&gt;\n    {%endif%\n&lt;\/li&gt;\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_32385",
            "padroes": [
                "This is something that I think would be very useful.  Basically, I'd like there to be a way to edit Python source programmatically without requiring human intervention.  There are a couple of things I would like to do with this:\n\n\n- Edit the configuration of Python apps that use source modules for configuration.- Set up a \"template\" so that I can customize a Python source file on the fly.  This way, I can set up a \"project\" system on an open source app I'm working on and allow certain files to be customized.\n\nI could probably write something that can do this myself, but I can see that opening up a lot of \"devil's in the details\" type issues.  Are there any ways to do this currently, or am I just going to have to bite the bullet and implement it myself?\n"
            ],
            "respostas": [
                "<p>I had the same issue and I simply opened the file and did some replace: then reload the file in the Python interpreter. This works fine and is easy to do. <\/p>\n\n<p>Otherwise AFAIK you have to use some conf objects.<\/p>\n",
                "<p>Most of these kinds of things can be determined programatically in Python, using modules like sys, os, and the special <a href=\"http:\/\/pyref.infogami.com\/__file__\" rel=\"nofollow\"><\/a> identifier which tells you where you are in the filesystem path.<\/p>\n\n<p>It's important to keep in mind that when a module is first imported it will execute everything in the file-scope, which is important for developing system-dependent behaviors. For example, the os module basically determines what operating system you're using on import and then adjusts its implementation accordingly (by importing another module corresponding to Linux, OSX, Windows, etc.).<\/p>\n\n<p>There's a lot of power in this feature and something along these lines is probably what you're looking for. :)<\/p>\n\n<p>[Edit] I've also used socket.gethostname() in some rare, hackish instances. ;)<\/p>\n",
                "<p>Python's standard library provides pretty good facilities for working with Python source; note the <a href=\"https:\/\/docs.python.org\/2\/library\/tokenize.html\" rel=\"nofollow\">tokenize<\/a> and <a href=\"https:\/\/docs.python.org\/2\/library\/parser.html\" rel=\"nofollow\">parser<\/a> modules.<\/p>\n"
            ]
        },
        {
            "tag": "questao_32404",
            "padroes": [
                "I am sketching the architecture for a set of programs that share various interrelated objects stored in a database. I want one of the programs to act as a service which provides a higher level interface for operations on these objects, and the other programs to access the objects through that service.\n\nI am currently aiming for Python and the Django framework as the technologies to implement that service with. I'm pretty sure I figure how to demonize the Python program in Linux. However, it is an optional spec item that the system should support Windows. I have little experience with Windows programming and no experience at all with Windows services.\n\nIs it possible to run a Python programs as a Windows service (i. e. run it automatically without user login)? I won't necessarily have to implement this part, but I need a rough idea how it would be done in order to decide whether to design along these lines.\n\nEdit: Thanks for all the answers so far, they are quite comprehensive. I would like to know one more thing: How is Windows aware of my service? Can I manage it with the native Windows utilities? Basically, what is the equivalent of putting a start\/stop script in \/etc\/init.d?\n"
            ],
            "respostas": [
                "<p>Although I upvoted the chosen answer a couple of weeks back, in the meantime I struggled a lot more with this topic. It feels like having a special Python installation and using special modules to run a script as a service is simply the wrong way. What about portability and such?<\/p>\n\n<p>I stumbled across the wonderful <a href=\"http:\/\/nssm.cc\/\">Non-sucking Service Manager<\/a>, which made it really simple and sane to deal with Windows Services. I figured since I could pass options to an installed service, I could just as well select my Python executable and pass my script as an option.<\/p>\n\n<p>I have not yet tried this solution, but I will do so right now and update this post along the process. I am also interested in using virtualenvs on Windows, so I might come up with a tutorial sooner or later and link to it here.<\/p>\n",
                "<p>There are a couple alternatives for installing as a service virtually any Windows executable.<\/p>\n\n<h2>Method 1: Use instsrv and srvany from rktools.exe<\/h2>\n\n<p>For Windows Home Server or Windows Server 2003 (works with WinXP too), the <a href=\"http:\/\/www.microsoft.com\/downloads\/details.aspx?FamilyID=9D467A69-57FF-4AE7-96EE-B18C4790CFFD&amp;displaylang=en\">Windows Server 2003 Resource Kit Tools<\/a> comes with utilities that can be used in tandem for this, called <strong>instsrv.exe<\/strong> and <strong>srvany.exe<\/strong>.  See this Microsoft KB article <a href=\"http:\/\/support.microsoft.com\/kb\/137890\">KB137890<\/a> for details on how to use these utils.  <\/p>\n\n<p>For Windows Home Server, there is a great user friendly wrapper for these utilities named aptly \"<a href=\"http:\/\/forum.wegotserved.com\/index.php?autocom=downloads&amp;showfile=7\">Any Service Installer<\/a>\".  <\/p>\n\n<h2>Method 2: Use ServiceInstaller for Windows NT<\/h2>\n\n<p>There is another alternative using <a href=\"http:\/\/www.kcmultimedia.com\/smaster\/\">ServiceInstaller for Windows NT<\/a> (<a href=\"http:\/\/www.kcmultimedia.com\/smaster\/download.html\">download-able here<\/a>) with <a href=\"http:\/\/conort.googlepages.com\/runanywindowsapplicationasntservice\">python instructions available<\/a>.  Contrary to the name, it works with both Windows 2000 and Windows XP as well.  Here are some instructions for how to install a python script as a service.<\/p>\n\n<blockquote>\n  <p><strong>Installing a Python script<\/strong><\/p>\n  \n  <p>Run ServiceInstaller to create a new\n  service. (In this example, it is\n  assumed that python is installed at\n  c:\\python25)<\/p>\n\n<pre><code>Service Name  : PythonTest\nDisplay Name : PythonTest \nStartup : Manual (or whatever you like)\nDependencies : (Leave blank or fill to fit your needs)\nExecutable : c:\\python25\\python.exe\nArguments : c:\\path_to_your_python_script\\test.py\nWorking Directory : c:\\path_to_your_python_script\n<\/code><\/pre>\n  \n  <p>After installing, open the Control\n  Panel's Services applet, select and\n  start the PythonTest service.<\/p>\n<\/blockquote>\n\n<p>After my initial answer, I noticed there were closely related Q&amp;A already posted on SO. See also:<\/p>\n\n<p><a href=\"http:\/\/stackoverflow.com\/questions\/32404\/can-i-run-a-python-script-as-a-service-in-windows-how\">Can I run a Python script as a service (in Windows)? How?<\/a><\/p>\n\n<p><a href=\"http:\/\/stackoverflow.com\/questions\/34328\/how-do-i-make-windows-aware-of-a-service-i-have-written-in-python\">How do I make Windows aware of a service I have written in Python?<\/a><\/p>\n",
                "<p>Yes you can. I do it using the pythoncom libraries that come included with <a href=\"http:\/\/www.activestate.com\/Products\/activepython\/index.mhtml\" rel=\"nofollow\">ActivePython<\/a> or can be installed with <a href=\"https:\/\/sourceforge.net\/projects\/pywin32\/\" rel=\"nofollow\">pywin32<\/a> (Python for Windows extensions).<\/p>\n\n<p>This is a basic skeleton for a simple service:<\/p>\n\n<pre><code>import win32serviceutil\nimport win32service\nimport win32event\nimport servicemanager\nimport socket\n\n\nclass AppServerSvc (win32serviceutil.ServiceFramework):\n    _svc_name_ = \"TestService\"\n    _svc_display_name_ = \"Test Service\"\n\n    def __init__(self,args):\n        win32serviceutil.ServiceFramework.__init__(self,args)\n        self.hWaitStop = win32event.CreateEvent(None,0,0,None)\n        socket.setdefaulttimeout(60)\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        win32event.SetEvent(self.hWaitStop)\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(servicemanager.EVENTLOG_INFORMATION_TYPE,\n                              servicemanager.PYS_SERVICE_STARTED,\n                              (self._svc_name_,''))\n        self.main()\n\n    def main(self):\n        pass\n\nif __name__ == '__main__':\n    win32serviceutil.HandleCommandLine(AppServerSvc)\n<\/code><\/pre>\n\n<p>Your code would go in the main() method, usually with some kind of infinite loop that might be interrumped by checking a flag, that you set in the SvcStop method<\/p>\n"
            ]
        },
        {
            "tag": "questao_32899",
            "padroes": [
                "I have some kind of test data and want to create an unit test for each item. My first idea was to do it like this:\n\nimport unittest\n\nl = [[\"foo\", \"a\", \"a\",], [\"bar\", \"a\", \"b\"], [\"lee\", \"b\", \"b\"]]\n\nclass TestSequence(unittest.TestCase):\n    def testsample(self):\n        for name, a,b in l:\n            print \"test\", name\n            self.assertEqual(a,b)\n\nif __name__ == '__main__':\n    unittest.main()\n\n\nThe downside of this is that it handles all data in one test. I would like to generate one test for each item on the fly. Any suggestions?\n"
            ],
            "respostas": [
                "<p>Besides using setattr, we can use load_tests since python 3.2. Please refer to blog post <a href=\"http:\/\/blog.livreuro.com\/en\/coding\/python\/how-to-generate-discoverable-unit-tests-in-python-dynamically\/\" rel=\"nofollow\">blog.livreuro.com\/en\/coding\/python\/how-to-generate-discoverable-unit-tests-in-python-dynamically\/<\/a><\/p>\n\n<pre><code>class Test(unittest.TestCase):\n    pass\n\ndef _test(self, file_name):\n    open(file_name, 'r') as f:\n        self.assertEqual('test result',f.read())\n\ndef _generate_test(file_name):\n    def test(self):\n        _test(self, file_name)\n    return test\n\ndef _generate_tests():\n    for file in files:\n        file_name = os.path.splitext(os.path.basename(file))[0]\n        setattr(Test, 'test_%s' % file_name, _generate_test(file))\n\ntest_cases = (Test,)\n\ndef load_tests(loader, tests, pattern):\n    _generate_tests()\n    suite = TestSuite()\n    for test_class in test_cases:\n        tests = loader.loadTestsFromTestCase(test_class)\n        suite.addTests(tests)\n    return suite\n\nif __name__ == '__main__':\n    _generate_tests()\n    unittest.main()\n<\/code><\/pre>\n",
                "<p>Following is my solution. I find this useful when:\n1. Should work for unittest.Testcase and unittest discover\n2. Have a set of tests to be run for different parameter settings.\n3. Very simple no dependency on other packages\n        import unittest<\/p>\n\n<pre><code>    class BaseClass(unittest.TestCase):\n        def setUp(self):\n            self.param = 2\n            self.base = 2\n\n        def test_me(self):\n            self.assertGreaterEqual(5, self.param+self.base)\n\n        def test_me_too(self):\n            self.assertLessEqual(3, self.param+self.base)\n\n\n\n     class Child_One(BaseClass):\n        def setUp(self):\n            BaseClass.setUp(self)\n            self.param = 4\n\n\n     class Child_Two(BaseClass):\n        def setUp(self):\n            BaseClass.setUp(self)\n            self.param = 1\n<\/code><\/pre>\n",
                "<p>This solution works with <code>unittest<\/code> and <code>nose<\/code>:<\/p>\n\n<pre><code>#!\/usr\/bin\/env python\nimport unittest\n\ndef make_function(description, a, b):\n    def ghost(self):\n        self.assertEqual(a, b, description)\n    print description\n    ghost.__name__ = 'test_{0'.format(description)\n    return ghost\n\n\nclass TestsContainer(unittest.TestCase):\n    pass\n\ntestsmap = {\n    'foo': [1, 1],\n    'bar': [1, 2],\n    'baz': [5, 5]\n\ndef generator():\n    for name, params in testsmap.iteritems():\n        test_func = make_function(name, params[0], params[1])\n        setattr(TestsContainer, 'test_{0'.format(name), test_func)\n\ngenerator()\n\nif __name__ == '__main__':\n    unittest.main()\n<\/code><\/pre>\n",
                "<p>I'd been having trouble with a very particular style of parameterized tests.  All our Selenium tests can run locally, but they also should be able to be run remotely against several platforms on SauceLabs.  Basically, I wanted to take a large amount of already-written test cases and parameterize them with the fewest changes to code possible.  Furthermore, I needed to be able to pass the parameters into the setUp method, something which I haven't seen any solutions for elsewhere.<\/p>\n\n<p>Here's what I've come up with:<\/p>\n\n<pre><code>import inspect\nimport types\n\ntest_platforms = [\n    {'browserName': \"internet explorer\", 'platform': \"Windows 7\", 'version': \"10.0\",\n    {'browserName': \"internet explorer\", 'platform': \"Windows 7\", 'version': \"11.0\",\n    {'browserName': \"firefox\", 'platform': \"Linux\", 'version': \"43.0\",\n]\n\n\ndef sauce_labs():\n    def wrapper(cls):\n        return test_on_platforms(cls)\n    return wrapper\n\n\ndef test_on_platforms(base_class):\n    for name, function in inspect.getmembers(base_class, inspect.isfunction):\n        if name.startswith('test_'):\n            for platform in test_platforms:\n                new_name = '_'.join(list([name, ''.join(platform['browserName'].title().split()), platform['version']]))\n                new_function = types.FunctionType(function.__code__, function.__globals__, new_name,\n                                                  function.__defaults__, function.__closure__)\n                setattr(new_function, 'platform', platform)\n                setattr(base_class, new_name, new_function)\n            delattr(base_class, name)\n\n    return base_class\n<\/code><\/pre>\n\n<p>With this, all I had to do was add a simple decorator @sauce_labs() to each regular old TestCase, and now when running them, they're wrapped up and rewritten, so that all the test methods are parameterized and renamed.  LoginTests.test_login(self) runs as LoginTests.test_login_internet_explorer_10.0(self), LoginTests.test_login_internet_explorer_11.0(self), and LoginTests.test_login_firefox_43.0(self), and each one has the parameter self.platform to decide what browser\/platform to run against, even in LoginTests.setUp, which is crucial for my task since that's where the connection to SauceLabs is initialized.<\/p>\n\n<p>Anyway, I hope this might be of help to someone looking to do a similar \"global\" parameterization of their tests!<\/p>\n",
                "<p>There's also Hypothesis which adds fuzz or property based testing: <a href=\"https:\/\/pypi.python.org\/pypi\/hypothesis\" rel=\"nofollow\">https:\/\/pypi.python.org\/pypi\/hypothesis<\/a><\/p>\n\n<p>This is a very powerful testing method.<\/p>\n",
                "<p>You can use <code>TestSuite<\/code> and custom <code>TestCase<\/code> classes. <\/p>\n\n<pre><code>import unittest\n\nclass CustomTest(unittest.TestCase):\n    def __init__(self, name, a, b):\n        super().__init__()\n        self.name = name\n        self.a = a\n        self.b = b\n\n    def runTest(self):\n        print(\"test\", name)\n        self.assertEqual(a, b)\n\nif __name__ == '__main__':\n    suite = unittest.TestSuite()\n    suite.addTest(CustomTest(\"Foo\", 1337, 1337))\n    suite.addTest(CustomTest(\"Bar\", 0xDEAD, 0xC0DE))\n    unittest.TextTestRunner().run(suite)\n<\/code><\/pre>\n",
                "<p>Just use metaclasses, as seen here;<\/p>\n\n<pre><code>class DocTestMeta(type):\n    \"\"\"\n    Test functions are generated in metaclass due to the way some\n    test loaders work. For example, setupClass() won't get called\n    unless there are other existing test methods, and will also\n    prevent unit test loader logic being called before the test\n    methods have been defined.\n    \"\"\"\n    def __init__(self, name, bases, attrs):\n        super(DocTestMeta, self).__init__(name, bases, attrs)\n\n    def __new__(cls, name, bases, attrs):\n        def func(self):\n            \"\"\"Inner test method goes here\"\"\"\n            self.assertTrue(1)\n\n        func.__name__ = 'test_sample'\n        attrs[func.__name__] = func\n        return super(DocTestMeta, cls).__new__(cls, name, bases, attrs)\n\nclass ExampleTestCase(TestCase):\n    \"\"\"Our example test case, with no methods defined\"\"\"\n    __metaclass__ = DocTestMeta\n<\/code><\/pre>\n\n<p>Output:<\/p>\n\n<pre><code>test_sample (ExampleTestCase) ... OK\n<\/code><\/pre>\n",
                "<p>I came across <a href=\"https:\/\/pypi.python.org\/pypi\/ParamUnittest\" rel=\"nofollow\"><strong>ParamUnittest<\/strong><\/a> the other day when looking at the source code to <a href=\"https:\/\/pypi.python.org\/pypi\/radon\" rel=\"nofollow\">radon<\/a> (<a href=\"https:\/\/github.com\/rubik\/radon\/blob\/master\/radon\/tests\/test_other_metrics.py\" rel=\"nofollow\">example usage on the github repo<\/a>). It should work with other frameworks that extend TestCase (like Nose).<\/p>\n\n<p>Here is an example:<\/p>\n\n<pre><code>import unittest\nimport paramunittest\n\n\n@paramunittest.parametrized(\n    ('1', '2'),\n    #(4, 3),    &lt;---- uncomment to have a failing test\n    ('2', '3'),\n    (('4', ), {'b': '5'),\n    ((), {'a': 5, 'b': 6),\n    {'a': 5, 'b': 6,\n)\nclass TestBar(TestCase):\n    def setParameters(self, a, b):\n        self.a = a\n        self.b = b\n\n    def testLess(self):\n        self.assertLess(self.a, self.b)\n<\/code><\/pre>\n",
                "<p>I use metaclasses and decorators for generate tests. You can check my implementation <a href=\"https:\/\/github.com\/erm0l0v\/python_wrap_cases\" rel=\"nofollow\">python_wrap_cases<\/a>. This library doesn't require any test frameworks.<\/p>\n\n<p>Your example:<\/p>\n\n<pre><code>import unittest\nfrom python_wrap_cases import wrap_case\n\n\n@wrap_case\nclass TestSequence(unittest.TestCase):\n\n    @wrap_case(\"foo\", \"a\", \"a\")\n    @wrap_case(\"bar\", \"a\", \"b\")\n    @wrap_case(\"lee\", \"b\", \"b\")\n    def testsample(self, name, a, b):\n        print \"test\", name\n        self.assertEqual(a, b)\n<\/code><\/pre>\n\n<p>Console output:<\/p>\n\n<pre><code>testsample_u'bar'_u'a'_u'b' (tests.example.test_stackoverflow.TestSequence) ... test bar\nFAIL\ntestsample_u'foo'_u'a'_u'a' (tests.example.test_stackoverflow.TestSequence) ... test foo\nok\ntestsample_u'lee'_u'b'_u'b' (tests.example.test_stackoverflow.TestSequence) ... test lee\nok\n<\/code><\/pre>\n\n<p>Also you may use <em>generators<\/em>. For example this code generate all possible combinations of tests with arguments <code>a__list<\/code> and <code>b__list<\/code><\/p>\n\n<pre><code>import unittest\nfrom python_wrap_cases import wrap_case\n\n\n@wrap_case\nclass TestSequence(unittest.TestCase):\n\n    @wrap_case(a__list=[\"a\", \"b\"], b__list=[\"a\", \"b\"])\n    def testsample(self, a, b):\n        self.assertEqual(a, b)\n<\/code><\/pre>\n\n<p>Console output:<\/p>\n\n<pre><code>testsample_a(u'a')_b(u'a') (tests.example.test_stackoverflow.TestSequence) ... ok\ntestsample_a(u'a')_b(u'b') (tests.example.test_stackoverflow.TestSequence) ... FAIL\ntestsample_a(u'b')_b(u'a') (tests.example.test_stackoverflow.TestSequence) ... FAIL\ntestsample_a(u'b')_b(u'b') (tests.example.test_stackoverflow.TestSequence) ... ok\n<\/code><\/pre>\n",
                "<p>Use <a href=\"https:\/\/technomilk.wordpress.com\/2012\/02\/12\/multiplying-python-unit-test-cases-with-different-sets-of-data\/\" rel=\"nofollow\">tdd<\/a> library. It adds simple decorators for the test methods:<\/p>\n\n<pre><code>import unittest\nfrom ddt import ddt, data\nfrom mycode import larger_than_two\n\n@ddt\nclass FooTestCase(unittest.TestCase):\n\n    @data(3, 4, 12, 23)\n    def test_larger_than_two(self, value):\n        self.assertTrue(larger_than_two(value))\n\n    @data(1, -3, 2, 0)\n    def test_not_larger_than_two(self, value):\n        self.assertFalse(larger_than_two(value))\n<\/code><\/pre>\n\n<p>This library can be installed with <code>pip<\/code>. It doesn't require <code>nose<\/code>, works excellent with the standard <code>unittest<\/code>.<\/p>\n",
                "<p>You can use <a href=\"https:\/\/github.com\/taykey\/nose-ittr\" rel=\"nofollow\">nose-ittr<\/a> plugin (<code>pip install nose-ittr<\/code>).<\/p>\n\n<p>It's very easy to integrate with existing tests, minimal changes (if any) are required. It also supports <em>nose<\/em> multiprocessing plugin.<\/p>\n\n<p>Not that you can also have a customize <code>setup<\/code> function per test.<\/p>\n\n<pre><code>@ittr(number=[1, 2, 3, 4])   \ndef test_even(self):   \n    assert_equal(self.number % 2, 0)\n<\/code><\/pre>\n\n<p>It is also possible to pass <code>nosetest<\/code> parameters like with their build-in plugin <code>attrib<\/code>, this way you can run only a specific test with specific parameter:<\/p>\n\n<pre><code>nosetest -a number=2\n<\/code><\/pre>\n",
                "<p>You would benefit from trying the <a href=\"https:\/\/launchpad.net\/testscenarios\">TestScenarios<\/a> library.<\/p>\n\n<blockquote>\n  <p>testscenarios provides clean dependency injection for python unittest style tests. This can be used for interface testing (testing many implementations via a single test suite) or for classic dependency injection (provide tests with dependencies externally to the test code itself, allowing easy testing in different situations).<\/p>\n<\/blockquote>\n",
                "<p>It can be done by using <a href=\"http:\/\/pytest.org\">pytest<\/a>. Just write the file <code>test_me.py<\/code> with content:\n<\/p>\n\n<pre><code>import pytest\n\n@pytest.mark.parametrize('name, left, right', [['foo', 'a', 'a'],\n                                               ['bar', 'a', 'b'],\n                                               ['baz', 'b', 'b']])\ndef test_me(name, left, right):\n    assert left == right, name\n<\/code><\/pre>\n\n<p>And run your test with command <code>py.test --tb=short test_me.py<\/code>. Then the output will be looks like:\n<\/p>\n\n<pre><code>=========================== test session starts ============================\nplatform darwin -- Python 2.7.6 -- py-1.4.23 -- pytest-2.6.1\ncollected 3 items\n\ntest_me.py .F.\n\n================================= FAILURES =================================\n_____________________________ test_me[bar-a-b] _____________________________\ntest_me.py:8: in test_me\n    assert left == right, name\nE   AssertionError: bar\n==================== 1 failed, 2 passed in 0.01 seconds ====================\n<\/code><\/pre>\n\n<p>It simple!. Also <a href=\"http:\/\/pytest.org\">pytest<\/a> has more features like <code>fixtures<\/code>, <code>mark<\/code>, <code>assert<\/code>, etc ...<\/p>\n",
                "<p>As of Python 3.4 subtests have been introduced to unittest for this purpose. See <a href=\"https:\/\/docs.python.org\/3\/library\/unittest.html#distinguishing-test-iterations-using-subtests\" rel=\"nofollow\">the documentation<\/a> for details. TestCase.subTest is a context manager which allows to isolate asserts in a test so that a failure will be reported with parameter information but does not stop the test execution. Here's the example from the documentation:<\/p>\n\n<pre><code>class NumbersTest(unittest.TestCase):\n\ndef test_even(self):\n    \"\"\"\n    Test that numbers between 0 and 5 are all even.\n    \"\"\"\n    for i in range(0, 6):\n        with self.subTest(i=i):\n            self.assertEqual(i % 2, 0)\n<\/code><\/pre>\n\n<p>The output of a test run would be:<\/p>\n\n<pre><code>======================================================================\nFAIL: test_even (__main__.NumbersTest) (i=1)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"subtests.py\", line 32, in test_even\n    self.assertEqual(i % 2, 0)\nAssertionError: 1 != 0\n\n======================================================================\nFAIL: test_even (__main__.NumbersTest) (i=3)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"subtests.py\", line 32, in test_even\n    self.assertEqual(i % 2, 0)\nAssertionError: 1 != 0\n\n======================================================================\nFAIL: test_even (__main__.NumbersTest) (i=5)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"subtests.py\", line 32, in test_even\n    self.assertEqual(i % 2, 0)\nAssertionError: 1 != 0\n<\/code><\/pre>\n\n<p>This is also part of <a href=\"https:\/\/pypi.python.org\/pypi\/unittest2\" rel=\"nofollow\">unittest2<\/a>, so it is available for earlier versions of Python.<\/p>\n",
                "<p><a href=\"https:\/\/docs.python.org\/2\/library\/unittest.html#load-tests-protocol\">load_tests<\/a> is a little known mechanism introduced in 2.7 to dynamically create a TestSuite. With it, you can easily create parametrized tests.<\/p>\n\n<p>For example:<\/p>\n\n<pre><code>import unittest\n\nclass GeneralTestCase(unittest.TestCase):\n    def __init__(self, methodName, param1=None, param2=None):\n        super(GeneralTestCase, self).__init__(methodName)\n\n        self.param1 = param1\n        self.param2 = param2\n\n    def runTest(self):\n        pass  # Test that depends on param 1 and 2.\n\n\ndef load_tests(loader, tests, pattern):\n    test_cases = unittest.TestSuite()\n    for p1, p2 in [(1, 2), (3, 4)]:\n        test_cases.addTest(GeneralTestCase('runTest', p1, p2))\n    return test_cases\n<\/code><\/pre>\n\n<p>That code will run all the TestCases in the TestSuite returned by load_tests. No other tests are automatically run by the discovery mechanism.<\/p>\n\n<p>Alternatively, you can also use inheritance as shown in this ticket: <a href=\"http:\/\/bugs.python.org\/msg151444\">http:\/\/bugs.python.org\/msg151444<\/a><\/p>\n",
                "<p>This can be solved elegantly using Metaclasses:<\/p>\n\n<pre><code>import unittest\n\nl = [[\"foo\", \"a\", \"a\",], [\"bar\", \"a\", \"b\"], [\"lee\", \"b\", \"b\"]]\n\nclass TestSequenceMeta(type):\n    def __new__(mcs, name, bases, dict):\n\n        def gen_test(a, b):\n            def test(self):\n                self.assertEqual(a, b)\n            return test\n\n        for tname, a, b in l:\n            test_name = \"test_%s\" % tname\n            dict[test_name] = gen_test(a,b)\n        return type.__new__(mcs, name, bases, dict)\n\nclass TestSequence(unittest.TestCase):\n    __metaclass__ = TestSequenceMeta\n\nif __name__ == '__main__':\n    unittest.main()\n<\/code><\/pre>\n",
                "<p>The <a href=\"https:\/\/nose.readthedocs.org\/en\/latest\/\">nose<\/a> testing framework <a href=\"https:\/\/nose.readthedocs.org\/en\/latest\/writing_tests.html#test-generators\">supports this<\/a>. <\/p>\n\n<p>Example (the code below is the entire contents of the file containing the test):<\/p>\n\n<pre><code>param_list = [('a', 'a'), ('a', 'b'), ('b', 'b')]\n\ndef test_generator():\n    for params in param_list:\n        yield check_em, params[0], params[1]\n\ndef check_em(a, b):\n    assert a == b\n<\/code><\/pre>\n\n<p>The output of the nosetests command:<\/p>\n\n<pre><code>> nosetests -v\ntestgen.test_generator('a', 'a') ... ok\ntestgen.test_generator('a', 'b') ... FAIL\ntestgen.test_generator('b', 'b') ... ok\n\n======================================================================\nFAIL: testgen.test_generator('a', 'b')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"\/usr\/lib\/python2.5\/site-packages\/nose-0.10.1-py2.5.egg\/nose\/case.py\", line 203, in runTest\n    self.test(*self.arg)\n  File \"testgen.py\", line 7, in check_em\n    assert a == b\nAssertionError\n\n----------------------------------------------------------------------\nRan 3 tests in 0.006s\n\nFAILED (failures=1)\n<\/code><\/pre>\n",
                "<p>i use something like this:<\/p>\n\n<pre><code>import unittest\n\nl = [[\"foo\", \"a\", \"a\",], [\"bar\", \"a\", \"b\"], [\"lee\", \"b\", \"b\"]]\n\nclass TestSequense(unittest.TestCase):\n    pass\n\ndef test_generator(a, b):\n    def test(self):\n        self.assertEqual(a,b)\n    return test\n\nif __name__ == '__main__':\n    for t in l:\n        test_name = 'test_%s' % t[0]\n        test = test_generator(t[1], t[2])\n        setattr(TestSequense, test_name, test)\n    unittest.main()\n<\/code><\/pre>\n\n<p>The <a href=\"https:\/\/github.com\/wolever\/nose-parameterized\"><code>nose-parameterized<\/code><\/a> package can be used to automate this process:<\/p>\n\n<pre><code>from nose_parameterized import parameterized\n\nclass TestSequence(unittest.TestCase):\n    @parameterized.expand([\n        [\"foo\", \"a\", \"a\",],\n        [\"bar\", \"a\", \"b\"],\n        [\"lee\", \"b\", \"b\"],\n    ])\n    def test_sequence(self, name, a, b):\n        self.assertEqual(a,b)\n<\/code><\/pre>\n\n<p>Which will generate the tests:<\/p>\n\n<pre><code>test_sequence_0_foo (__main__.TestSequence) ... ok\ntest_sequence_1_bar (__main__.TestSequence) ... FAIL\ntest_sequence_2_lee (__main__.TestSequence) ... ok\n\n======================================================================\nFAIL: test_sequence_1_bar (__main__.TestSequence)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"\/usr\/local\/lib\/python2.7\/site-packages\/nose_parameterized\/parameterized.py\", line 233, in &lt;lambda&gt;\n    standalone_func = lambda *a: func(*(a + p.args), **p.kwargs)\n  File \"x.py\", line 12, in test_sequence\n    self.assertEqual(a,b)\nAssertionError: 'a' != 'b'\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_33475",
            "padroes": [
                "I need to launch a server on the remote machine and retrieve the port number that the server process is lsitening on.  When invoked, the server will listen on a random port and output the port number on stderr.\n\nI want to automate the process of logging on to the remote machine, launching the process, and retrieving the port number. I wrote a Python script called \"invokejob.py\" that lives on the remote machine to act as a wrapper that invokes the job and then returns the port number, it looks like this:\n\nimport re, subprocess\nexecutable = ... # Name of executable\nregex = ... # Regex to extract the port number from the output\np = subprocess.Popen(executable,\n    bufsize=1, # line buffered\n    stderr=subprocess.PIPE\n    )\ns = p.stderr.readline()\nport = re.match(regex).groups()[0]\nprint port\n\n\nIf I log in interactively, this script works:\n\n$ ssh remotehost.example.com\nLast login: Thu Aug 28 17:31:18 2008 from localhost\n$ .\/invokejob.py\n63409\n$ exit\nlogout\nConnection to remotehost.example.com closed.\n\n\n(Note: successful logout, it did not hang).\n\nHowever, if I try to invoke it from the command-line, it just hangs:\n\n$ ssh remotehost.example.com invokejob.py\n\n\nDoes anybody know why it hangs in the second case, and what I can do to avoid this? \n\nNote that I need to retrieve the output of the program, so I can't just use the ssh \"-f\" flag or redirect standard output.\n"
            ],
            "respostas": [
                "<p>what if you do the following:<\/p>\n\n<h2><code>ssh &lt;remote host&gt; '&lt;your command&gt; ;&lt;your regexp using awk or something&gt;'<\/code><\/h2>\n\n<p>For example<\/p>\n\n<h2><code>ssh &lt;remote host&gt; '&lt;your program&gt;; ps aux | awk \\'\/root\/ {print $2\\''<\/code><\/h2>\n\n<p>This will connect to , execute  and then print each PSID for any user root or any process with root in its description.<\/p>\n\n<p>I have used this method for running all kinds of commands on remote machines.  The catch is to wrap the command(s) you wish to execute in single quotation marks (') and to separate each command with a semi-colon (;).<\/p>\n",
                "<p>@Ben Collins<\/p>\n\n<p>I think you're right about stderr being an issue. I am pretty sure it's blocking on the readline() call. <\/p>\n\n<p>In the end, I gave up and decided to use the pxssh module from <a href=\"http:\/\/pexpect.sourceforge.net\" rel=\"nofollow\">pexpect<\/a> to automate my interaction with an ssh session.<\/p>\n\n<p>@Misha M<\/p>\n\n<p>Unfortunately, the semi-colon trick doesn't work here: it blocks on executing my program. <\/p>\n",
                "<blockquote>\n<pre><code>s = p.stderr.readline()\n<\/code><\/pre>\n<\/blockquote>\n\n<p>I suspect it's the above line.  When you invoke a command directly through ssh, you don't get your full pty (assuming Linux), and thus no stderr to read from.<\/p>\n\n<p>When you log in interactively, stdin, stdout, and stderr are set up for you, and so your script works.<\/p>\n"
            ]
        },
        {
            "tag": "questao_33534",
            "padroes": [
                "I'm trying to extend some \"base\" classes in Python:\n\nclass xlist (list):\n    def len(self):\n        return len(self)\n\n    def add(self, *args):\n        self.extend(args)\n        return None\n\n\nclass xint (int):\n    def add(self, value):\n        self += value\n        return self\n\n\nx = xlist([1,2,3])\nprint x.len()   ## >>> 3 ok\nprint x         ## >>> [1,2,3] ok\nx.add (4, 5, 6)\nprint x         ## >>> [1,2,3,4,5,6] ok\n\nx = xint(10)\nprint x         ## >>> 10 ok\nx.add (2)\nprint x         ## >>> 10  # Not ok (#1)\n\nprint type(x)         ## >>>  ok\nx += 5\nprint type(x)         ## >>>   # Not ok (#2)\n\n\nIt works fine in the list case because the append method modifies the object \"in place\", without returning it. But in the int case, the add method doesn't modify the value of the external x variable. I suppose that's fine in the sense that self is a local variable in the add method of the class, but this is preventing me from modifying the initial value assigned to the instance of the class.\n\nIs it possible to extend a class this way or should I define a class property with the base type and map all the needed methods to this property?\n"
            ],
            "respostas": [
                "<p>Ints are immutable and you can't modify them in place, so you should go with option #2 (because option #1 is impossible without some trickery).<\/p>\n",
                "<p>i expanded you xlist class just a bit, made it so you could find all index points of a number making it so you can extend with multiple lists at once making it initialize and making it so you can iterate through it<\/p>\n\n<pre><code>class xlist:\n    def __init__(self,alist):\n        if type(alist)==type(' '):\n            self.alist = [int(i) for i in alist.split(' ')]\n        else:\n            self.alist = alist\n    def __iter__(self):\n        i = 0\n        while i&lt;len(self.alist):\n            yield self.alist[i]\n            i+=1\n    def len(self):\n        return len(self.alist)\n    def add(self, *args):\n        if type(args[0])==type([1]):\n            if len(args)&gt;1:\n                tmp = []\n                [tmp.extend(i) for i in args]\n                args = tmp\n            else:args = args[0]\n        if type(args)==type(''):args = [int(i) for i in args.split(' ')] \n        (self.alist).extend(args)\n        return None\n    def index(self,val):\n        gen = (i for i,x in enumerate(self.alist) if x == val)\n        return list(gen)\n<\/code><\/pre>\n",
                "<p><strong>int<\/strong> is a value type, so each time you do an assignment, (e.g. both instances of <strong>+=<\/strong> above), it doesn't modify the object you have on the heap, but replaces the reference with one of the result of the right hand side of the assignment (i.e. an int)<\/p>\n\n<p><strong>list<\/strong> isn't a value type, so it isn't bound by the same rules.<\/p>\n\n<p>this page has more details on the differences: <a href=\"http:\/\/docs.python.org\/ref\/objects.html\">http:\/\/docs.python.org\/ref\/objects.html<\/a><\/p>\n\n<p>IMO, yes, you should define a new class that keeps an int as an instance variable<\/p>\n",
                "<p>Your two <code>xint<\/code> examples don't work for two different reasons.<\/p>\n\n<p>The first doesn't work because <code>self += value<\/code> is equivalent to <code>self = self + value<\/code> which just reassigns the local variable <code>self<\/code> to a different object (an integer) but doesn't change the original object. You can't really get this <\/p>\n\n<pre><code>&gt;&gt;&gt; x = xint(10)\n&gt;&gt;&gt; x.add(2)\n<\/code><\/pre>\n\n<p>to work with a subclass of <code>int<\/code> since integers are <a href=\"http:\/\/docs.python.org\/ref\/objects.html\">immutable<\/a>.<\/p>\n\n<p>To get the second one to work you can define an <a href=\"http:\/\/docs.python.org\/ref\/numeric-types.html\"><code>__add__<\/code> method<\/a>, like so:<\/p>\n\n<pre><code>class xint(int):\n    def __add__(self, value):\n        return xint(int.__add__(self, value))\n\n&gt;&gt;&gt; x = xint(10)\n&gt;&gt;&gt; type(x)\n&lt;class '__main__.xint'&gt;\n&gt;&gt;&gt; x += 3\n&gt;&gt;&gt; x\n13\n&gt;&gt;&gt; type(x)\n&lt;class '__main__.xint'&gt;\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_33978",
            "padroes": [
                "How would you go about finding out how much memory is being used by an object? I know it is possible to find out how much is used by a block of code, but not by an instantiated object (anytime during its life), which is what I want. \n"
            ],
            "respostas": [
                "<p>For big objects you may use a somewhat crude but effective method:\ncheck how much memory your Python process occupies in the system, then delete the object and compare.<\/p>\n\n<p>This method has many drawbacks but it will give you a very fast estimate for very big objects.<\/p>\n",
                "<p>This must be used with care because an override on the objects __sizeof__ might be misleading.<\/p>\n\n<p>Using the bregman.suite, some tests with sys.getsizeof output a copy of an array object (data) in an object instance as being bigger than the object itself (mfcc).<\/p>\n\n<pre><code>&gt;&gt;&gt; mfcc = MelFrequencyCepstrum(filepath, params)\n&gt;&gt;&gt; data = mfcc.X[:]\n&gt;&gt;&gt; sys.getsizeof(mfcc)\n64\n&gt;&gt;&gt; sys.getsizeof(mfcc.X)\n&gt;&gt;&gt;80\n&gt;&gt;&gt; sys.getsizeof(data)\n80\n&gt;&gt;&gt; mfcc\n&lt;bregman.features.MelFrequencyCepstrum object at 0x104ad3e90&gt;\n<\/code><\/pre>\n",
                "<p>I haven't any personal experience with either of the following, but a simple search for a \"Python [memory] profiler\" yield:<\/p>\n\n<ul>\n<li><p>PySizer, \"a memory profiler for Python,\" found at <a href=\"http:\/\/pysizer.8325.org\/\" rel=\"nofollow\">http:\/\/pysizer.8325.org\/<\/a>.  However the page seems to indicate that the project hasn't been updated for a while, and refers to...<\/p><\/li>\n<li><p>Heapy, \"support[ing] debugging and optimization regarding memory related issues in Python programs,\" found at <a href=\"http:\/\/guppy-pe.sourceforge.net\/#Heapy\" rel=\"nofollow\">http:\/\/guppy-pe.sourceforge.net\/#Heapy<\/a>.<\/p><\/li>\n<\/ul>\n\n<p>Hope that helps.<\/p>\n",
                "<p>Another approach is to use pickle. See <a href=\"http:\/\/stackoverflow.com\/a\/565382\/420867\">this answer<\/a> to a duplicate of this question.<\/p>\n",
                "<p>Try this:<\/p>\n\n<pre><code>sys.getsizeof(object)\n<\/code><\/pre>\n\n<p><a href=\"https:\/\/docs.python.org\/3\/library\/sys.html#sys.getsizeof\" rel=\"nofollow\">getsizeof()<\/a> calls the objectÃÃÃs <code>__sizeof__<\/code> method and adds an additional garbage collector overhead <strong>if<\/strong> the object is managed by the garbage collector.<\/p>\n",
                "<p><strong>There's no easy way to find out the memory size of a python object<\/strong>. One of the problems you may find is that Python objects - like lists and dicts - may have references to other python objects (in this case, what would your size be? The size containing the size of each object or not?). There are some pointers overhead and internal structures related to object types and garbage collection. Finally, some python objects have non-obvious behaviors. For instance, lists reserve space for more objects than they have, most of the time; dicts are even more complicated since they can operate in different ways (they have a different implementation for small number of keys and sometimes they over allocate entries).<\/p>\n\n<p>There is a <a href=\"http:\/\/code.activestate.com\/recipes\/544288\/\">big chunk of code<\/a> (and an <a href=\"http:\/\/code.activestate.com\/recipes\/546530\/\">updated big chunk of code<\/a>) out there to try to best approximate the size of a python object in memory. There's also some <a href=\"https:\/\/mail.python.org\/pipermail\/python-list\/2008-January\/483475.html\">simpler approximations<\/a>. But they will always be approximations.<\/p>\n\n<p>You may also want to check some <a href=\"http:\/\/mail.python.org\/pipermail\/python-list\/2002-March\/135223.html\">old description about PyObject<\/a> (the internal C struct that represents virtually all python objects).<\/p>\n"
            ]
        },
        {
            "tag": "questao_34020",
            "padroes": [
                "A reliable coder friend told me that Python's current multi-threading implementation is seriously buggy - enough to avoid using altogether.  What can said about this rumor?\n"
            ],
            "respostas": [
                "<p>I've used it in several applications and have never had nor heard of threading being anything other than 100% reliable, as long as you know its limits.  You can't spawn 1000 threads at the same time and expect your program to run properly on Windows, however you can easily write a worker pool and just feed it 1000 operations, and keep everything nice and under control.<\/p>\n",
                "<p>If you want to code in python and get great threading support, you might want to check out IronPython or Jython. Since the python code in IronPython and Jython run on the .NET CLR and Java VM respectively, they enjoy the great threading support built into those libraries. In addition to that, IronPython doesn't have the GIL, an issue that prevents CPython threads from taking full advantage of multi-core architectures.<\/p>\n",
                "<p>As far as I know there are no real bugs, but the performance when threading in cPython is really bad (compared to most other threading implementations, but usually good enough if all most of the threads do is block) due to the <a href=\"http:\/\/docs.python.org\/api\/threads.html\" rel=\"nofollow\">GIL<\/a> (Global Interpreter Lock), so really it is implementation specific rather than language specific. Jython, for example, does not suffer from this due to using the Java thread model.<\/p>\n\n<p>See <a href=\"http:\/\/www.artima.com\/weblogs\/viewpost.jsp?thread=214235\" rel=\"nofollow\">this<\/a> post on why it is not really feasible to remove the GIL from the cPython implementation, and <a href=\"http:\/\/www.pyzine.com\/Issue001\/Section_Articles\/article_ThreadingGlobalInterpreter.html\" rel=\"nofollow\">this<\/a> for some practical elaboration and workarounds.<\/p>\n\n<p>Do a quick google for <a href=\"http:\/\/www.google.com\/search?q=python+gil\" rel=\"nofollow\">\"Python GIL\"<\/a> for more information.<\/p>\n",
                "<p>The GIL (Global Interpreter Lock) might be a problem, but the API is quite OK. Try out the excellent <code>processing<\/code> module, which implements the Threading API for separate processes. I am using that right now (albeit on OS X, have yet to do some testing on Windows) and am really impressed. The Queue class is really saving my bacon in terms of managing complexity!<\/p>\n\n<p><strong>EDIT<\/strong>: it seemes the processing module is being included in the standard library as of version 2.6 (<code>import multiprocessing<\/code>). Joy!<\/p>\n",
                "<p>The standard implementation of Python (generally known as CPython as it is written in C) uses OS threads, but since there is the <a href=\"http:\/\/en.wikipedia.org\/wiki\/Global_Interpreter_Lock\" rel=\"nofollow\">Global Interpreter Lock<\/a>, only one thread at a time is allowed to run Python code.  But within those limitations, the threading libraries are robust and widely used.<\/p>\n\n<p>If you want to be able to use multiple CPU cores, there are a few options.  One is to use multiple python interpreters concurrently, as mentioned by others.  Another option is to use a different implementation of Python that does not use a GIL.  The two main options are <a href=\"http:\/\/en.wikipedia.org\/wiki\/Jython\" rel=\"nofollow\">Jython<\/a> and <a href=\"http:\/\/en.wikipedia.org\/wiki\/IronPython\" rel=\"nofollow\">IronPython<\/a>.<\/p>\n\n<p>Jython is written in Java, and is now fairly mature, though some incompatibilities remain.  For example, the web framework <a href=\"http:\/\/zyasoft.com\/pythoneering\/2008\/01\/django-on-jython-minding-gap.html\" rel=\"nofollow\">Django does not run perfectly yet<\/a>, but is getting closer all the time.  Jython is <a href=\"http:\/\/mail.python.org\/pipermail\/python-list\/2001-December\/116555.html\" rel=\"nofollow\">great for thread safety<\/a>, comes out <a href=\"http:\/\/blogs.warwick.ac.uk\/dwatkins\/entry\/benchmarking_parallel_python_1_2\/\" rel=\"nofollow\">better in benchmarks<\/a> and has a <a href=\"http:\/\/cgwalters.livejournal.com\/17956.html\" rel=\"nofollow\">cheeky message for those wanting the GIL<\/a>.<\/p>\n\n<p>IronPython uses the .NET framework and is written in C#.  Compatibility is reaching the stage where <a href=\"http:\/\/www.infoq.com\/news\/2008\/03\/django-and-ironpython\" rel=\"nofollow\">Django can run on IronPython<\/a> (at least as a demo) and there are <a href=\"http:\/\/www.voidspace.org.uk\/ironpython\/threading.shtml\" rel=\"nofollow\">guides to using threads in IronPython<\/a>.<\/p>\n",
                "<p>Python threads are good for <strong>concurrent I\/O programming<\/strong>. Threads are swapped out of the CPU as soon as they block waiting for input from file, network, etc. This allows other Python threads to use the CPU while others wait. This would allow you to write a multi-threaded web server or web crawler, for example.<\/p>\n\n<p>However, Python threads are serialized by the <a href=\"http:\/\/en.wikipedia.org\/wiki\/Global_Interpreter_Lock\">GIL<\/a> when they enter interpreter core. This means that if two threads are crunching numbers, only one can run at any given moment. It also means that you can't take advantage of multi-core or multi-processor architectures.<\/p>\n\n<p>There are solutions like running multiple Python interpreters concurrently, using a C based threading library. This is not for the faint of heart and the benefits might not be worth the trouble. Let's hope for an all Python solution in a future release.<\/p>\n"
            ]
        },
        {
            "tag": "questao_34079",
            "padroes": [
                "What's the best way to specify a proxy with username and password for an http connection in python?\n"
            ],
            "respostas": [
                "<p>Here is the method use urllib <\/p>\n\n<pre><code>import urllib.request\n\n# set up authentication info\nauthinfo = urllib.request.HTTPBasicAuthHandler()\nproxy_support = urllib.request.ProxyHandler({\"http\" : \"http:\/\/ahad-haam:3128\")\n\n# build a new opener that adds authentication and caching FTP handlers\nopener = urllib.request.build_opener(proxy_support, authinfo,\n                                     urllib.request.CacheFTPHandler)\n\n# install it\nurllib.request.install_opener(opener)\n\nf = urllib.request.urlopen('http:\/\/www.python.org\/')\n\"\"\"\n<\/code><\/pre>\n",
                "<p>Or if you want to install it, so that it is always used with urllib2.urlopen (so you don't need to keep a reference to the opener around):<\/p>\n\n<pre><code>import urllib2\nurl = 'www.proxyurl.com'\nusername = 'user'\npassword = 'pass'\npassword_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()\n# None, with the \"WithDefaultRealm\" password manager means\n# that the user\/pass will be used for any realm (where\n# there isn't a more specific match).\npassword_mgr.add_password(None, url, username, password)\nauth_handler = urllib2.HTTPBasicAuthHandler(password_mgr)\nopener = urllib2.build_opener(auth_handler)\nurllib2.install_opener(opener)\nprint urllib2.urlopen(\"http:\/\/www.example.com\/folder\/page.html\").read()\n<\/code><\/pre>\n",
                "<p>The best way of going through a proxy that requires authentication is using <a href=\"http:\/\/docs.python.org\/lib\/module-urllib2.html\">urllib2<\/a> to build a custom url opener, then using that to make all the requests you want to go through the proxy. Note in particular, you probably don't want to embed the proxy password in the url or the python source code (unless it's just a quick hack).<\/p>\n\n<pre><code>import urllib2\n\ndef get_proxy_opener(proxyurl, proxyuser, proxypass, proxyscheme=\"http\"):\n    password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()\n    password_mgr.add_password(None, proxyurl, proxyuser, proxypass)\n\n    proxy_handler = urllib2.ProxyHandler({proxyscheme: proxyurl)\n    proxy_auth_handler = urllib2.ProxyBasicAuthHandler(password_mgr)\n\n    return urllib2.build_opener(proxy_handler, proxy_auth_handler)\n\nif __name__ == \"__main__\":\n    import sys\n    if len(sys.argv) &gt; 4:\n        url_opener = get_proxy_opener(*sys.argv[1:4])\n        for url in sys.argv[4:]:\n            print url_opener.open(url).headers\n    else:\n        print \"Usage:\", sys.argv[0], \"proxy user pass fetchurls...\"\n<\/code><\/pre>\n\n<p>In a more complex program, you can seperate these components out as appropriate (for instance, only using one password manager for the lifetime of the application). The python documentation has <a href=\"http:\/\/docs.python.org\/lib\/urllib2-examples.html\">more examples on how to do complex things with urllib2<\/a> that you might also find useful.<\/p>\n",
                "<p>Setting an environment var named <strong>http_proxy<\/strong> like this: <strong>http:\/\/username:password@proxy_url:port<\/strong><\/p>\n",
                "<p>This works for me:  <\/p>\n\n<pre><code>import urllib2\n\nproxy = urllib2.ProxyHandler({'http': 'http:\/\/\nusername:password@proxyurl:proxyport')\nauth = urllib2.HTTPBasicAuthHandler()\nopener = urllib2.build_opener(proxy, auth, urllib2.HTTPHandler)\nurllib2.install_opener(opener)\n\nconn = urllib2.urlopen('http:\/\/python.org')\nreturn_str = conn.read()\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_34243",
            "padroes": [
                "Is there something like the Python descriptor protocol implemented in other languages? It seems like a nice way to increase modularity\/encapsulation without bloating your containing class' implementation, but I've never heard of a similar thing in any other languages. Is it likely absent from other languages because of the lookup overhead?\n"
            ],
            "respostas": [
                "<p>Ruby and C# both easily let you create accessors by specifying getter\/setter methods for an attribute, much like in Python.  However, this isn't designed to naturally let you write the code for these methods in another class the way that Python allows.  In practice, I'm not sure how much this matters, since every time I've seen an attribute defined through the descriptor protocol its been implemented in the same class.<\/p>\n\n<p>EDIT: Darn my dyslexia (by which I mean careless reading).  For some reason I've always read \"descriptor\" as \"decorator\" and vice versa, even when I'm the one typing both of them.  I'll leave my post intact since it has valid information, albeit information which has absolutely nothing to do with the question.<\/p>\n\n<p>The term \"decorator\" itself is actually the name of a design pattern described in the famous \"Design Patterns\" book.  The Wikipedia article contains many examples in different programming languages of decorator usage: <a href=\"http:\/\/en.wikipedia.org\/wiki\/Decorator_pattern\" rel=\"nofollow\">http:\/\/en.wikipedia.org\/wiki\/Decorator_pattern<\/a><\/p>\n\n<p>However, the decorators in that article object-oriented; they have classes implementing a predefined interface which lets another existing class behave differently somehow, etc.  Python decorators act in a functional way by replacing a function at runtime with another function, allowing you to effectively modify\/replace that function, insert code, etc.<\/p>\n\n<p>This is known in the Java world as Aspect-Oriented programming, and the AspectJ Java compiler lets you do these kinds of things and compile your AspectJ code (which is a superset of Java) into Java bytecode.<\/p>\n\n<p>I'm not familiar enough with C# or Ruby to know what their version of decorators would be.<\/p>\n",
                "<p>I've not heard of a direct equivalent either. You could probably achieve the same effect with macros, especially in a language like Lisp which has extremely powerful macros.<\/p>\n\n<p>I wouldn't be at all surprised if other languages start to incorporate something similar because it is so powerful.<\/p>\n"
            ]
        },
        {
            "tag": "questao_34328",
            "padroes": [
                "In another question I posted yesterday, I got very good advice on how a Python script could be run as a service in Windows. What I'm left wondering is: How is Windows aware of the services that can be managed in the native tools (\"services\" window in \"administrative tools\"). I. e. what is the Windows equivalent of putting a start\/stop script in \/etc\/init.d under Linux?\n"
            ],
            "respostas": [
                "<p>You can use srvany.exe from Windows NT Resource Kit to create a user defined service that will show up in the admin tools...<\/p>\n\n<p><a href=\"http:\/\/support.microsoft.com\/kb\/137890\" rel=\"nofollow\">http:\/\/support.microsoft.com\/kb\/137890<\/a><\/p>\n\n<p>I am using this method to run tracd (a python script \/ server) for trac. <\/p>\n\n<p>Here are some very clear instructions: <a href=\"http:\/\/www.tacktech.com\/display.cfm?ttid=197\" rel=\"nofollow\">http:\/\/www.tacktech.com\/display.cfm?ttid=197<\/a><\/p>\n\n<p>It does require some registry editing (very minimal and easy) but will allow you to make any command line \/ script a windows service. <\/p>\n",
                "<p>As with most \"aware\" things in Windows, the answer is \"Registry\".<\/p>\n\n<p>Take a look at this Microsoft Knowledge Base article: <a href=\"http:\/\/support.microsoft.com\/kb\/103000\" rel=\"nofollow\">http:\/\/support.microsoft.com\/kb\/103000<\/a><\/p>\n\n<p>Search for \"A Win32 program that can be started by the Service Controller and that obeys the service control protocol.\" This is the kind of service you're interested in.<\/p>\n\n<p>The service registration (contents of KEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\n\\myservice) carries information about the service, including things like its executable location, what to do when it fails (halt the OS?), what services must be started before this one, what user it runs as.<\/p>\n\n<p>As to service control protocol, main() of your program is supposed to invoke a Windows API call, setting up callbacks for start, stop, pause for your service. What you do in those callbacks is all up to you.<\/p>\n",
                "<p>Don't muck with the registry directly. User the SC command-line tool. Namely, SC CREATE<\/p>\n\n<pre>\n    DESCRIPTION:\n        SC is a command line program used for communicating with the\n        NT Service Controller and services.\n    USAGE:\n        sc  [command] [service name]  ...\n\n        The option  has the form \"\\\\ServerName\"\n        Further help on commands can be obtained by typing: \"sc [command]\"\n        Commands:\n          query-----------Queries the status for a service, or\n                          enumerates the status for types of services.\n          queryex---------Queries the extended status for a service, or\n                          enumerates the status for types of services.\n          start-----------Starts a service.\n          pause-----------Sends a PAUSE control request to a service.\n          interrogate-----Sends an INTERROGATE control request to a service.\n          continue--------Sends a CONTINUE control request to a service.\n          stop------------Sends a STOP request to a service.\n          config----------Changes the configuration of a service (persistant).\n          description-----Changes the description of a service.\n          failure---------Changes the actions taken by a service upon failure.\n          qc--------------Queries the configuration information for a service.\n          qdescription----Queries the description for a service.\n          qfailure--------Queries the actions taken by a service upon failure.\n          delete----------Deletes a service (from the registry).\n          create----------Creates a service. (adds it to the registry).\n          control---------Sends a control to a service.\n          sdshow----------Displays a service's security descriptor.\n          sdset-----------Sets a service's security descriptor.\n          GetDisplayName--Gets the DisplayName for a service.\n          GetKeyName------Gets the ServiceKeyName for a service.\n          EnumDepend------Enumerates Service Dependencies.\n\n        The following commands don't require a service name:\n        sc   \n          boot------------(ok | bad) Indicates whether the last boot should\n                          be saved as the last-known-good boot configuration\n          Lock------------Locks the Service Database\n          QueryLock-------Queries the LockStatus for the SCManager Database\n    EXAMPLE:\n        sc start MyService\n<\/pre>\n",
                "<p>Here is code to install a python-script as a service, written in python :)<\/p>\n\n<p><a href=\"http:\/\/code.activestate.com\/recipes\/551780\/\">http:\/\/code.activestate.com\/recipes\/551780\/<\/a><\/p>\n\n<p>This post could also help you out:<\/p>\n\n<p><a href=\"http:\/\/essiene.blogspot.com\/2005\/04\/python-windows-services.html\">http:\/\/essiene.blogspot.com\/2005\/04\/python-windows-services.html<\/a><\/p>\n"
            ]
        },
        {
            "tag": "questao_34209",
            "padroes": [
                "In the transition to newforms admin I'm having difficulty figuring out how specify core=False for ImageFields.\n\nI get the following error:\n\nTypeError: __init__() got an unexpected keyword argument 'core'\n\n\n[Edit] However, by just removing the core argument I get a \"This field is required.\" error in the admin interface on attempted submission. How does one accomplish what core=False is meant to do using newforms admin?\n"
            ],
            "respostas": [
                "<p>This is simple. I started getting this problems a few revisions ago. Basically, just remove the \"core=True\" parameter in the ImageField in the models, and then follow the instructions <a href=\"http:\/\/docs.djangoproject.com\/en\/dev\/ref\/contrib\/admin\/#inlinemodeladmin-objects\" rel=\"nofollow\">here<\/a> to convert to what the newforms admin uses.<\/p>\n",
                "<p>The <code>core<\/code> attribute isn't used anymore.<\/p>\n\n<p>From <a href=\"http:\/\/oebfare.com\/blog\/2008\/jul\/20\/newforms-admin-migration-and-screencast\/\" rel=\"nofollow\">Brian Rosner's Blog<\/a>:<\/p>\n\n<blockquote>\n  <p>You can safely just remove any and all <code>core<\/code> arguments. They are no longer used. <em>newforms-admin<\/em> now provides a nice delete checkbox for exisiting instances in inlines.<\/p>\n<\/blockquote>\n",
                "<p>To get rid of \"This field is required,\" you need to make it not required, by using blank=True (and possibly null=True as well, if it's not a CharField).<\/p>\n"
            ]
        },
        {
            "tag": "questao_34439",
            "padroes": [
                "Given a Python object of any kind, is there an easy way to get a list of all methods that this object has?Or,\n\nif this is not possible, is there at least an easy way to check if it has a particular method other than simply checking if an error occurs when the method is called?\n"
            ],
            "respostas": [
                "<blockquote>\n  <p>...is there at least an easy way to check if it has a particular method other than simply checking if an error occurs when the method is called<\/p>\n<\/blockquote>\n\n<p>While \"<a href=\"http:\/\/docs.python.org\/2\/glossary.html#term-eafp\" rel=\"nofollow\">Easier to ask for forgiveness than permission<\/a>\" is certainly the Pythonic way, what you are looking for maybe:<\/p>\n\n<pre><code>d={'foo':'bar', 'spam':'eggs'\nif 'get' in dir(d):\n    d.get('foo')\n# OUT: 'bar'\n<\/code><\/pre>\n",
                "<p>One can create a <code>getAttrs<\/code> function that will return an object's callable property names<\/p>\n\n<pre><code>def getAttrs(object):\n  return filter(lambda m: callable(getattr(object, m)), dir(object))\n\nprint getAttrs('Foo bar'.split(' '))\n<\/code><\/pre>\n\n<p>That'd return<\/p>\n\n<pre><code>['__add__', '__class__', '__contains__', '__delattr__', '__delitem__',\n '__delslice__', '__eq__', '__format__', '__ge__', '__getattribute__', \n '__getitem__', '__getslice__', '__gt__', '__iadd__', '__imul__', '__init__', \n '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', \n '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', \n '__setattr__', '__setitem__', '__setslice__', '__sizeof__', '__str__', \n '__subclasshook__', 'append', 'count', 'extend', 'index', 'insert', 'pop', \n 'remove', 'reverse', 'sort']\n<\/code><\/pre>\n",
                "<p>I believe that what you want is a something like this: a list of attributes\/methods of your object. dir() built-in can do this job for you IMHO :).<\/p>\n\n<pre><code>$ python\nPython 2.7.6 (default, Jun 22 2015, 17:58:13) \n[GCC 4.8.2] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; a = \"I am a string\"\n&gt;&gt;&gt; dir(a)\n['__add__', '__class__', '__contains__', '__delattr__', '__doc__',\n'__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__',\n'__getnewargs__', '__getslice__', '__gt__', '__hash__', '__init__',\n'__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__',\n'__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__',\n'__setattr__', '__sizeof__', '__str__', '__subclasshook__',\n'_formatter_field_name_split', '_formatter_parser', 'capitalize',\n'center', 'count', 'decode', 'encode', 'endswith', 'expandtabs', 'find',\n'format', 'index', 'isalnum', 'isalpha', 'isdigit', 'islower', 'isspace',\n'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'partition',\n'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip',\n'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title',\n'translate', 'upper', 'zfill']\n<\/code><\/pre>\n\n<p><b> +PLUS <\/b><br>\nAs I was checking your issue, I have decided to make a script in order to better format the output of dir(). Here goes:<\/p>\n\n<p><b>list_objects_methods.py<\/b><\/p>\n\n<pre><code>#!\/usr\/bin\/python\nOBJ = \"I am a string.\"\nCOUNT = 0\n\nfor method in dir(OBJ):\n    print \"| {0: &lt;20\".format(method),\n    COUNT += 1\n    if COUNT == 4:\n        COUNT = 0\n        print\n<\/code><\/pre>\n\n<p>Hope that I have contributed :). \nRegards!<\/p>\n",
                "<p>There is no reliable way to list all object's methods. <code>dir(object)<\/code> is usually useful, but in some cases it may not list all methods. According to <a href=\"https:\/\/docs.python.org\/2\/library\/functions.html#dir\" rel=\"nofollow\"><code>dir()<\/code> documentation<\/a>: <em>\"With an argument, <strong>attempt<\/strong> to return a list of valid attributes for that object.\"<\/em><\/p>\n\n<p>Checking that method exists can be done by <code>callable(getattr(object, method))<\/code> as already mentioned there.<\/p>\n",
                "<p>The problem with all methods indicated here is that you CAN'T be sure that a method doesn't exist.<\/p>\n\n<p>In Python you can intercept the dot calling thru <code>__getattr__<\/code> and <code>__getattribute__<\/code>, making it possible to create method \"at runtime\"<\/p>\n\n<p>Exemple:<\/p>\n\n<pre><code>class MoreMethod(object):\n    def some_method(self, x):\n        return x\n    def __getattr__(self, *args):\n        return lambda x: x*2\n<\/code><\/pre>\n\n<p>If you execute it, you can call method non existing in the object dictionary...<\/p>\n\n<pre><code>&gt;&gt;&gt; o = MoreMethod()\n&gt;&gt;&gt; o.some_method(5)\n5\n&gt;&gt;&gt; dir(o)\n['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattr__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'some_method']\n&gt;&gt;&gt; o.i_dont_care_of_the_name(5)\n10\n<\/code><\/pre>\n\n<p>And it's why you use the <a href=\"https:\/\/docs.python.org\/2\/glossary.html#term-eafp\" rel=\"nofollow\">Easier to ask for forgiveness than permission<\/a> paradigms in Python.<\/p>\n",
                "<p>If you specifically want <strong>methods<\/strong>, you should use <a href=\"https:\/\/docs.python.org\/2\/library\/inspect.html#inspect.ismethod\" rel=\"nofollow\">inspect.ismethod<\/a>.<\/p>\n\n<p>For method names:<\/p>\n\n<pre><code>import inspect\nmethod_names = [attr for attr in dir(self) if inspect.ismethod(getattr(self, attr))]\n<\/code><\/pre>\n\n<p>For the methods themselves:<\/p>\n\n<pre><code>import inspect\nmethods = [member for member in [getattr(self, attr) for attr in dir(self)] if inspect.ismethod(member)]\n<\/code><\/pre>\n",
                "<p>On top of the more direct answers, I'd be remiss if I didn't mention <a href=\"http:\/\/ipython.scipy.org\/\">iPython<\/a>.\nHit 'tab' to see the available methods, with autocompletion.<\/p>\n\n<p>And once you've found a method, try:<\/p>\n\n<pre><code>help(object.method) \n<\/code><\/pre>\n\n<p>to see the pydocs, method signature, etc.<\/p>\n\n<p>Ahh... <a href=\"http:\/\/en.wikipedia.org\/wiki\/REPL\">REPL<\/a>.<\/p>\n",
                "<p>To check if it has a particular method:<\/p>\n\n<pre><code>hasattr(object,\"method\")\n<\/code><\/pre>\n",
                "<p>The simplest method is to use dir(objectname). It will display all the methods available for that object. Cool trick.<\/p>\n",
                "<p>You can use the built in <code>dir()<\/code> function to get a list of all the attributes a module has.  Try this at the command line to see how it works.<\/p>\n\n<pre><code>&gt;&gt;&gt; import moduleName\n&gt;&gt;&gt; dir(moduleName)\n<\/code><\/pre>\n\n<p>Also, you can use the <code>hasattr(module_name, \"attr_name\")<\/code> function to find out if a module has a specific attribute.<\/p>\n\n<p>See the <a href=\"http:\/\/www.ibm.com\/developerworks\/library\/l-pyint.html\">Guide to Python introspection<\/a> for more information.<\/p>\n",
                "<p>It appears you can use this code, replacing 'object' with the object you're interested in:-<\/p>\n\n<pre><code>[method for method in dir(object) if callable(getattr(object, method))]\n<\/code><\/pre>\n\n<p>I discovered it at <a href=\"http:\/\/www.diveintopython.net\/power_of_introspection\/index.html\">this site<\/a>, hopefully that should provide some further detail!<\/p>\n"
            ]
        },
        {
            "tag": "questao_34916",
            "padroes": [
                "Is there anything similar to rails' scaffolding fo pylons? I've been poking around google, but fofund only this thing caled dbsprockets, which is fine, although probably way to much for my needs. What i really need is a basic CRUD thas is based on the SQLAlchemy model.\n"
            ],
            "respostas": [
                "<p>Just updating an old question. DBSprockets has been replaced by <a href=\"http:\/\/sprox.org\/\" rel=\"nofollow\">sprox<\/a> which learns a lot of lessons from it and is pretty cool.<\/p>\n\n<p>It isn't quite the throwaway 'scaffolding' that Rails provides, it is more like an agile form generation tool that is highly extensible.<\/p>\n",
                "<p>I hear you, I've followed the Pylons mailing list for a while looking for something similar. There have been some attempts in the past (see <a href=\"http:\/\/adminpylon.devjavu.com\/\" rel=\"nofollow\">AdminPylon<\/a> and <a href=\"http:\/\/code.google.com\/p\/restin\/\" rel=\"nofollow\">Restin<\/a>) but none have really kept up with SQLAlchemy's rapidly developing orm api.<\/p>\n\n<p>Since DBSprockets is likely to be incorporated into TurboGears it will likely be maintained. I'd bite the bullet and go with that.<\/p>\n",
                "<p>The question is super old, but hell: <a href=\"http:\/\/code.google.com\/p\/formalchemy\/\" rel=\"nofollow\">http:\/\/code.google.com\/p\/formalchemy\/<\/a><\/p>\n\n<p>Gives you basic crud out of the box, customizable to do even relatively complex things easily, and gives you a drop-in Pylons admin app too (written and customizable with the same api, no magic).<\/p>\n"
            ]
        },
        {
            "tag": "questao_35538",
            "padroes": [
                "What's the best way to go about validating that a document follows some version of HTML (prefereably that I can specify)? I'd like to be able to know where the failures occur, as in a web-based validator, except in a native Python app.\n"
            ],
            "respostas": [
                "<p>In my case the python W3C\/HTML validation packages did not work <code>pip search w3c<\/code> (as of sept 2016).<\/p>\n\n<p>I solved this with<\/p>\n\n<pre><code>$ pip install requests\n\n$ python\nPython 2.7.12 (default, Jun 29 2016, 12:46:54)\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n&gt;&gt;&gt; r = requests.post('https:\/\/validator.w3.org\/nu\/', \n...                    data=file('index.html', 'rb').read(), \n...                    params={'out': 'json', \n...                    headers={'User-Agent': 'Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/41.0.2272.101 Safari\/537.36', \n...                    'Content-Type': 'text\/html; charset=UTF-8')\n\n&gt;&gt;&gt; r.text\n&gt;&gt;&gt; u'{\"messages\":[{\"type\":\"info\", ...\n\n&gt;&gt;&gt; r.json()\n&gt;&gt;&gt; {u'messages': [{u'lastColumn': 59, ...\n<\/code><\/pre>\n\n<p>More documentation here <a href=\"http:\/\/docs.python-requests.org\/en\/master\/user\/quickstart\/#binary-response-content\" rel=\"nofollow\">python requests<\/a>, <a href=\"https:\/\/github.com\/validator\/validator\/wiki\/Service:-Input:-POST-body\" rel=\"nofollow\">W3C Validator API<\/a><\/p>\n",
                "<p>I think that <a href=\"http:\/\/tidy.sourceforge.net\/\" rel=\"nofollow\">HTML tidy<\/a> will do what you want. There is a Python binding for it.<\/p>\n",
                "<p>Try tidylib. You can get some really basic bindings as part of the elementtidy module (builds elementtrees from HTML documents). <a href=\"http:\/\/effbot.org\/downloads\/#elementtidy\">http:\/\/effbot.org\/downloads\/#elementtidy<\/a><\/p>\n\n<pre><code>&gt;&gt;&gt; import _elementtidy\n&gt;&gt;&gt; xhtml, log = _elementtidy.fixup(\"&lt;html&gt;&lt;\/html&gt;\")\n&gt;&gt;&gt; print log\nline 1 column 1 - Warning: missing &lt;!DOCTYPE&gt; declaration\nline 1 column 7 - Warning: discarding unexpected &lt;\/html&gt;\nline 1 column 14 - Warning: inserting missing 'title' element\n<\/code><\/pre>\n\n<p>Parsing the log should give you pretty much everything you need.<\/p>\n",
                "<p>XHTML is easy, use <a href=\"http:\/\/lxml.de\/validation.html\" rel=\"nofollow\">lxml<\/a>.<\/p>\n\n<p>HTML is harder, since there's traditionally not been as much interest in validation among the HTML crowd (run StackOverflow itself through a validator, yikes). The easiest solution would be to execute external applications such as <a href=\"http:\/\/www.jclark.com\/sp\/\" rel=\"nofollow\">nsgmls<\/a> or <a href=\"http:\/\/openjade.sourceforge.net\/\" rel=\"nofollow\">OpenJade<\/a>, and then parse their output.<\/p>\n",
                "<p>Starting with html5, you can try to use <a href=\"http:\/\/code.google.com\/p\/html5lib\/\">html5lib<\/a>. <\/p>\n\n<p>You can also decide to install the HTML validator locally and create a client to request the validation. <\/p>\n\n<p>Here I had made a program to validate a list of urls in a txt file. I was just checking the HEAD to get the validation status, but if you do a GET you would get the full results. Look at the API of the validator, there are plenty of options for it.<\/p>\n\n<pre><code>import httplib2\nimport time\n\nh = httplib2.Http(\".cache\")\n\nf = open(\"urllistfile.txt\", \"r\")\nurllist = f.readlines()\nf.close()\n\nfor url in urllist:\n   # wait 10 seconds before the next request - be nice with the validator\n   time.sleep(10)\n   resp= {\n   url = url.strip()\n   urlrequest = \"http:\/\/qa-dev.w3.org\/wmvs\/HEAD\/check?doctype=HTML5&amp;uri=\"+url\n   try:\n      resp, content = h.request(urlrequest, \"HEAD\")\n      if resp['x-w3c-validator-status'] == \"Abort\":\n         print url, \"FAIL\"\n      else:\n         print url, resp['x-w3c-validator-status'], resp['x-w3c-validator-errors'], resp['x-w3c-validator-warnings']\n   except:\n      pass\n<\/code><\/pre>\n",
                "<p>I think the most elegant way it to invoke the W3C Validation Service at<\/p>\n\n<pre><code>http:\/\/validator.w3.org\/\n<\/code><\/pre>\n\n<p>programmatically. Few people know that you do not have to screen-scrape the results in order to get the results, because the service returns non-standard HTTP header paramaters <\/p>\n\n<pre><code>X-W3C-Validator-Recursion: 1\nX-W3C-Validator-Status: Invalid (or Valid)\nX-W3C-Validator-Errors: 6\nX-W3C-Validator-Warnings: 0\n<\/code><\/pre>\n\n<p>for indicating the validity and the number of errors and warnings.<\/p>\n\n<p>For instance, the command line <\/p>\n\n<pre><code>curl -I \"http:\/\/validator.w3.org\/check?uri=http%3A%2F%2Fwww.stalsoft.com\"\n<\/code><\/pre>\n\n<p>returns<\/p>\n\n<pre><code>HTTP\/1.1 200 OK\nDate: Wed, 09 May 2012 15:23:58 GMT\nServer: Apache\/2.2.9 (Debian) mod_python\/3.3.1 Python\/2.5.2\nContent-Language: en\nX-W3C-Validator-Recursion: 1\nX-W3C-Validator-Status: Invalid\nX-W3C-Validator-Errors: 6\nX-W3C-Validator-Warnings: 0\nContent-Type: text\/html; charset=UTF-8\nVary: Accept-Encoding\nConnection: close\n<\/code><\/pre>\n\n<p>Thus, you can elegantly invoke the W3C Validation Service and extract the results from the HTTP header:<\/p>\n\n<pre class=\"lang-python prettyprint-override\"><code># Programmatic XHTML Validations in Python\n# Martin Hepp and Alex Stolz\n# mhepp@computer.org \/ alex.stolz@ebusiness-unibw.org\n\nimport urllib\nimport urllib2\n\nURL = \"http:\/\/validator.w3.org\/check?uri=%s\"\nSITE_URL = \"http:\/\/www.heppnetz.de\"\n\n# pattern for HEAD request taken from \n# http:\/\/stackoverflow.com\/questions\/4421170\/python-head-request-with-urllib2\n\nrequest = urllib2.Request(URL % urllib.quote(SITE_URL))\nrequest.get_method = lambda : 'HEAD'\nresponse = urllib2.urlopen(request)\n\nvalid = response.info().getheader('X-W3C-Validator-Status')\nif valid == \"Valid\":\n    valid = True\nelse:\n    valid = False\nerrors = int(response.info().getheader('X-W3C-Validator-Errors'))\nwarnings = int(response.info().getheader('X-W3C-Validator-Warnings'))\n\nprint \"Valid markup: %s (Errors: %i, Warnings: %i) \" % (valid, errors, warnings)\n<\/code><\/pre>\n",
                "<p><a href=\"http:\/\/countergram.com\/software\/pytidylib\">http:\/\/countergram.com\/software\/pytidylib<\/a> is a nice python binding for HTML Tidy.  Their example:<\/p>\n\n<pre><code>from tidylib import tidy_document\ndocument, errors = tidy_document('''&lt;p&gt;f&amp;otilde;o &lt;img src=\"bar.jpg\"&gt;''',\n    options={'numeric-entities':1)\nprint document\nprint errors\n<\/code><\/pre>\n"
            ]
        },
        {
            "tag": "questao_35569",
            "padroes": [
                "It seems like if you want to get the keys of a mapping, you ask for them; otherwise, give me the whole mapping (constituted by a set of key-value pairs). Is there a historical reason for this?\n"
            ],
            "respostas": [
                "<p>Check out <a href=\"http:\/\/mail.python.org\/pipermail\/python-3000\/2007-September\/010209.html\" rel=\"nofollow\">this thread<\/a> for a discussion on the reasons behind this behavior (including that Guido likes it, and it's <a href=\"http:\/\/mail.python.org\/pipermail\/python-3000\/2007-September\/010222.html\" rel=\"nofollow\">not likely to change<\/a>).<\/p>\n"
            ]
        },
        {
            "tag": "questao_35634",
            "padroes": [
                "Is there a Ruby equivalent for Python's \"is\"? It tests whether two objects are identical (i.e. have the same memory location).\n"
            ],
            "respostas": [
                "<p>You could also use <code>__id__<\/code>. This gives you the objects internal ID number, which is always unique. To check if to objects are the same, try<\/p>\n\n<blockquote>\n  <p><code>a.__id__ = b.__id__<\/code><\/p>\n<\/blockquote>\n\n<p>This is how Ruby's standard library does it as far as I can tell (see <code>group_by<\/code> and others).<\/p>\n",
                "<p>Use <code>a.equal? b<\/code><\/p>\n\n<p><a href=\"http:\/\/www.ruby-doc.org\/core\/classes\/Object.html\">http:\/\/www.ruby-doc.org\/core\/classes\/Object.html<\/a><\/p>\n\n<blockquote>\n  <p>Unlike ==, the equal? method should never be overridden by subclasses: it is used to determine object identity (that is, a.equal?(b) iff a is the same object as b). <\/p>\n<\/blockquote>\n"
            ]
        },
        {
            "tag": "questao_35753",
            "padroes": [
                "Right now I'm developing mostly in C\/C++, but I wrote some small utilities in Python to automatize some tasks and I really love it as language (especially the productivity). \n\nExcept for the performances (a problem that could be sometimes solved thanks to the ease of interfacing Python with C modules), do you think it is proper for production use in the development of stand-alone complex applications (think for example to a word processor or a graphic tool)?\n\nWhat IDE would you suggest? The IDLE provided with Python is not enough even for small projects in my opinion.\n"
            ],
            "respostas": [
                "<p>I had only one python experience, my trash-cli project.<\/p>\n\n<p>I know that probably some or all problems depends of my inexperience with python.<\/p>\n\n<p>I found frustrating these things: <\/p>\n\n<ol>\n<li>the difficult of finding a good IDE for free<\/li>\n<li>the limited support to automatic refactoring<\/li>\n<\/ol>\n\n<p>Moreover:<\/p>\n\n<ol>\n<li>the need of introduce two level of grouping packages and modules confuses me.<\/li>\n<li>it seems to me that there is not a widely adopted code naming convention<\/li>\n<li>it seems to me that there are some standard library APIs docs that are incomplete<\/li>\n<li>the fact that some standard libraries are not fully object oriented annoys me<\/li>\n<\/ol>\n\n<p>Although some python coders tell me that they does not have these problems, or they say these are not problems.<\/p>\n",
                "<p>Try Django or Pylons, write a simple app with both of them and then decide which one suits you best. There are others (like Turbogears or Werkzeug) but those are the most used.<\/p>\n",
                "<p>I know I'm probably stating the obvious, but don't forget that the quality of the development team and their familiarity with the technology will have a major impact on your ability to deliver. <\/p>\n\n<p>If you have a strong team, then it's probably not an issue if they're familiar. But if you have people who are more 9 to 5'rs who aren't familiar with the technology, they will need more support and you'd need to make a call if the productivity gains are worth whatever the cost of that support is.<\/p>\n",
                "<blockquote>\n  <p>And as far as I know they use a lot of python inside google too.<\/p>\n<\/blockquote>\n\n<p>Well i'd hope so, the maker of python still works at google if i'm not mistaken? <\/p>\n\n<p>As for the use of Python, i think it's a great language for stand-alone apps. It's heavily used in a lot of Linux programs, and there are a few nice widget sets out there to aid in the development of GUI's. <\/p>\n",
                "<p>Python is a delight to use. I use it routinely and also write a lot of code for work in C#. There are two drawbacks to writing UI code in Python. one is that there is not a single ui framework that is accepted by the majority of the community. when you write in c# the .NET runtime and class libraries are all meant to work together. With Python every UI library has at's own semantics which are often at odds with the pythonic mindset in which you are trying to write your program. I am not blaming the library writers. I've tried several libraries (wxwidgets, PythonWin[Wrapper around MFC], Tkinter), When doing so I often felt that I was writing code in a language other than Python (despite the fact that it was python) because the libraries aren't exactly pythonic they are a port from another language be it c, c++, tk.<\/p>\n\n<p>So  for me I will write UI code in .NET (for me C#) because of the IDE &amp; the consistency of the libraries. But when I can I will write business logic in python because it is more clear and more fun.<\/p>\n",
                "<p>Refactoring is inevitable on larger codebases and the lack of static typing makes this much harder in python than in statically typed languages.<\/p>\n",
                "<p>One way to judge what python is used for is to look at what products use python at the moment.  This <a href=\"http:\/\/en.wikipedia.org\/wiki\/Python_software\" rel=\"nofollow\">wikipedia page<\/a> has a long list including various web frameworks, content management systems, version control systems, desktop apps and IDEs.<\/p>\n\n<p>As it says <a href=\"http:\/\/en.wikipedia.org\/wiki\/Python_%28programming_language%29#Usage\" rel=\"nofollow\">here<\/a> - \"Some of the largest projects that use Python are the Zope application server, YouTube, and the original BitTorrent client. Large organizations that make use of Python include Google, Yahoo!, CERN and NASA. ITA uses Python for some of its components.\"<\/p>\n\n<p>So in short, yes, it is \"proper for production use in the development of stand-alone complex applications\".  So are many other languages, with various pros and cons.  Which is the best language for your particular use case is too subjective to answer, so I won't try, but often the answer will be \"the one your developers know best\".<\/p>\n",
                "<p>Nothing to add to the other answers, <em>besides<\/em> that if you choose python you <strong>must<\/strong> use something like <a href=\"http:\/\/pypi.python.org\/pypi\/pylint\" rel=\"nofollow\">pylint<\/a> which nobody mentioned so far.<\/p>\n",
                "<p>Python is considered (among Python programmers :) to be a great language for rapid prototyping. There's not a lot of extraneous syntax getting in the way of your thought processes, so most of the work you do tends to go into the code. (There's far less idioms required to be involved in writing good Python code than in writing good C++.)<\/p>\n\n<p>Given this, most Python (CPython) programmers ascribe to the \"premature optimization is the root of all evil\" philosophy. By writing high-level (and significantly slower) Python code, one can optimize the bottlenecks out using C\/C++ bindings when your application is nearing completion. At this point it becomes more clear what your processor-intensive algorithms are through proper profiling. This way, you write most of the code in a very readable and maintainable manner while allowing for speedups down the road. You'll see several Python library modules written in C for this very reason.<\/p>\n\n<p>Most graphics libraries in Python (i.e. wxPython) are just Python wrappers around C++ libraries anyway, so you're pretty much writing to a C++ backend.<\/p>\n\n<p>To address your IDE question, <a href=\"http:\/\/pythonide.blogspot.com\/\">SPE<\/a> (Stani's Python Editor) is a good IDE that I've used and <a href=\"http:\/\/www.eclipse.org\/\">Eclipse<\/a> with <a href=\"http:\/\/pydev.sourceforge.net\/\">PyDev<\/a> gets the job done as well. Both are OSS, so they're free to try!<\/p>\n\n<p>[Edit] @Marcin: Have you had experience writing > 30k LOC in Python? It's also funny that you should mention Google's scalability concerns, since they're Python's biggest supporters! Also a small organization called NASA also uses Python frequently ;) see <a href=\"http:\/\/www.python.org\/about\/success\/usa\/\">\"One coder and 17,000 Lines of Code Later\"<\/a>.<\/p>\n",
                "<p>I really like python, it's usually my language of choice these days for small (non-gui) stuff that I do on my own.<\/p>\n\n<p>However, for some larger Python projects I've tackled, I'm finding that it's not quite the same as programming in say, C++. I was working on a language parser, and needed to represent an AST in Python. This is certainly within the scope of what Python can do, but I had a bit of trouble with some refactoring. I was changing the representation of my AST and changing methods and classes around a lot, and I found I missed the strong typing that would be available to me in a C++ solution. Python's duck typing was almost <em>too<\/em> flexible and I found myself adding a lot of <code>assert<\/code> code to try to check my types as the program ran. And then I couldn't really be sure that everything was properly typed unless I had 100% code coverage testing (which I didn't at the time).<\/p>\n\n<p>Actually, that's another thing that I miss sometimes. It's possible to write syntactically correct code in Python that simply won't run. The compiler is incapable of telling you about it until it actually executes the code, so in infrequently-used code paths such as error handlers you can easily have unseen bugs lurking around. Even code that's as simple as printing an error message with a % format string can fail at runtime because of mismatched types.<\/p>\n\n<p>I haven't used Python for any GUI stuff so I can't comment on that aspect.<\/p>\n",
                "<p>In my opinion python is more than ready for developing complex applications. I see pythons strength more on the server side than writing graphical clients. But have a look at <a href=\"http:\/\/www.resolversystems.com\/\" rel=\"nofollow\">http:\/\/www.resolversystems.com\/<\/a>. They develop a whole spreadsheet in python using the .net ironpython port.<\/p>\n\n<p>If you are familiar with eclipse have a look at <a href=\"http:\/\/pydev.sourceforge.net\/\" rel=\"nofollow\">pydev<\/a> which provides auto-completion and debugging support for python with all the other eclipse goodies like svn support. The guy developing it has just been bought by <a href=\"http:\/\/aptana.com\/blog\/pcolton\/pydev_news\" rel=\"nofollow\">aptana<\/a>, so this will be solid choice for the future.<\/p>\n\n<p>@Marcin<\/p>\n\n<blockquote>\n  <p>Cons: as a dynamic language, has way\n  worse IDE support (proper syntax\n  completion requires static typing,\n  whether explicit in Java or inferred\n  in SML),<\/p>\n<\/blockquote>\n\n<p>You are right, that static analysis may not provide full syntax completion for dynamic languages, but I thing pydev gets the job done very well. Further more I have a different development style when programming python. I have always an ipython session open and with one F5 I do not only get the perfect completion from ipython, but object introspection and manipulation as well.<\/p>\n\n<blockquote>\n  <p>But if you want to write second Google\n  or Yahoo, you will be much better with\n  C# or Java.<\/p>\n<\/blockquote>\n\n<p><a href=\"http:\/\/www.jaiku.com\/blog\/2008\/08\/18\/from-the-dev-corner-an-under-the-hood-preview-of-our-new-engine\/\" rel=\"nofollow\">Google just rewrote jaiku<\/a> to work on top of App Engine, all in python. And as far as I know they use a lot of python inside google too.<\/p>\n",
                "<p>You'll find mostly two answers to that &ndash; the religous one (Yes! Of course! It's the best language ever!) and the other religious one (you gotta be kidding me! Python? No... it's not mature enough). I will maybe skip the last religion (Python?! Use Ruby!). The truth, as always, is far from obvious. <\/p>\n\n<p><strong>Pros<\/strong>: it's easy, readable, batteries included, has lots of good libraries for pretty much everything. It's expressive and dynamic typing makes it more concise in many cases.<\/p>\n\n<p><strong>Cons<\/strong>: as a dynamic language, has way worse IDE support (proper syntax completion <strong>requires<\/strong> static typing, whether explicit in Java or inferred in SML), its object system is far from perfect (interfaces, anyone?) and it is easy to end up with messy code that has methods returning either int or boolean or object or some sort under unknown circumstances.<\/p>\n\n<p>My take &ndash; I love Python for scripting, automation, tiny webapps and other simple well defined tasks. In my opinion it is by far <strong>the best<\/strong> dynamic language on the planet. That said, I would <strong>never<\/strong> use it <strong>any<\/strong> dynamically typed language to develop an application of substantial size.<\/p>\n\n<p>Say &ndash; it would be fine to use it for Stack Overflow, which has three developers and I guess no more than 30k lines of code. For bigger things &ndash; first your development would be super fast, and then once team and codebase grow things are slowing down more than they would with Java or C#. You need to offset lack of compilation time checks by writing more unittests, refactorings get harder cause you never know what your refacoring broke until you run all tests or even the whole big app, etc.<\/p>\n\n<p>Now &ndash; decide on how big your team is going to be and how big the app is supposed to be once it is done. If you have 5 or less people and the target size is roughly Stack Overflow, go ahead, write in Python. You will finish in no time and be happy with good codebase. But if you want to write second Google or Yahoo, you will be much better with C# or Java.<\/p>\n\n<p>Side-note on C\/C++ you have mentioned: if you are not writing performance critical software (say massive parallel raytracer that will run for three months rendering a film) or a very mission critical system (say Mars lander that will fly three years straight and has only one chance to land right or you lose $400mln) do not use it. For web apps, most desktop apps, most apps in general it is not a good choice. You will die debugging pointers and memory allocation in complex business logic.<\/p>\n",
                "<p>We've used IronPython to build our flagship spreadsheet application (40kloc production code - and it's Python, which IMO means loc per feature is low) at <a href=\"http:\/\/www.resolversystems.com\/\">Resolver Systems<\/a>, so I'd definitely say it's ready for production use of complex apps.<\/p>\n\n<p>There are two ways in which this might not be a useful answer to you :-)<\/p>\n\n<ol>\n<li>We're using IronPython, not the more usual CPython.  This gives us the huge advantage of being able to use .NET class libraries.  I may be setting myself up for flaming here, but I would say that I've never really seen a CPython application that looked \"professional\" - so having access to the WinForms widget set was a huge win for us.  IronPython also gives us the advantage of being able to easily drop into C# if we need a performance boost.  (Though to be honest we have <em>never<\/em> needed to do that.  All of our performance problems to date have been because we chose dumb algorithms rather than because the language was slow.)  Using C# from IP is much easier than writing a C Extension for CPython.  <\/li>\n<li>We're an Extreme Programming shop, so we write tests before we write code.  I would not write production code in a dynamic language without writing the tests first; the lack of a compile step needs to be covered by something, and as other people have pointed out, refactoring without it can be tough.  (Greg Hewgill's answer suggests he's had the same problem.  On the other hand, I don't think I would write - or especially refactor - production code in <em>any<\/em> language these days without writing the tests first - but YMMV.)<\/li>\n<\/ol>\n\n<p>Re: the IDE - we've been pretty much fine with each person using their favourite text editor; if you prefer something a bit more heavyweight then <a href=\"http:\/\/www.wingware.com\/products\">WingIDE<\/a> is pretty well-regarded.<\/p>\n"
            ]
        },
        {
            "tag": "questao_35805",
            "padroes": [
                "If I create a class A as follows:\n\nclass A:\n    def __init__(self):\n        self.name = 'A'\n\n\nInspecting the __dict__ member looks like {'name': 'A'\n\nIf however I create a class B:\n\nclass B:\n    name = 'B'\n\n\n__dict__ is empty.\n\nWhat is the difference between the two, and why doesn't name show up in B's __dict__?\n"
            ],
            "respostas": [
                "<pre><code>class A:\n    def _ _init_ _(self):\n        self.name = 'A'\na = A()\n<\/code><\/pre>\n\n<p>Creates an attribute on the object instance a of type A and it can therefore be found in: <code>a.__dict__<\/code><\/p>\n\n<pre><code>class B:\n    name = 'B'\nb = B()\n<\/code><\/pre>\n\n<p>Creates an attribute on the class B and the attribute can be found in <code>B.__dict__<\/code> alternatively if you have an instance b of type B you can see the class level attributes in <code>b.__class__.__dict__<\/code><\/p>\n",
                "<p><code>B.name<\/code> is a class attribute, not an instance attribute.  It shows up in <code>B.__dict__<\/code>, but not in <code>b = B(); b.__dict__<\/code>.<\/p>\n\n<p>The distinction is obscured somewhat because when you access an attribute on an instance, the class dict is a fallback.  So in the above example, <code>b.name<\/code> will give you the value of <code>B.name<\/code>.<\/p>\n"
            ]
        },
        {
            "tag": "questao_35817",
            "padroes": [
                "When using os.system() it's often necessary to escape filenames and other arguments passed as parameters to commands.  How can I do this?  Preferably something that would work on multiple operating systems\/shells but in particular for bash.\n\nI'm currently doing the following, but am sure there must be a library function for this, or at least a more elegant\/robust\/efficient option:\n\ndef sh_escape(s):\n   return s.replace(\"(\",\"\\\\(\").replace(\")\",\"\\\\)\").replace(\" \",\"\\\\ \")\n\nos.system(\"cat %s | grep something | sort > %s\" \n          % (sh_escape(in_filename), \n             sh_escape(out_filename)))\n\n\nEdit: I've accepted the simple answer of using quotes, don't know why I didn't think of that; I guess because I came from Windows where ' and \" behave a little differently.\n\nRegarding security, I understand the concern, but, in this case, I'm interested in a quick and easy solution which os.system() provides, and the source of the strings is either not user-generated or at least entered by a trusted user (me).\n"
            ],
            "respostas": [
                "<p>If you do use the system command, I would try and whitelist what goes into the os.system() call.. For example..<\/p>\n\n<pre><code>clean_user_input re.sub(\"[^a-zA-Z]\", \"\", user_input)\nos.system(\"ls %s\" % (clean_user_input))\n<\/code><\/pre>\n\n<p>The subprocess module is a better option, and I would recommend trying to avoid using anything like os.system\/subprocess wherever possible.<\/p>\n",
                "<p>The real answer is: Don't use <code>os.system()<\/code> in the first place. Use <a href=\"http:\/\/docs.python.org\/2\/library\/subprocess.html#subprocess.call\" rel=\"nofollow\"><code>subprocess.call<\/code><\/a> instead and supply the unescaped arguments.<\/p>\n",
                "<p>The function I use is:<\/p>\n\n<pre><code>def quote_argument(argument):\n    return '\"%s\"' % (\n        argument\n        .replace('\\\\', '\\\\\\\\')\n        .replace('\"', '\\\\\"')\n        .replace('$', '\\\\$')\n        .replace('`', '\\\\`')\n    )\n<\/code><\/pre>\n\n<p>that is: I always enclose the argument in double quotes, and then backslash-quote the only characters special inside double quotes.<\/p>\n",
                "<p><strong>Notice<\/strong>: This is an answer for Python 2.7.x.<\/p>\n\n<p>According to the <a href=\"https:\/\/hg.python.org\/cpython\/file\/2.7\/Lib\/pipes.py#l262\" rel=\"nofollow\">source<\/a>, <code>pipes.quote()<\/code> is a way to \"<em>Reliably quote a string as a single argument for <strong>\/bin\/sh<\/em><\/strong>\". (Although it is <a href=\"https:\/\/docs.python.org\/2\/library\/pipes.html#pipes.quote\" rel=\"nofollow\">deprecated since version 2.7<\/a> and finally exposed publicly in Python 3.3 as the <code>shelx.quote()<\/code> function.)<\/p>\n\n<p>On <a href=\"https:\/\/hg.python.org\/cpython\/file\/2.7\/Lib\/subprocess.py#l577\" rel=\"nofollow\">the other hand<\/a>, <code>subprocess.list2cmdline()<\/code> is a way to \"<em>Translate a sequence of arguments into a command line string, using the same rules as the <strong>MS C runtime<\/em><\/strong>\".<\/p>\n\n<p>Here we are, the platform independent way of quoting strings for command lines.<\/p>\n\n<pre><code>import sys\nmswindows = (sys.platform == \"win32\")\n\nif mswindows:\n    from subprocess import list2cmdline\n    quote_args = list2cmdline\nelse:\n    # POSIX\n    from pipes import quote\n\n    def quote_args(seq):\n        return ' '.join(quote(arg) for arg in seq)\n<\/code><\/pre>\n\n<p>Usage:<\/p>\n\n<pre><code># Quote a single argument\nprint quote_args(['my argument'])\n\n# Quote multiple arguments\nmy_args = ['This', 'is', 'my arguments']\nprint quote_args(my_args)\n<\/code><\/pre>\n",
                "<p>I believe that os.system just invokes whatever command shell is configured for the user, so I don't think you can do it in a platform independent way.  My command shell could be anything from bash, emacs, ruby, or even quake3.  Some of these programs aren't expecting the kind of arguments you are passing to them and even if they did there is no guarantee they do their escaping the same way.<\/p>\n",
                "<p>Note that pipes.quote is actually broken in Python 2.5 and Python 3.1 and not safe to use--It doesn't handle zero-length arguments.<\/p>\n\n<pre><code>&gt;&gt;&gt; from pipes import quote\n&gt;&gt;&gt; args = ['arg1', '', 'arg3']\n&gt;&gt;&gt; print 'mycommand %s' % (' '.join(quote(arg) for arg in args))\nmycommand arg1  arg3\n<\/code><\/pre>\n\n<p>See <a href=\"http:\/\/bugs.python.org\/issue7476\" rel=\"nofollow\">Python issue 7476<\/a>; it has been fixed in Python 2.6 and 3.2 and newer.<\/p>\n",
                "<p>Maybe <code>subprocess.list2cmdline<\/code> is a better shot?<\/p>\n",
                "<p>This is what I use:<\/p>\n\n<pre><code>def shellquote(s):\n    return \"'\" + s.replace(\"'\", \"'\\\\''\") + \"'\"\n<\/code><\/pre>\n\n<p>The shell will always accept a quoted filename and remove the surrounding quotes before passing it to the program in question. Notably, this avoids problems with filenames that contain spaces or any other kind of nasty shell metacharacter.<\/p>\n\n<p><strong>Update<\/strong>: If you are using Python 3.3 or later, use <a href=\"http:\/\/docs.python.org\/dev\/library\/shlex.html#shlex.quote\">shlex.quote<\/a> instead of rolling your own.<\/p>\n",
                "<p>Perhaps you have a specific reason for using <code>os.system()<\/code>. But if not you should probably be using the <a href=\"http:\/\/docs.python.org\/lib\/module-subprocess.html\"><code>subprocess<\/code> module<\/a>. You can specify the pipes directly and avoid using the shell.<\/p>\n\n<p>The following is from <a href=\"http:\/\/www.python.org\/dev\/peps\/pep-0324\/\">PEP324<\/a>:<\/p>\n\n<blockquote>\n<pre><code>Replacing shell pipe line\n-------------------------\n\noutput=`dmesg | grep hda`\n==&gt;\np1 = Popen([\"dmesg\"], stdout=PIPE)\np2 = Popen([\"grep\", \"hda\"], stdin=p1.stdout, stdout=PIPE)\noutput = p2.communicate()[0]\n<\/code><\/pre>\n<\/blockquote>\n",
                "<p><a href=\"https:\/\/docs.python.org\/3\/library\/shlex.html#shlex.quote\"><code>shlex.quote()<\/code><\/a> does what you want since python 3.<\/p>\n\n<p>(Use <a href=\"https:\/\/docs.python.org\/2\/library\/pipes.html#pipes.quote\"><code>pipes.quote<\/code><\/a> to support both python 2 and python 3)<\/p>\n"
            ]
        },
        {
            "tag": "questao_35948",
            "padroes": [
                "I'm using Google App Engine and Django templates.I have a table that I want to display the objects look something like:\nObject Result:\n    Items = [item1,item2]\n    Users = [{name='username',item1=3,item2=4,..]\n\n\nThe Django template is:\n\n\n\n    user\n    {% for item in result.items %\n        {{item\n    {% endfor %\n\n\n{% for user in result.users %\n     \n        {{user.name\n        {% for item in result.items %\n            {{ user.item \n        {% endfor %\n    \n{% endfor %\n\n\n\nNow the Django documention states that when it sees a . in variablesIt tries several things to get the data, one of which is dictionary lookup which is exactly what I want but doesn't seem to happen...\n"
            ],
            "respostas": [
                "<p>shouldn't this:<\/p>\n\n<pre><code>{{ user.item \n<\/code><\/pre>\n\n<p>be this?<\/p>\n\n<pre><code>{{ item \n<\/code><\/pre>\n\n<p>there is no user object in the context within that loop....?<\/p>\n",
                "<p>As a replacement for k,v in user.items on Google App Engine using django templates where user = {'a':1, 'b', 2, 'c', 3<\/p>\n\n<pre><code>{% for pair in user.items %\n   {% for keyval in pair % {{ keyval {% endfor %&lt;br&gt;\n{% endfor %\n<\/code><\/pre>\n\n<p>a 1<br>\nb 2<br>\nc 3<br><\/p>\n\n<p>pair = (key, value) for each dictionary item.<\/p>\n",
                "<p>@Dave Webb (i haven't been rated high enough to comment yet)<\/p>\n\n<p>The dot lookups can be summarized like this: when the template system encounters a dot in a variable name, it tries the following lookups, in this order:<\/p>\n\n<pre><code>* Dictionary lookup (e.e., foo[\"bar\"])\n* Attribute lookup (e.g., foo.bar)\n* Method call (e.g., foo.bar())\n* List-index lookup (e.g., foo[bar])\n<\/code><\/pre>\n\n<p>The system uses the first lookup type that works. ItÃÃÃs short-circuit logic.<\/p>\n",
                "<p>Or you can use the default django system which is used to resolve attributes in tempaltes like this : <\/p>\n\n<pre><code>from django.template import Variable, VariableDoesNotExist\n@register.filter\ndef hash(object, attr):\n    pseudo_context = { 'object' : object \n    try:\n        value = Variable('object.%s' % attr).resolve(pseudo_context)\n    except VariableDoesNotExist:\n        value = None\nreturn value\n<\/code><\/pre>\n\n<p>That just works<\/p>\n\n<p>in your template :<\/p>\n\n<pre><code>{{ user|hash:item \n<\/code><\/pre>\n",
                "<p>I'm assuming that the part the doesn't work is <code>{{ user.item <\/code>.<\/p>\n\n<p>Django will be trying a dictionary lookup, but using the string <code>\"item\"<\/code> and not the value of the <code>item<\/code> loop variable.  Django did the same thing when it resolved <code>{{ user.name  <\/code> to the <code>name<\/code> attribute of the <code>user<\/code> object, rather than looking for a variable called <code>name<\/code>.<\/p>\n\n<p>I think you will need to do some preprocessing of the data in your view before you render it in your template.<\/p>\n",
                "<p>I found a \"nicer\"\/\"better\" solution for getting variables inside\nIts not the nicest way, but it works.<\/p>\n\n<p>You install a custom filter into django which gets the key of your dict as a parameter<\/p>\n\n<p>To make it work in google app-engine you need to add a file to your main directory,\nI called mine *django_hack.py* which contains this little piece of code<\/p>\n\n<pre><code>from google.appengine.ext import webapp\n\nregister = webapp.template.create_template_register()\n\ndef hash(h,key):\n    if key in h:\n        return h[key]\n    else:\n        return None\n\nregister.filter(hash)\n<\/code><\/pre>\n\n<p>Now that we have this file, all we need to do is tell the app-engine to use it...\nwe do that by adding this little line to your main file<\/p>\n\n<pre><code>webapp.template.register_template_library('django_hack')\n<\/code><\/pre>\n\n<p>and in your template view add this template instead of the usual code<\/p>\n\n<pre><code>{{ user|hash:item \n<\/code><\/pre>\n\n<p>And its should work perfectly =)<\/p>\n"
            ]
        }
    ]
}